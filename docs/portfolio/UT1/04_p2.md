---
title: "PrÃ¡ctica 2"
date: 2025-01-01
---

- [Consigna](https://juanfkurucz.com/ucu-ia/ut1/02-feature-modelo-base/)
- [Datos](https://www.kaggle.com/competitions/titanic/overview)
- [Info](https://scikit-learn.org/)
- [Google Colab](https://colab.research.google.com/drive/1nuPh-BP41EjGhOabzr1j7om2KLEUKWqf?usp=sharing)


# 0. InvestigaciÃ³n de Scikit-learn (10 min)

## **ğŸ” Explora la documentaciÃ³n oficial:**

[scikit-learn.org](https://scikit-learn.org/)

### **LogisticRegression:**

1. Â¿QuÃ© tipo de problema resuelve?

ClasificaciÃ³n (binaria y multiclase). Modela probabilidades y decide por clase.

1. Â¿QuÃ© parÃ¡metros importantes tiene?

`penalty` (`l1`, `l2`, `elasticnet`, `None`), `C` (inverso de la regularizaciÃ³n), `solver`, `max_iter`, `class_weight`, `multi_class` (en transiciÃ³n; multinomial recomendado), `l1_ratio` (para `elasticnet`).

1. Â¿CuÃ¡ndo usarÂ `solver='liblinear'`Â vs otros solvers?
- **`liblinear`**: datasets **pequeÃ±os** y **binarios**; soporta `l1`/`l2` (multiclase solo envolviendo con OneVsRest).
- **`lbfgs`, `newton-cg`, `newton-cholesky`, `sag`**: buenos para **multiclase** (optimizan pÃ©rdida multinomial). `newton-cholesky` rinde bien si `n_samples >> n_features * n_classes`.
- **`saga`**: grande-escala y Ãºnico que soporta **`elasticnet`** (tambiÃ©n `l1`, `l2`) con multiclase.

### **DummyClassifier:**

1. Â¿Para quÃ© sirve exactamente?

Da una **lÃ­nea base** que ignora `X` (predicciones triviales) para comparar si tu modelo real aporta algo.

1. Â¿QuÃ© estrategias de baseline ofrece?

Estrategias (strategy): `most_frequent`, `prior`, `stratified`, `uniform`, `constant` (predice una clase dada).

1. Â¿Por quÃ© es importante tener un baseline?

Si tu modelo no supera al Dummy, probablemente no estÃ¡ aprendiendo nada Ãºtil respecto a la distribuciÃ³n de clases.

### **train_test_split:**

1. Â¿QuÃ© hace el parÃ¡metroÂ `stratify`?

Mantiene en train y test la **misma proporciÃ³n de clases** que en el dataset original.

1. Â¿Por quÃ© usarÂ `random_state`?

Para reproducibilidad de la particiÃ³n aleatoria.

1. Â¿QuÃ© porcentaje de test es recomendable?

La doc no fija un porcentaje â€œidealâ€; elige test_size segÃºn tamaÃ±o de datos y usa validaciÃ³n cruzada (p. ej., StratifiedKFold) cuando haya pocas muestras o clases desbalanceadas.

### **MÃ©tricas de evaluaciÃ³n:**

1. Â¿QuÃ© significa cada mÃ©trica enÂ `classification_report`?

precision (TP/(TP+FP)), recall (TP/(TP+FN)), f1-score (media armÃ³nica de precision y recall), support (nÂº de muestras por clase).

1. Â¿CÃ³mo interpretar la matriz de confusiÃ³n?

Filas = verdaderas, columnas = predichas. La diagonal son aciertos; los fuera de diagonal son errores (quÃ© clases se confunden). Puede normalizarse por verdaderas/predichas/todas.

1. Â¿CuÃ¡ndo usar accuracy vs otras mÃ©tricas?

**Accuracy**: ok si las clases estÃ¡n **balanceadas** y los costos de error son similares.
Con **desbalance** o cuando importan mÃ¡s FN o FP, prioriza **precision/recall/F1**; la propia guÃ­a destaca precisiÃ³n-recobrado y curvas PR para clases muy desbalanceadas. 

# **1. Preprocesamiento y features**

## Que es **Feature Engineering?**

Feature Engineering es crear nuevas variables (features) a partir de las existentes para mejorar el modelo. Es como "cocinar" los datos para que el algoritmo los entienda mejor.

```python
((891, 14), (891,))
```

Esto significa que, despuÃ©s de todo tu preprocesamiento y **one-hot encoding**, tu **matriz de entrada `X`** quedÃ³ con **891 filas y 14 columnas**, y tu **vector objetivo `y`** tiene **891 etiquetas**.

**ExplicaciÃ³n codigo!:**

1. **QuÃ© hace cada bloque**
- `df = train.copy()`: trabajÃ¡s sobre una copia.
- **ImputaciÃ³n**:
    - `Embarked`: completa con la **moda**.
    - `Fare`: completa con la **mediana**.
    - `Age`: completa con la **mediana por grupo** (`Sex`,`Pclass`).
        
        `transform('median')` devuelve un vector alineado a las filas originales (una mediana para cada fila segÃºn su grupo).
        
- **Nuevas features**:
    - `FamilySize = SibSp + Parch + 1` (la persona cuenta).
    - `IsAlone = 1` si el tamaÃ±o de familia es 1.
    - `Title`: extrae el tÃ­tulo del nombre (regex `',\s*([^\.]+)\.'` â†’ lo que estÃ¡ entre coma y punto).
        
        Luego colapsÃ¡s tÃ­tulos poco frecuentes a `'Rare'`.
        
- **Preparar para el modelo**:
    - ElegÃ­s `features = [...]`.
    - `pd.get_dummies(..., drop_first=True)`: convierte categÃ³ricas a dummies y **elimina la primera categorÃ­a** de cada variable para evitar colinealidad perfecta (kâˆ’1 columnas por variable categÃ³rica).
    - `y = df['Survived']`.
1. **Por quÃ© `X.shape == (891, 14`**
- El dataset de Titanic â€œtrainâ€ tiene **891 pasajeros** â†’ 891 filas.
- Las **14 columnas** salen de:
    - Variables numÃ©ricas/directas:
        
        `Pclass`, `Age`, `Fare`, `FamilySize`, `IsAlone`, `SibSp`, `Parch` â†’ **7**
        
    - Dummies:
        - `Sex` (2 categorÃ­as) con `drop_first` â†’ **1**
        - `Embarked` (S, C, Q) con `drop_first` â†’ **2**
        - `Title` (tras agrupar, tÃ­picamente 5 categorÃ­as: p.ej. `Mr`, `Mrs`, `Miss`, `Master`, `Rare`) con `drop_first` â†’ **4**
    - Total: **7 + 1 + 2 + 4 = 14**.
1. **Por quÃ© `y.shape == (891,)`**
- `y` es un **vector** (no matriz) con la etiqueta `Survived` para cada una de las **891** filas.

# **2. Modelo base y baseline**

## Por que se necesita un Baseline?

UnÂ **baseline**Â es un modelo muy simple que nos da una referencia de quÃ© tan bien podemos hacer con reglas bÃ¡sicas. Si nuestro modelo complejo no supera al baseline, algo estÃ¡ mal.

```python
Baseline acc: 0.6145251396648045
LogReg acc  : 0.8156424581005587

Classification report (LogReg):
              precision    recall  f1-score   support

           0       0.82      0.89      0.86       110
           1       0.80      0.70      0.74        69

    accuracy                           0.82       179
   macro avg       0.81      0.79      0.80       179
weighted avg       0.81      0.82      0.81       179

Confusion matrix (LogReg):
[[98 12]
 [21 48]]
```

**ExplicaciÃ³n!:**

**Que significa el baseline?**

- **Baseline acc = 0.6145**: si usaste `DummyClassifier(strategy='most_frequent')`, eso es â€œsiempre predecir la clase mayoritariaâ€.
    
    En tu test hay **179** casos y la clase **0 (no sobreviviÃ³)** tiene **110** (lo ves en el `support` y en la matriz).
    
    110/179=0.6145110 / 179 = 0.6145110/179=0.6145 â‡’ el baseline coincide con â€œtodo 0â€.
    

**Mejora de tu Logistic Regression**

- **LogReg acc = 0.8156**: sube ~**20,1 puntos** sobre el baseline (de 61,45% a 81,56%).
    
    Eso es **+32,7%** de mejora relativa en accuracy y **â€“52,2%** de reducciÃ³n del error (pasÃ¡s de 38,55% a 18,44%).
    

**CÃ³mo leer el classification_report**

- **Clase 0**: `precision=0.82`, `recall=0.89`, `f1=0.86`, `support=110`
    - Precision 0.82 = de los **110** predichos como 0+? (miramos matriz): TN=98, FP=12 â‡’ 98/(98+12)=0.8298/(98+12)=0.8298/(98+12)=0.82
    - Recall 0.89 = de los **110** verdaderos 0, acertaste **98** â‡’ 98/(98+12)=0.8998/(98+12)=0.8998/(98+12)=0.89.
- **Clase 1**: `precision=0.80`, `recall=0.70`, `f1=0.74`, `support=69`
    - Precision 0.80 = 48/(48+12)=0.8048/(48+12)=0.8048/(48+12)=0.80
    - Recall 0.70 = 48/(48+21)=0.695...48/(48+21)=0.695...48/(48+21)=0.695... â‰ˆ 0.70
- **Accuracy = 0.82** con 179 casos.
- **Macro avg**: media simple entre clases (no pondera tamaÃ±os).
- **Weighted avg**: media ponderada por `support` (refleja mejor el global cuando hay desbalance).

### Matriz de confusiÃ³n

```
[[98 12]
 [21 48]]
```

- Filas = **clase verdadera**; Columnas = **predicciÃ³n**.
- Para clase 0: **98** aciertos (TN) y **12** falsos positivos.
- Para clase 1: **48** aciertos (TP) y **21** falsos negativos.
- El modelo **distingue mejor la clase 0** (recall 0.89) que la 1 (recall 0.70). Hay **21** positivos que se le escaparon (FN).

# â“ Preguntas

1. **Matriz de confusiÃ³n:**Â Â¿En quÃ© casos se equivoca mÃ¡s el modelo: cuando predice que una persona sobreviviÃ³ y no lo hizo, o al revÃ©s?

Con `[[98 12],[21 48]]` (filas = verdadero, columnas = predicho):

- **FP (predijo 1 y era 0)** = 12
- **FN (predijo 0 y era 1)** = 21
    
    Se equivoca mÃ¡s cuando predice que NO sobreviviÃ³ y sÃ­ sobreviviÃ³ (FN=21 > FP=12).
    
1. **Clases atendidas:**Â Â¿El modelo acierta mÃ¡s con los que sobrevivieron o con los que no sobrevivieron?
- Clase 0 (no sobreviviÃ³): recall = 98/110 â‰ˆ **89.1%**
- Clase 1 (sobreviviÃ³): recall = 48/69 â‰ˆ **69.6%**
    
    Acierta mÃ¡s con los que no sobrevivieron (clase 0).
    
1. **ComparaciÃ³n con baseline:**Â Â¿La RegresiÃ³n LogÃ­stica obtiene mÃ¡s aciertos que el modelo que siempre predice la clase mÃ¡s comÃºn?
- **Baseline acc** â‰ˆ **0.6145** (predecir siempre 0 â†’ 110/179).
- **LogReg acc** â‰ˆ **0.8156** (146/179).
    
    La RegresiÃ³n LogÃ­stica supera claramente al baseline (+20.1 pts).
    
1. **Errores mÃ¡s importantes:**Â Â¿CuÃ¡l de los dos tipos de error creÃ©s que es mÃ¡s grave para este problema?

Depende del objetivo:

- Si te importa no perder verdaderos sobrevivientes (clase 1), el error mÃ¡s grave es el FN (decir â€œno sobreviveâ€ a quien sÃ­ sobreviviÃ³).
- Si el costo es alarmar de mÃ¡s (marcar como 1 a quien no lo es), entonces preocupa el FP.
    
    En Titanic, suele interesar mÃ¡s captar sobrevivientes â‡’ reducir FN (mejorar recall de la clase 1).
    
1. **Observaciones generales:**Â Mirando las grÃ¡ficas y nÃºmeros, Â¿quÃ© patrones interesantes encontraste sobre la supervivencia?
- Sexo: mujeres tienden a tener mayor tasa de supervivencia.
- Clase: 1Âª clase sobrevive mÃ¡s que 2Âª y 3Âª.
- Tarifa (Fare): tarifas altas suelen asociarse a mayor supervivencia.
- Edad/niÃ±ez: niÃ±os (p. ej., â€œMasterâ€) tienen mejores tasas.
- TamaÃ±o de familia: estar completamente solo suele perjudicar; tamaÃ±os moderados ayudan.
    
    (Estos patrones suelen verse en las grÃ¡ficas mÃ¡s comunes de esta comp).
    
1. **Mejoras simples:**Â Â¿QuÃ© nueva columna (feature) se te ocurre que podrÃ­a ayudar a que el modelo acierte mÃ¡s?

Una columna que suele ayudar: **`FarePerPerson = Fare / FamilySize`**

- Normaliza la tarifa por el tamaÃ±o del grupo/familia y captura mejor el â€œpoder adquisitivoâ€ individual.
    
    Otras ideas rÃ¡pidas: **`Deck`** (letra de `Cabin`), **`TicketGroupSize`** (cuÃ¡ntos comparten el mismo ticket), interacciones como `Sex*Pclass` o `Age*Pclass`.
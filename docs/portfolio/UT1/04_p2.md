---
title: "Práctica 2"
date: 2025-01-01
---

# **Práctica 2: Feature Engineering simple + Modelo base**

- [Consigna](https://juanfkurucz.com/ucu-ia/ut1/02-feature-modelo-base/)
- [Datos](https://www.kaggle.com/competitions/titanic/overview)
- [Info](https://scikit-learn.org/)
- [Google Colab](https://colab.research.google.com/drive/1nuPh-BP41EjGhOabzr1j7om2KLEUKWqf?usp=sharing)


# Investigación de Scikit-learn 

## **Exploración de la documentación oficial**

[scikit-learn.org](https://scikit-learn.org/)

### **LogisticRegression:**

1. ¿Qué tipo de problema resuelve?

Clasificación (binaria y multiclase). Modela probabilidades y decide por clase.

1. ¿Qué parámetros importantes tiene?

`penalty` (`l1`, `l2`, `elasticnet`, `None`), `C` (inverso de la regularización), `solver`, `max_iter`, `class_weight`, `multi_class` (en transición; multinomial recomendado), `l1_ratio` (para `elasticnet`).

1. ¿Cuándo usar `solver='liblinear'` vs otros solvers?
- **`liblinear`**: datasets **pequeños** y **binarios**; soporta `l1`/`l2` (multiclase solo envolviendo con OneVsRest).
- **`lbfgs`, `newton-cg`, `newton-cholesky`, `sag`**: buenos para **multiclase** (optimizan pérdida multinomial). `newton-cholesky` rinde bien si `n_samples >> n_features * n_classes`.
- **`saga`**: grande-escala y único que soporta **`elasticnet`** (también `l1`, `l2`) con multiclase.

### **DummyClassifier:**

1. ¿Para qué sirve exactamente?

Da una **línea base** que ignora `X` (predicciones triviales) para comparar si tu modelo real aporta algo.

1. ¿Qué estrategias de baseline ofrece?

Estrategias (strategy): `most_frequent`, `prior`, `stratified`, `uniform`, `constant` (predice una clase dada).

1. ¿Por qué es importante tener un baseline?

Si tu modelo no supera al Dummy, probablemente no está aprendiendo nada útil respecto a la distribución de clases.

### **train_test_split:**

1. ¿Qué hace el parámetro `stratify`?

Mantiene en train y test la **misma proporción de clases** que en el dataset original.

1. ¿Por qué usar `random_state`?

Para reproducibilidad de la partición aleatoria.

1. ¿Qué porcentaje de test es recomendable?

La doc no fija un porcentaje “ideal”; elige test_size según tamaño de datos y usa validación cruzada (p. ej., StratifiedKFold) cuando haya pocas muestras o clases desbalanceadas.

### **Métricas de evaluación:**

1. ¿Qué significa cada métrica en `classification_report`?

precision (TP/(TP+FP)), recall (TP/(TP+FN)), f1-score (media armónica de precision y recall), support (nº de muestras por clase).

1. ¿Cómo interpretar la matriz de confusión?

Filas = verdaderas, columnas = predichas. La diagonal son aciertos; los fuera de diagonal son errores (qué clases se confunden). Puede normalizarse por verdaderas/predichas/todas.

1. ¿Cuándo usar accuracy vs otras métricas?

**Accuracy**: ok si las clases están **balanceadas** y los costos de error son similares.
Con **desbalance** o cuando importan más FN o FP, prioriza **precision/recall/F1**; la propia guía destaca precisión-recobrado y curvas PR para clases muy desbalanceadas. 

# **1. Preprocesamiento y features**

## Que es **Feature Engineering?**

Feature Engineering es crear nuevas variables (features) a partir de las existentes para mejorar el modelo. Es como "cocinar" los datos para que el algoritmo los entienda mejor.

```python
((891, 14), (891,))
```

Esto significa que, después de todo tu preprocesamiento y **one-hot encoding**, tu **matriz de entrada `X`** quedó con **891 filas y 14 columnas**, y tu **vector objetivo `y`** tiene **891 etiquetas**.

**Explicación codigo!:**

1. **Qué hace cada bloque**
- `df = train.copy()`: trabajás sobre una copia.
- **Imputación**:
    - `Embarked`: completa con la **moda**.
    - `Fare`: completa con la **mediana**.
    - `Age`: completa con la **mediana por grupo** (`Sex`,`Pclass`).
        
        `transform('median')` devuelve un vector alineado a las filas originales (una mediana para cada fila según su grupo).
        
- **Nuevas features**:
    - `FamilySize = SibSp + Parch + 1` (la persona cuenta).
    - `IsAlone = 1` si el tamaño de familia es 1.
    - `Title`: extrae el título del nombre (regex `',\s*([^\.]+)\.'` → lo que está entre coma y punto).
        
        Luego colapsás títulos poco frecuentes a `'Rare'`.
        
- **Preparar para el modelo**:
    - Elegís `features = [...]`.
    - `pd.get_dummies(..., drop_first=True)`: convierte categóricas a dummies y **elimina la primera categoría** de cada variable para evitar colinealidad perfecta (k−1 columnas por variable categórica).
    - `y = df['Survived']`.
1. **Por qué `X.shape == (891, 14`**
- El dataset de Titanic “train” tiene **891 pasajeros** → 891 filas.
- Las **14 columnas** salen de:
    - Variables numéricas/directas:
        
        `Pclass`, `Age`, `Fare`, `FamilySize`, `IsAlone`, `SibSp`, `Parch` → **7**
        
    - Dummies:
        - `Sex` (2 categorías) con `drop_first` → **1**
        - `Embarked` (S, C, Q) con `drop_first` → **2**
        - `Title` (tras agrupar, típicamente 5 categorías: p.ej. `Mr`, `Mrs`, `Miss`, `Master`, `Rare`) con `drop_first` → **4**
    - Total: **7 + 1 + 2 + 4 = 14**.
1. **Por qué `y.shape == (891,)`**
- `y` es un **vector** (no matriz) con la etiqueta `Survived` para cada una de las **891** filas.

# **2. Modelo base y baseline**

## Por que se necesita un Baseline?

Un **baseline** es un modelo muy simple que nos da una referencia de qué tan bien podemos hacer con reglas básicas. Si nuestro modelo complejo no supera al baseline, algo está mal.

```python
Baseline acc: 0.6145251396648045
LogReg acc  : 0.8156424581005587

Classification report (LogReg):
              precision    recall  f1-score   support

           0       0.82      0.89      0.86       110
           1       0.80      0.70      0.74        69

    accuracy                           0.82       179
   macro avg       0.81      0.79      0.80       179
weighted avg       0.81      0.82      0.81       179

Confusion matrix (LogReg):
[[98 12]
 [21 48]]
```

**Explicación!:**

**Que significa el baseline?**

- **Baseline acc = 0.6145**: si usaste `DummyClassifier(strategy='most_frequent')`, eso es “siempre predecir la clase mayoritaria”.
    
    En tu test hay **179** casos y la clase **0 (no sobrevivió)** tiene **110** (lo ves en el `support` y en la matriz).
    
    110/179=0.6145110 / 179 = 0.6145110/179=0.6145 ⇒ el baseline coincide con “todo 0”.
    

**Mejora de tu Logistic Regression**

- **LogReg acc = 0.8156**: sube ~**20,1 puntos** sobre el baseline (de 61,45% a 81,56%).
    
    Eso es **+32,7%** de mejora relativa en accuracy y **–52,2%** de reducción del error (pasás de 38,55% a 18,44%).
    

**Cómo leer el classification_report**

- **Clase 0**: `precision=0.82`, `recall=0.89`, `f1=0.86`, `support=110`
    - Precision 0.82 = de los **110** predichos como 0+? (miramos matriz): TN=98, FP=12 ⇒ 98/(98+12)=0.8298/(98+12)=0.8298/(98+12)=0.82
    - Recall 0.89 = de los **110** verdaderos 0, acertaste **98** ⇒ 98/(98+12)=0.8998/(98+12)=0.8998/(98+12)=0.89.
- **Clase 1**: `precision=0.80`, `recall=0.70`, `f1=0.74`, `support=69`
    - Precision 0.80 = 48/(48+12)=0.8048/(48+12)=0.8048/(48+12)=0.80
    - Recall 0.70 = 48/(48+21)=0.695...48/(48+21)=0.695...48/(48+21)=0.695... ≈ 0.70
- **Accuracy = 0.82** con 179 casos.
- **Macro avg**: media simple entre clases (no pondera tamaños).
- **Weighted avg**: media ponderada por `support` (refleja mejor el global cuando hay desbalance).

### Matriz de confusión

```
[[98 12]
 [21 48]]
```

- Filas = **clase verdadera**; Columnas = **predicción**.
- Para clase 0: **98** aciertos (TN) y **12** falsos positivos.
- Para clase 1: **48** aciertos (TP) y **21** falsos negativos.
- El modelo **distingue mejor la clase 0** (recall 0.89) que la 1 (recall 0.70). Hay **21** positivos que se le escaparon (FN).

# ❓ Preguntas

1. **Matriz de confusión:** ¿En qué casos se equivoca más el modelo: cuando predice que una persona sobrevivió y no lo hizo, o al revés?

Con `[[98 12],[21 48]]` (filas = verdadero, columnas = predicho):

- **FP (predijo 1 y era 0)** = 12
- **FN (predijo 0 y era 1)** = 21
    
    Se equivoca más cuando predice que NO sobrevivió y sí sobrevivió (FN=21 > FP=12).
    
1. **Clases atendidas:** ¿El modelo acierta más con los que sobrevivieron o con los que no sobrevivieron?
- Clase 0 (no sobrevivió): recall = 98/110 ≈ **89.1%**
- Clase 1 (sobrevivió): recall = 48/69 ≈ **69.6%**
    
    Acierta más con los que no sobrevivieron (clase 0).
    
1. **Comparación con baseline:** ¿La Regresión Logística obtiene más aciertos que el modelo que siempre predice la clase más común?
- **Baseline acc** ≈ **0.6145** (predecir siempre 0 → 110/179).
- **LogReg acc** ≈ **0.8156** (146/179).
    
    La Regresión Logística supera claramente al baseline (+20.1 pts).
    
1. **Errores más importantes:** ¿Cuál de los dos tipos de error creés que es más grave para este problema?

Depende del objetivo:

- Si te importa no perder verdaderos sobrevivientes (clase 1), el error más grave es el FN (decir “no sobrevive” a quien sí sobrevivió).
- Si el costo es alarmar de más (marcar como 1 a quien no lo es), entonces preocupa el FP.
    
    En Titanic, suele interesar más captar sobrevivientes ⇒ reducir FN (mejorar recall de la clase 1).
    
1. **Observaciones generales:** Mirando las gráficas y números, ¿qué patrones interesantes encontraste sobre la supervivencia?
- Sexo: mujeres tienden a tener mayor tasa de supervivencia.
- Clase: 1ª clase sobrevive más que 2ª y 3ª.
- Tarifa (Fare): tarifas altas suelen asociarse a mayor supervivencia.
- Edad/niñez: niños (p. ej., “Master”) tienen mejores tasas.
- Tamaño de familia: estar completamente solo suele perjudicar; tamaños moderados ayudan.
    
    (Estos patrones suelen verse en las gráficas más comunes de esta comp).
    
1. **Mejoras simples:** ¿Qué nueva columna (feature) se te ocurre que podría ayudar a que el modelo acierte más?

Una columna que suele ayudar: **`FarePerPerson = Fare / FamilySize`**

- Normaliza la tarifa por el tamaño del grupo/familia y captura mejor el “poder adquisitivo” individual.
    
    Otras ideas rápidas: **`Deck`** (letra de `Cabin`), **`TicketGroupSize`** (cuántos comparten el mismo ticket), interacciones como `Sex*Pclass` o `Age*Pclass`.
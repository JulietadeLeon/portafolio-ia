---
title: "Práctica 4"
date: 2025-01-01
---

# Práctica 4: Regresion Lineal y Regresion Logistica

- [Consigna](https://juanfkurucz.com/ucu-ia/ut1/04-regresion-lineal-logistica/)
- [Google Colab](https://colab.research.google.com/drive/1jw9tarib-LxfDrGTF2K5WfiXlT4hW9go?usp=sharing)

# 🏠 Parte 1: Regresión Lineal - Predecir Precios de Casas

## 🔧 **Paso 1: Setup Inicial**

- 🔗 [Documentación LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- 🔗 [Documentación LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- 🔗 [Documentación train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

## 🏠 **Paso 2: Cargar Dataset de Boston Housing**

### **📋 CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)**

🔗 **Referencias oficiales:**

- [Descripción detallada - Kaggle](https://www.kaggle.com/datasets/altavish/boston-housing-dataset)
- [Paper original - Harrison & Rubinfeld (1978)](https://www.sciencedirect.com/science/article/abs/pii/0095069678900062)

**🏠 Caso de negocio:**

- **Problema**: Una inmobiliaria de Boston necesita estimar precios de propiedades automáticamente
- **Objetivo**: Predecir el valor medio de casas (en miles de USD) basado en características del barrio
- **Variables**: 13 características como criminalidad, zonas industriales, acceso a autopistas, etc.
- **Valor para el negocio**: Automatizar valuaciones, optimizar inversiones inmobiliarias
- 💭 ¿Cuál columna contiene los precios que queremos predecir?
- 🔍 Revisa la salida de `boston_data.head()` para ver las columnas
- 📖 Busca en internet: "boston housing dataset target variable"

```python
🏠 DATASET: Boston Housing
 📊 Forma: (506, 14)
 📋 Columnas: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']

🔍 Primeras 5 filas:
      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \
0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   
1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   
2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   
3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   
4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   

        b  lstat  medv  
0  396.90   4.98  24.0  
1  396.90   9.14  21.6  
2  392.83   4.03  34.7  
3  394.63   2.94  33.4  
4  396.90   5.33  36.2  

📊 X tiene forma: (506, 13)
📊 y tiene forma: (506,)
🎯 Queremos predecir: Precio de casas en miles de USD
📈 Precio mínimo: $5.0k, Precio máximo: $50.0k
```

### Dataset Boston Housing

- **Tamaño**: 506 observaciones (casas) y 14 columnas (variables).
- **Variable objetivo (y)**: `medv` → precio medio de las casas en miles de dólares.
- **Variables predictoras (X)**: 13 columnas restantes, que incluyen factores socioeconómicos, demográficos y estructurales.

### Variables

- `crim`: tasa de criminalidad por zona.
- `zn`: proporción de terrenos residenciales de más de 25.000 pies².
- `indus`: proporción de acres destinados a negocios no minoristas.
- `chas`: variable binaria (1 si el barrio está junto al río Charles).
- `nox`: concentración de óxidos de nitrógeno (contaminación del aire).
- `rm`: número medio de habitaciones por vivienda.
- `age`: proporción de casas construidas antes de 1940.
- `dis`: distancia ponderada a centros de empleo en Boston.
- `rad`: índice de accesibilidad a carreteras radiales.
- `tax`: tasa de impuesto a la propiedad.
- `ptratio`: ratio alumnos/profesor en las escuelas locales.
- `b`: medida de población afroamericana en el vecindario.
- `lstat`: % de población con nivel socioeconómico bajo.

### Formas

- `X`: (506, 13) → 506 casas, 13 variables explicativas.
- `y`: (506,) → 506 valores de precio (`medv`).

### Rango de precios

- **Mínimo**: $5.0k
- **Máximo**: $50.0k
    
    Esto significa que el dataset abarca casas desde muy accesibles hasta propiedades de lujo para la época (años 70s).
    

### **Interpretación**

Este dataset busca **predecir el precio medio de las casas en Boston** en función de características estructurales (ej. número de habitaciones), ambientales (ej. contaminación, cercanía al río) y socioeconómicas (ej. criminalidad, nivel socioeconómico del barrio).

## **🔬 Paso 3: Entrenar Regresión Lineal**

- 🤖 ¿Qué clase de sklearn se usa para regresión lineal? (Mira las importaciones arriba)
- 📚 ¿Cuál método entrena un modelo? [Documentación fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit)
- 🔮 ¿Cuál método hace predicciones? [Documentación predict](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict)
- 📊 **Métricas**: [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html), [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html), [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)

```python
📊 Datos de entrenamiento: 404 casas
📊 Datos de prueba: 102 casas
✅ Modelo entrenado!

🔮 Predicciones hechas para 102 casas

📈 MÉTRICAS DE EVALUACIÓN:
   📊 MAE (Error Absoluto Medio): $3.19k
   📊 MSE (Error Cuadrático Medio): 24.29
   📊 RMSE (Raíz del Error Cuadrático): $4.93k
   📊 R² (Coeficiente de determinación): 0.669
   📊 MAPE (Error Porcentual Absoluto): 16.9%

🔍 INTERPRETACIÓN:
   💰 En promedio nos equivocamos por $3.19k (MAE)
   📈 El modelo explica 66.9% de la variabilidad (R²)
   📊 Error porcentual promedio: 16.9% (MAPE)

🔍 EJEMPLOS (Real vs Predicho):
   Casa 1: Real $23.6k vs Predicho $29.0k
   Casa 2: Real $32.4k vs Predicho $36.0k
   Casa 3: Real $13.6k vs Predicho $14.8k
   Casa 4: Real $22.8k vs Predicho $25.0k
   Casa 5: Real $16.1k vs Predicho $18.8k
```

**Resultados generales del modelo**

- **Datos**: el modelo se entrenó con **404 casas** y se probó con **102 casas** (aprox. 80/20 de división).
- **Predicciones**: se hicieron predicciones para todas las casas del conjunto de prueba.

**Métricas principales**

- **MAE = $3.19k** → En promedio, el modelo se equivoca en **3.190 dólares** respecto al precio real de la casa.
- **RMSE = $4.93k** → El error típico está en torno a los **5.000 dólares**; como penaliza más los errores grandes, nos dice que algunos casos se alejan bastante más que el promedio.
- **R² = 0.669** → El modelo explica un **66.9% de la variabilidad** de los precios. No es perfecto, pero es un nivel razonable: dos tercios de las diferencias en precios se entienden por las variables incluidas.
- **MAPE = 16.9%** → El error porcentual medio es de **~17%**, es decir, el precio predicho suele estar entre un **±17%** del valor real.

Esto significa que el modelo es **útil para tener una estimación aproximada del precio**, aunque no sustituye una tasación profesional.

**Ejemplos prácticos**

- Casa 1: real $23.6k → predicho $29.0k (**error de +$5.4k**, un 23% más alto).
- Casa 3: real $13.6k → predicho $14.8k (**muy buen ajuste**, solo $1.2k de diferencia).
- Casa 5: real $16.1k → predicho $18.8k (**error moderado**, +$2.7k).

Esto muestra que:

- El modelo tiende a **sobreestimar precios** en algunos casos (ej: Casa 1).
- Pero en general los valores están dentro de un rango razonable de error.

**Conclusión:**

El modelo de **regresión lineal** logra capturar buena parte de la relación entre las variables del dataset y el precio de las casas, con un error típico de **3–5 mil dólares**. Sin embargo, aún queda ~33% de la variabilidad sin explicar, lo que significa que factores no incluidos en el dataset también influyen bastante en el precio real.

### **📚 BONUS: ¿Qué significan estas métricas?**

- 🔍 [Guía completa de métricas de regresión](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)
- 📊 Piensa en las unidades: ¿cuál mantiene las unidades originales?
- 📈 ¿Cuál métrica castigaría más un error de $50k vs $5k?
1. **MAE (Mean Absolute Error):** Promedio de los errores **absolutos** sin importar si son positivos o negativos.
2. **MSE (Mean Squared Error):** Promedio de los errores **al cuadrado**, penaliza más los errores grandes.
3. **RMSE:** Raíz cuadrada del MSE, vuelve a las **unidades** originales del problema.
4. **R²:** Indica qué porcentaje de la **variabilidad** es explicada por el modelo (0–1, donde 1 es perfecto).
5. **MAPE:** Error porcentual promedio, útil para comparar modelos con diferentes **escalas**.

# 🏥 Parte 2: Regresión Logística - Diagnóstico Médico

## 🩺 **Paso 4: Cargar Datos Médicos**

### **📋 CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)**

🔗 **Referencias oficiales:**

- [Breast Cancer Wisconsin Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
- [Paper original - Wolberg et al. (1995)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2386340/)
- [Descripción sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)

**🩺 Caso de negocio:**

- **Problema**: Un hospital necesita asistencia automatizada para diagnóstico de cáncer de mama
- **Objetivo**: Clasificar tumores como benignos (0) o malignos (1) basado en características celulares
- **Variables**: 30 características de núcleos celulares (tamaño, textura, perímetro, etc.)
- **Valor para el negocio**: Apoyar diagnósticos médicos, reducir tiempo de análisis, segunda opinión automática

```python
🏥 DATASET: Breast Cancer (Diagnóstico)
   📊 Pacientes: 569
   📊 Características: 30
   🎯 Objetivo: Predecir si tumor es benigno (1) o maligno (0)

📊 DISTRIBUCIÓN:
   ❌ Casos malignos: 212
   ✅ Casos benignos: 357
```

## **🧪 Paso 5: Entrenar Regresión Logística**

- 🔪 ¿Cuál función divide datos en entrenamiento y prueba? (Ya la usaste arriba)
- 🤖 ¿Qué clase se usa para regresión logística? [Documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- 📚 Los métodos `.fit()` y `.predict()` son iguales que en regresión lineal
- 💭 Recuerda: `max_iter=5000` evita warnings de convergencia (más iteraciones = mejor convergencia)
- 📊 **Métricas**: [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)
- 🔢 [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)

```python
📊 Datos de entrenamiento: 455 pacientes
📊 Datos de prueba: 114 pacientes
✅ Modelo de clasificación entrenado!

📈 MÉTRICAS DE CLASIFICACIÓN:
   🎯 Exactitud (Accuracy): 0.956 (95.6%)
   🎯 Precisión (Precision): 0.946 (94.6%)
   🎯 Recall (Sensibilidad): 0.986 (98.6%)
   🎯 F1-Score: 0.966

🔢 MATRIZ DE CONFUSIÓN:
   📊 [[39  4]
 [ 1 70]]
   📋 [Verdaderos Negativos, Falsos Positivos]
   📋 [Falsos Negativos, Verdaderos Positivos]

📋 REPORTE DETALLADO:
              precision    recall  f1-score   support

     Maligno       0.97      0.91      0.94        43
     Benigno       0.95      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.96      0.95      0.95       114
weighted avg       0.96      0.96      0.96       114

🔍 INTERPRETACIÓN MÉDICA:
   🩺 Precision: De los casos que predecimos como benignos, 94.6% lo son realmente
   🩺 Recall: De todos los casos benignos reales, detectamos 98.6%
   🩺 F1-Score: Balance general entre precision y recall: 0.966

🔍 EJEMPLOS (Real vs Predicho):
   Paciente 1: Real: Benigno vs Predicho: Benigno
   Paciente 2: Real: Maligno vs Predicho: Maligno
   Paciente 3: Real: Maligno vs Predicho: Maligno
   Paciente 4: Real: Benigno vs Predicho: Benigno
   Paciente 5: Real: Benigno vs Predicho: Benigno
```

### **📚 BONUS: ¿Qué significan las métricas de clasificación?**

- 🔍 [Guía de métricas de clasificación](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)
- 🩺 En medicina: ¿es peor no detectar un cáncer o dar falsa alarma?
- 📊 ¿Cuál métrica usarías si las clases están muy desbalanceadas?
1. **Accuracy:** Porcentaje de predicciones **correctas** sobre el total.
2. **Precision:** De todas las predicciones **positivas**, ¿cuántas fueron realmente correctas?
3. **Recall (Sensibilidad):** De todos los casos **positivos** reales, ¿cuántos detectamos?
4. **F1-Score:** Promedio **armónico** entre precision y recall.
5. **Matriz de Confusión:** Tabla que muestra **predicciones** vs **valores reales**.

## **🎯 Paso 6: Preguntas de Reflexión**

1. **¿Cuál es la diferencia principal entre regresión lineal y logística?**

**💡 PISTA:** Piensa en qué tipo de valores produce cada una (números vs categorías)

- La **regresión lineal** predice **valores numéricos continuos** (ej: precio de una casa).
- La **regresión logística** predice **categorías** (ej: enfermo / sano) a partir de probabilidades entre 0 y 1.
1. **¿Por qué dividimos los datos en entrenamiento y prueba?**

**💡 PISTA:** 🔗 [Artículo sobre train/test split](https://www.geeksforgeeks.org/how-to-split-data-into-train-and-test-sets-in-python/)

- Para que el modelo **aprenda** con una parte (train) y luego podamos **evaluar su desempeño en datos nuevos** (test).
- Así comprobamos si el modelo generaliza bien y no memoriza (overfitting).
1. **¿Qué significa una exactitud del 95%?**

**💡 PISTA:** Si tienes 100 pacientes, ¿en cuántos acertaría el modelo?

- Que el modelo acierta en el **95% de los casos**.
- Si tienes **100 pacientes**, acertaría en **95** y fallaría en **5**.
1. **¿Cuál es más peligroso: predecir "benigno" cuando es "maligno", o al revés?**

**💡 PISTA:** 🩺 Piensa en las consecuencias médicas de cada error

- Es más grave **predecir "benigno" cuando en realidad es "maligno"** (falso negativo).
- Porque significa **no detectar un cáncer**, lo que puede costar la vida.
- Una falsa alarma (falso positivo) es molesta, pero se puede confirmar con más pruebas.

# **📝 Parte 3: Actividad Final - Compara los Dos Modelos**

## **🔍 Paso 7: Comparación Simple**

- 💭 Piensa en ejemplos concretos que viste en los ejercicios anteriores
- 🔍 ¿Qué tipos de números puede dar cada modelo?
- 📊 ¿Cómo medimos si está bien o mal cada tipo de predicción?

| **Aspecto** | **Regresión Lineal** | **Regresión Logística** |
| --- | --- | --- |
| **Qué predice** | Valores numéricos continuos | Valores categóricos (clases) |
| **Ejemplo de uso** | Predecir el precio de una casa según sus m^2 | Predecir si un paciente tiene cáncer: sí/no |
| **Rango de salida** | De -∞ a +∞ (cualquier número real) | Entre 0 y 1 (probabilidad) |
| **Métrica principal** | Error cuadrático medio (MSE, RMSE, R^2) | Exactitud, Precision, Recall, F1-Score |

## **🎯 Paso 8: Reflexión Final**

1. **¿Cuál modelo usarías para predecir el salario de un empleado?**

**💡 PISTA:** El salario, ¿es un número continuo o una categoría?

Regresión lineal, porque el salario es un valor numérico continuo (ej: 1.200 USD, 1.350 USD, etc.).

1. **¿Cuál modelo usarías para predecir si un email es spam?**

**💡 PISTA:** 📧 ¿Cuántas opciones hay? (spam/no spam)

Regresión logística, porque solo hay dos categorías: spam / no spam.

1. **¿Por qué es importante separar datos de entrenamiento y prueba?**

**💡 PISTA:** 🔗 [Conceptos de validación en ML](https://scikit-learn.org/stable/modules/cross_validation.html)

Esto permite comprobar si realmente generaliza y no solo memorizó los datos (evitar overfitting).

---

**📊 Practica con otros datasets:**

- 🏠 [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) - Predicción de precios en California
- 💰 [Tips Dataset](https://github.com/mwaskom/seaborn-data/blob/master/tips.csv) - Predicción de propinas en restaurantes
- 🍷 [Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality) - Clasificación de calidad de vinos
- 🌸 [Iris Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) - Clasificación de especies de flores
- 📧 [SMS Spam](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) - Detección de spam en mensajes

**🤖 Aprende sobre más tipos de modelos:**

- 🔧 [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) - Regresión con regularización L2
- 🎯 [Lasso Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) - Regresión con regularización L1 y selección de features
- ⚖️ [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) - Combina Ridge y Lasso
- 📊 [Polynomial Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) - Regresión polinomial
- 🎪 [SGD Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) - Clasificación con gradiente descendente
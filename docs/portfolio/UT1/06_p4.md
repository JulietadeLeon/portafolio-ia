---
title: "PrÃ¡ctica 4"
date: 2025-01-01
---

# PrÃ¡ctica 4: Regresion Lineal y Regresion Logistica

- [Consigna](https://juanfkurucz.com/ucu-ia/ut1/04-regresion-lineal-logistica/)
- [Google Colab](https://colab.research.google.com/drive/1jw9tarib-LxfDrGTF2K5WfiXlT4hW9go?usp=sharing)

# ğŸ  Parte 1: RegresiÃ³n Lineal - Predecir Precios de Casas

## ğŸ”§Â **Paso 1: Setup Inicial**

- ğŸ”—Â [DocumentaciÃ³n LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- ğŸ”—Â [DocumentaciÃ³n LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- ğŸ”—Â [DocumentaciÃ³n train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

## ğŸ Â **Paso 2: Cargar Dataset de Boston Housing**

### **ğŸ“‹ CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)**

ğŸ”—Â **Referencias oficiales:**

- [DescripciÃ³n detallada - Kaggle](https://www.kaggle.com/datasets/altavish/boston-housing-dataset)
- [Paper original - Harrison & Rubinfeld (1978)](https://www.sciencedirect.com/science/article/abs/pii/0095069678900062)

**ğŸ  Caso de negocio:**

- **Problema**: Una inmobiliaria de Boston necesita estimar precios de propiedades automÃ¡ticamente
- **Objetivo**: Predecir el valor medio de casas (en miles de USD) basado en caracterÃ­sticas del barrio
- **Variables**: 13 caracterÃ­sticas como criminalidad, zonas industriales, acceso a autopistas, etc.
- **Valor para el negocio**: Automatizar valuaciones, optimizar inversiones inmobiliarias
- ğŸ’­ Â¿CuÃ¡l columna contiene los precios que queremos predecir?
- ğŸ” Revisa la salida deÂ `boston_data.head()`Â para ver las columnas
- ğŸ“– Busca en internet: "boston housing dataset target variable"

```python
ğŸ  DATASET: Boston Housing
 ğŸ“Š Forma: (506, 14)
 ğŸ“‹ Columnas: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']

ğŸ” Primeras 5 filas:
      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \
0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   
1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   
2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   
3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   
4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   

        b  lstat  medv  
0  396.90   4.98  24.0  
1  396.90   9.14  21.6  
2  392.83   4.03  34.7  
3  394.63   2.94  33.4  
4  396.90   5.33  36.2  

ğŸ“Š X tiene forma: (506, 13)
ğŸ“Š y tiene forma: (506,)
ğŸ¯ Queremos predecir: Precio de casas en miles de USD
ğŸ“ˆ Precio mÃ­nimo: $5.0k, Precio mÃ¡ximo: $50.0k
```

### Dataset Boston Housing

- **TamaÃ±o**: 506 observaciones (casas) y 14 columnas (variables).
- **Variable objetivo (y)**: `medv` â†’ precio medio de las casas en miles de dÃ³lares.
- **Variables predictoras (X)**: 13 columnas restantes, que incluyen factores socioeconÃ³micos, demogrÃ¡ficos y estructurales.

### Variables

- `crim`: tasa de criminalidad por zona.
- `zn`: proporciÃ³n de terrenos residenciales de mÃ¡s de 25.000 piesÂ².
- `indus`: proporciÃ³n de acres destinados a negocios no minoristas.
- `chas`: variable binaria (1 si el barrio estÃ¡ junto al rÃ­o Charles).
- `nox`: concentraciÃ³n de Ã³xidos de nitrÃ³geno (contaminaciÃ³n del aire).
- `rm`: nÃºmero medio de habitaciones por vivienda.
- `age`: proporciÃ³n de casas construidas antes de 1940.
- `dis`: distancia ponderada a centros de empleo en Boston.
- `rad`: Ã­ndice de accesibilidad a carreteras radiales.
- `tax`: tasa de impuesto a la propiedad.
- `ptratio`: ratio alumnos/profesor en las escuelas locales.
- `b`: medida de poblaciÃ³n afroamericana en el vecindario.
- `lstat`: % de poblaciÃ³n con nivel socioeconÃ³mico bajo.

### Formas

- `X`: (506, 13) â†’ 506 casas, 13 variables explicativas.
- `y`: (506,) â†’ 506 valores de precio (`medv`).

### Rango de precios

- **MÃ­nimo**: $5.0k
- **MÃ¡ximo**: $50.0k
    
    Esto significa que el dataset abarca casas desde muy accesibles hasta propiedades de lujo para la Ã©poca (aÃ±os 70s).
    

### **InterpretaciÃ³n**

Este dataset busca **predecir el precio medio de las casas en Boston** en funciÃ³n de caracterÃ­sticas estructurales (ej. nÃºmero de habitaciones), ambientales (ej. contaminaciÃ³n, cercanÃ­a al rÃ­o) y socioeconÃ³micas (ej. criminalidad, nivel socioeconÃ³mico del barrio).

## **ğŸ”¬Â Paso 3: Entrenar RegresiÃ³n Lineal**

- ğŸ¤– Â¿QuÃ© clase de sklearn se usa para regresiÃ³n lineal? (Mira las importaciones arriba)
- ğŸ“š Â¿CuÃ¡l mÃ©todo entrena un modelo?Â [DocumentaciÃ³n fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit)
- ğŸ”® Â¿CuÃ¡l mÃ©todo hace predicciones?Â [DocumentaciÃ³n predict](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict)
- ğŸ“ŠÂ **MÃ©tricas**:Â [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html),Â [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html),Â [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)

```python
ğŸ“Š Datos de entrenamiento: 404 casas
ğŸ“Š Datos de prueba: 102 casas
âœ… Modelo entrenado!

ğŸ”® Predicciones hechas para 102 casas

ğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:
   ğŸ“Š MAE (Error Absoluto Medio): $3.19k
   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): 24.29
   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): $4.93k
   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): 0.669
   ğŸ“Š MAPE (Error Porcentual Absoluto): 16.9%

ğŸ” INTERPRETACIÃ“N:
   ğŸ’° En promedio nos equivocamos por $3.19k (MAE)
   ğŸ“ˆ El modelo explica 66.9% de la variabilidad (RÂ²)
   ğŸ“Š Error porcentual promedio: 16.9% (MAPE)

ğŸ” EJEMPLOS (Real vs Predicho):
   Casa 1: Real $23.6k vs Predicho $29.0k
   Casa 2: Real $32.4k vs Predicho $36.0k
   Casa 3: Real $13.6k vs Predicho $14.8k
   Casa 4: Real $22.8k vs Predicho $25.0k
   Casa 5: Real $16.1k vs Predicho $18.8k
```

**Resultados generales del modelo**

- **Datos**: el modelo se entrenÃ³ con **404 casas** y se probÃ³ con **102 casas** (aprox. 80/20 de divisiÃ³n).
- **Predicciones**: se hicieron predicciones para todas las casas del conjunto de prueba.

**MÃ©tricas principales**

- **MAE = $3.19k** â†’ En promedio, el modelo se equivoca en **3.190 dÃ³lares** respecto al precio real de la casa.
- **RMSE = $4.93k** â†’ El error tÃ­pico estÃ¡ en torno a los **5.000 dÃ³lares**; como penaliza mÃ¡s los errores grandes, nos dice que algunos casos se alejan bastante mÃ¡s que el promedio.
- **RÂ² = 0.669** â†’ El modelo explica un **66.9% de la variabilidad** de los precios. No es perfecto, pero es un nivel razonable: dos tercios de las diferencias en precios se entienden por las variables incluidas.
- **MAPE = 16.9%** â†’ El error porcentual medio es de **~17%**, es decir, el precio predicho suele estar entre un **Â±17%** del valor real.

Esto significa que el modelo es **Ãºtil para tener una estimaciÃ³n aproximada del precio**, aunque no sustituye una tasaciÃ³n profesional.

**Ejemplos prÃ¡cticos**

- Casa 1: real $23.6k â†’ predicho $29.0k (**error de +$5.4k**, un 23% mÃ¡s alto).
- Casa 3: real $13.6k â†’ predicho $14.8k (**muy buen ajuste**, solo $1.2k de diferencia).
- Casa 5: real $16.1k â†’ predicho $18.8k (**error moderado**, +$2.7k).

Esto muestra que:

- El modelo tiende a **sobreestimar precios** en algunos casos (ej: Casa 1).
- Pero en general los valores estÃ¡n dentro de un rango razonable de error.

**ConclusiÃ³n:**

El modelo de **regresiÃ³n lineal** logra capturar buena parte de la relaciÃ³n entre las variables del dataset y el precio de las casas, con un error tÃ­pico de **3â€“5 mil dÃ³lares**. Sin embargo, aÃºn queda ~33% de la variabilidad sin explicar, lo que significa que factores no incluidos en el dataset tambiÃ©n influyen bastante en el precio real.

### **ğŸ“šÂ BONUS: Â¿QuÃ© significan estas mÃ©tricas?**

- ğŸ”Â [GuÃ­a completa de mÃ©tricas de regresiÃ³n](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)
- ğŸ“Š Piensa en las unidades: Â¿cuÃ¡l mantiene las unidades originales?
- ğŸ“ˆ Â¿CuÃ¡l mÃ©trica castigarÃ­a mÃ¡s un error de $50k vs $5k?
1. **MAE (Mean Absolute Error):** Promedio de los errores **absolutos** sin importar si son positivos o negativos.
2. **MSE (Mean Squared Error):** Promedio de los errores **al cuadrado**, penaliza mÃ¡s los errores grandes.
3. **RMSE:** RaÃ­z cuadrada del MSE, vuelve a las **unidades** originales del problema.
4. **RÂ²:** Indica quÃ© porcentaje de la **variabilidad** es explicada por el modelo (0â€“1, donde 1 es perfecto).
5. **MAPE:** Error porcentual promedio, Ãºtil para comparar modelos con diferentes **escalas**.

# ğŸ¥ Parte 2: RegresiÃ³n LogÃ­stica - DiagnÃ³stico MÃ©dico

## ğŸ©ºÂ **Paso 4: Cargar Datos MÃ©dicos**

### **ğŸ“‹ CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)**

ğŸ”—Â **Referencias oficiales:**

- [Breast Cancer Wisconsin Dataset - UCI Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
- [Paper original - Wolberg et al. (1995)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2386340/)
- [DescripciÃ³n sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)

**ğŸ©º Caso de negocio:**

- **Problema**: Un hospital necesita asistencia automatizada para diagnÃ³stico de cÃ¡ncer de mama
- **Objetivo**: Clasificar tumores como benignos (0) o malignos (1) basado en caracterÃ­sticas celulares
- **Variables**: 30 caracterÃ­sticas de nÃºcleos celulares (tamaÃ±o, textura, perÃ­metro, etc.)
- **Valor para el negocio**: Apoyar diagnÃ³sticos mÃ©dicos, reducir tiempo de anÃ¡lisis, segunda opiniÃ³n automÃ¡tica

```python
ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)
   ğŸ“Š Pacientes: 569
   ğŸ“Š CaracterÃ­sticas: 30
   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)

ğŸ“Š DISTRIBUCIÃ“N:
   âŒ Casos malignos: 212
   âœ… Casos benignos: 357
```

## **ğŸ§ªÂ Paso 5: Entrenar RegresiÃ³n LogÃ­stica**

- ğŸ”ª Â¿CuÃ¡l funciÃ³n divide datos en entrenamiento y prueba? (Ya la usaste arriba)
- ğŸ¤– Â¿QuÃ© clase se usa para regresiÃ³n logÃ­stica?Â [DocumentaciÃ³n](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- ğŸ“š Los mÃ©todosÂ `.fit()`Â yÂ `.predict()`Â son iguales que en regresiÃ³n lineal
- ğŸ’­ Recuerda:Â `max_iter=5000`Â evita warnings de convergencia (mÃ¡s iteraciones = mejor convergencia)
- ğŸ“ŠÂ **MÃ©tricas**:Â [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html),Â [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html),Â [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)
- ğŸ”¢Â [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html),Â [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)

```python
ğŸ“Š Datos de entrenamiento: 455 pacientes
ğŸ“Š Datos de prueba: 114 pacientes
âœ… Modelo de clasificaciÃ³n entrenado!

ğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:
   ğŸ¯ Exactitud (Accuracy): 0.956 (95.6%)
   ğŸ¯ PrecisiÃ³n (Precision): 0.946 (94.6%)
   ğŸ¯ Recall (Sensibilidad): 0.986 (98.6%)
   ğŸ¯ F1-Score: 0.966

ğŸ”¢ MATRIZ DE CONFUSIÃ“N:
   ğŸ“Š [[39  4]
 [ 1 70]]
   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]
   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]

ğŸ“‹ REPORTE DETALLADO:
              precision    recall  f1-score   support

     Maligno       0.97      0.91      0.94        43
     Benigno       0.95      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.96      0.95      0.95       114
weighted avg       0.96      0.96      0.96       114

ğŸ” INTERPRETACIÃ“N MÃ‰DICA:
   ğŸ©º Precision: De los casos que predecimos como benignos, 94.6% lo son realmente
   ğŸ©º Recall: De todos los casos benignos reales, detectamos 98.6%
   ğŸ©º F1-Score: Balance general entre precision y recall: 0.966

ğŸ” EJEMPLOS (Real vs Predicho):
   Paciente 1: Real: Benigno vs Predicho: Benigno
   Paciente 2: Real: Maligno vs Predicho: Maligno
   Paciente 3: Real: Maligno vs Predicho: Maligno
   Paciente 4: Real: Benigno vs Predicho: Benigno
   Paciente 5: Real: Benigno vs Predicho: Benigno
```

### **ğŸ“šÂ BONUS: Â¿QuÃ© significan las mÃ©tricas de clasificaciÃ³n?**

- ğŸ”Â [GuÃ­a de mÃ©tricas de clasificaciÃ³n](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)
- ğŸ©º En medicina: Â¿es peor no detectar un cÃ¡ncer o dar falsa alarma?
- ğŸ“Š Â¿CuÃ¡l mÃ©trica usarÃ­as si las clases estÃ¡n muy desbalanceadas?
1. **Accuracy:** Porcentaje de predicciones **correctas** sobre el total.
2. **Precision:** De todas las predicciones **positivas**, Â¿cuÃ¡ntas fueron realmente correctas?
3. **Recall (Sensibilidad):** De todos los casos **positivos** reales, Â¿cuÃ¡ntos detectamos?
4. **F1-Score:** Promedio **armÃ³nico** entre precision y recall.
5. **Matriz de ConfusiÃ³n:** Tabla que muestra **predicciones** vs **valores reales**.

## **ğŸ¯Â Paso 6: Preguntas de ReflexiÃ³n**

1. **Â¿CuÃ¡l es la diferencia principal entre regresiÃ³n lineal y logÃ­stica?**

**ğŸ’¡ PISTA:**Â Piensa en quÃ© tipo de valores produce cada una (nÃºmeros vs categorÃ­as)

- La **regresiÃ³n lineal** predice **valores numÃ©ricos continuos** (ej: precio de una casa).
- La **regresiÃ³n logÃ­stica** predice **categorÃ­as** (ej: enfermo / sano) a partir de probabilidades entre 0 y 1.
1. **Â¿Por quÃ© dividimos los datos en entrenamiento y prueba?**

**ğŸ’¡ PISTA:**Â ğŸ”—Â [ArtÃ­culo sobre train/test split](https://www.geeksforgeeks.org/how-to-split-data-into-train-and-test-sets-in-python/)

- Para que el modelo **aprenda** con una parte (train) y luego podamos **evaluar su desempeÃ±o en datos nuevos** (test).
- AsÃ­ comprobamos si el modelo generaliza bien y no memoriza (overfitting).
1. **Â¿QuÃ© significa una exactitud del 95%?**

**ğŸ’¡ PISTA:**Â Si tienes 100 pacientes, Â¿en cuÃ¡ntos acertarÃ­a el modelo?

- Que el modelo acierta en el **95% de los casos**.
- Si tienes **100 pacientes**, acertarÃ­a en **95** y fallarÃ­a en **5**.
1. **Â¿CuÃ¡l es mÃ¡s peligroso: predecir "benigno" cuando es "maligno", o al revÃ©s?**

**ğŸ’¡ PISTA:**Â ğŸ©º Piensa en las consecuencias mÃ©dicas de cada error

- Es mÃ¡s grave **predecir "benigno" cuando en realidad es "maligno"** (falso negativo).
- Porque significa **no detectar un cÃ¡ncer**, lo que puede costar la vida.
- Una falsa alarma (falso positivo) es molesta, pero se puede confirmar con mÃ¡s pruebas.

# **ğŸ“ Parte 3: Actividad Final - Compara los Dos Modelos**

## **ğŸ”Â Paso 7: ComparaciÃ³n Simple**

- ğŸ’­ Piensa en ejemplos concretos que viste en los ejercicios anteriores
- ğŸ” Â¿QuÃ© tipos de nÃºmeros puede dar cada modelo?
- ğŸ“Š Â¿CÃ³mo medimos si estÃ¡ bien o mal cada tipo de predicciÃ³n?

| **Aspecto** | **RegresiÃ³n Lineal** | **RegresiÃ³n LogÃ­stica** |
| --- | --- | --- |
| **QuÃ© predice** | Valores numÃ©ricos continuos | Valores categÃ³ricos (clases) |
| **Ejemplo de uso** | Predecir el precio de una casa segÃºn sus m^2 | Predecir si un paciente tiene cÃ¡ncer: sÃ­/no |
| **Rango de salida** | De -âˆ a +âˆ (cualquier nÃºmero real) | Entre 0 y 1 (probabilidad) |
| **MÃ©trica principal** | Error cuadrÃ¡tico medio (MSE, RMSE, R^2) | Exactitud, Precision, Recall, F1-Score |

## **ğŸ¯Â Paso 8: ReflexiÃ³n Final**

1. **Â¿CuÃ¡l modelo usarÃ­as para predecir el salario de un empleado?**

**ğŸ’¡ PISTA:**Â El salario, Â¿es un nÃºmero continuo o una categorÃ­a?

RegresiÃ³n lineal, porque el salario es un valor numÃ©rico continuo (ej: 1.200 USD, 1.350 USD, etc.).

1. **Â¿CuÃ¡l modelo usarÃ­as para predecir si un email es spam?**

**ğŸ’¡ PISTA:**Â ğŸ“§ Â¿CuÃ¡ntas opciones hay? (spam/no spam)

RegresiÃ³n logÃ­stica, porque solo hay dos categorÃ­as: spam / no spam.

1. **Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?**

**ğŸ’¡ PISTA:**Â ğŸ”—Â [Conceptos de validaciÃ³n en ML](https://scikit-learn.org/stable/modules/cross_validation.html)

Esto permite comprobar si realmente generaliza y no solo memorizÃ³ los datos (evitar overfitting).

---

**ğŸ“Š Practica con otros datasets:**

- ğŸ Â [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)Â - PredicciÃ³n de precios en California
- ğŸ’°Â [Tips Dataset](https://github.com/mwaskom/seaborn-data/blob/master/tips.csv)Â - PredicciÃ³n de propinas en restaurantes
- ğŸ·Â [Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)Â - ClasificaciÃ³n de calidad de vinos
- ğŸŒ¸Â [Iris Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)Â - ClasificaciÃ³n de especies de flores
- ğŸ“§Â [SMS Spam](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)Â - DetecciÃ³n de spam en mensajes

**ğŸ¤– Aprende sobre mÃ¡s tipos de modelos:**

- ğŸ”§Â [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)Â - RegresiÃ³n con regularizaciÃ³n L2
- ğŸ¯Â [Lasso Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)Â - RegresiÃ³n con regularizaciÃ³n L1 y selecciÃ³n de features
- âš–ï¸Â [Elastic Net](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)Â - Combina Ridge y Lasso
- ğŸ“ŠÂ [Polynomial Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)Â - RegresiÃ³n polinomial
- ğŸªÂ [SGD Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)Â - ClasificaciÃ³n con gradiente descendente
# Apuntes

## ¬øQu√© es Machine Learning?

![.](assets/image.png)


## 3 definiciones de Machine Learning

- Es una rama de la inteligencia artificial que permite a los sistemas aprender de los datos sin ser programados expl√≠citamente. (Resumen Google)
- El machine learning es una rama de la inteligencia artificial (IA) centrada en entrenar a computadoras y m√°quinas para imitar el modo en que aprenden los humanos, realizar tareas de forma aut√≥noma y mejorar su rendimiento y precisi√≥n a trav√©s de la experiencia y la exposici√≥n a m√°s datos. (IBM)
- La capacidad de aprendizaje y de predicci√≥n de las m√°quinas se ha incrementado a lo largo del tiempo. Esto se observa tanto en los asistentes virtuales, que cada vez son m√°s eficientes al responder y ejecutar tareas gracias a la mejora de los grandes modelos de lenguaje (LLM), como en plataformas de 'streaming' o comercio electr√≥nico, que utilizan algoritmos para personalizar contenidos. El 'machine learning', especializado en el reconocimiento de patrones, es un campo en auge con d√©cadas de historia. (BBVA)

## Diferencias con inteligencia artificial

- Inteligencia Artificial (IA): Es el concepto m√°s amplio. Engloba todas las t√©cnicas para que una m√°quina ‚Äúpiense‚Äù o act√∫e de manera inteligente, incluyendo reglas programadas a mano, l√≥gica, b√∫squeda, y tambi√©n machine learning.
- Machine Learning (ML): Es un subconjunto de la IA que se basa espec√≠ficamente en que la m√°quina aprenda de datos y mejore con la experiencia, en lugar de seguir reglas fijas preprogramadas.

En resumen: Toda ML es IA, pero no toda IA es ML.

## Diferencias con an√°lisis estad√≠stico

En com√∫n:

- Ambos usan datos para encontrar patrones, relaciones y tendencias.
- Requieren t√©cnicas matem√°ticas y conocimiento en probabilidad.
- Buscan apoyar la toma de decisiones basadas en evidencia.

Diferencias:

- An√°lisis estad√≠stico: Se enfoca en describir, resumir e inferir conclusiones sobre un conjunto de datos, generalmente con hip√≥tesis predefinidas y modelos interpretables. La prioridad es entender el fen√≥meno.
- Machine Learning: Se centra m√°s en construir modelos predictivos o de clasificaci√≥n que funcionen bien con datos nuevos, a veces sin necesidad de hip√≥tesis previas, y prioriza la precisi√≥n de la predicci√≥n sobre la interpretabilidad.

En pocas palabras: el an√°lisis estad√≠stico explica y valida hip√≥tesis; el machine learning predice y se adapta autom√°ticamente a nuevos datos.

## Diferencias con Data Mining

En com√∫n:

- Tanto Machine Learning como Data Mining buscan descubrir patrones y conocimiento √∫til en grandes vol√∫menes de datos.
- Usan t√©cnicas estad√≠sticas, matem√°ticas y computacionales.
- Se aplican en √°mbitos como marketing, finanzas, salud, seguridad, etc.

Diferencias:

- Data Mining: Es el proceso general de explorar y extraer conocimiento a partir de grandes bases de datos. Incluye tareas como segmentaci√≥n, detecci√≥n de anomal√≠as, asociaci√≥n de reglas y, muchas veces, usa machine learning como herramienta. El foco est√° en descubrir informaci√≥n previamente desconocida.
- Machine Learning: Es una rama espec√≠fica (y m√°s t√©cnica) que desarrolla modelos que aprenden de datos para realizar predicciones o clasificaciones. No se limita a exploraci√≥n; busca generalizar a nuevos datos.

## Herramientas o librer√≠as de IA

- analizar y procesar datos tabulares
- entrenar modelos de machine learning
- procesar y entender texto
- entender texto o hacer chatbots

PyTorch

Torch es una biblioteca de aprendizaje autom√°tico de c√≥digo abierto conocida por su gr√°fico computacional din√°mico y favorecida por los investigadores. El marco es excelente para la creaci√≥n de prototipos y la experimentaci√≥n. Adem√°s, cuenta con el apoyo creciente de la comunidad, que ha creado herramientas como PyTorch. PyTorch se ha convertido r√°pidamente en uno de los frameworks m√°s utilizados, √∫til en todo tipo de aplicaciones.

Keras

Keras es una API de redes neuronales de alto nivel de c√≥digo abierto que se ejecuta sobre TensorFlow u otros marcos. Es f√°cil de usar y de aprender, lo que simplifica el proceso de trabajar con modelos de aprendizaje profundo. Adem√°s, es ideal para la creaci√≥n r√°pida de prototipos. S√≥lo debes tener en cuenta que Keras puede carecer de algunas funciones avanzadas para tareas complejas.

TensorFlow

Desarrollado por Google, TensorFlow es una de las bibliotecas de IA de uso general m√°s utilizadas. Ofrece un ecosistema flexible de herramientas, bibliotecas y recursos comunitarios para ayudar a los investigadores y desarrolladores a desarrollar e implementar una variedad de modelos de IA.

## Proceso CRISP-DM

- comprensi√≥n del negocio
- comprensi√≥n de datos
- preparaci√≥n de datos
- modelado
- evaluaci√≥n
- despliegue

[](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdVQuMvGmZuhBAhoMgRjS40sD9GhilfvbMmbkgaykDxnbKuW1dvGUfHHXRC4dvqoLJUJtVTeFniwm3pit49yog_1_w0-Su6Wqjh5noNklP1DEQD8spOBtGhGKUKfLjyh4talsbdDA?key=FN5pMZSQ79RaqUo1B27ldQ)

De manera simple, Machine Learning consiste en ense√±ar a las computadoras a aprender patrones de datos con el fin de realizar predicciones.

Su funcionamiento es similar al del cerebro humano:

- Primero se observan muchos ejemplos.
- Luego se detectan patrones en esos datos.
- Finalmente, se hacen predicciones sobre casos nuevos.

## **Machine Learning**

El proceso de Machine Learning se basa en tres pasos principales:

1. Se alimentan datos al algoritmo.
2. El algoritmo encuentra patrones matem√°ticos en esos datos.
3. Con esos patrones, puede hacer predicciones sobre datos nuevos.

**Ejemplo:** despu√©s de analizar 1000 casas vendidas, el algoritmo es capaz de predecir el precio de una casa nueva.

![image.png](image%201.png)

## **EDA**

EDA significa Exploratory Data Analysis o en espa√±ol An√°lisis Exploratorio de Datos.

Es una etapa fundamental dentro de un proyecto de an√°lisis de datos o machine learning y consiste en:

- **Explorar los datos** para entender su estructura, calidad y caracter√≠sticas.
- **Detectar patrones, tendencias y relaciones** entre variables.
- **Identificar valores at√≠picos (outliers)**, datos faltantes o errores.
- **Usar estad√≠sticas descriptivas** (medias, medianas, varianzas, distribuciones) y **visualizaciones** (gr√°ficos, histogramas, diagramas de dispersi√≥n, etc.) para resumir la informaci√≥n.

En pocas palabras: un **EDA** es como ‚Äúconocer tus datos‚Äù antes de aplicar modelos o algoritmos, asegur√°ndote de entender qu√© informaci√≥n tienes y qu√© problemas puede haber.

```python
train.head(3)
```

- Muestra las **primeras filas** del dataset (por defecto 5).
- √ötil para ver c√≥mo est√°n organizados los datos.

```python
train.info()
```

Resume la **estructura del dataset**: n√∫mero de filas, columnas, tipos de datos y cu√°ntos valores faltan en cada columna.

```python
train.describe(include='all').T
```

- Genera un **resumen estad√≠stico** de todas las columnas (num√©ricas y categ√≥ricas).
- El ‚Äú.T‚Äù lo transpone, dejando variables como filas para leerlo m√°s f√°cil.

```python
train.isna().sum().sort_values(ascending=False)
```

- Cuenta la cantidad de **valores faltantes (NaN)** por columna.
- Luego los ordena de mayor a menor.

```python
train['Survived'].value_counts(normalize=True)
```

- Cuenta cu√°ntos registros hay de cada categor√≠a en la columna ‚Äúsurvived‚Äù.
- Con ‚Äúnormalize=True‚Äù devuelve los **porcentajes** en lugar de los conteos.

## EDA Visual

```python
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Supervivencia global por sexo
sns.countplot(data=train, x='Survived', hue='Sex', ax=axes[0,0])
axes[0,0].set_title('Supervivencia por sexo')

# Tasa de supervivencia por clase
sns.barplot(data=train, x='Pclass', y='Survived', estimator=np.mean, ax=axes[0,1])
axes[0,1].set_title('Tasa de supervivencia por clase')

# Distribuci√≥n de edad por supervivencia
sns.histplot(data=train, x='Age', hue='Survived', kde=True, bins=30, ax=axes[1,0])
axes[1,0].set_title('Edad vs supervivencia')

# Correlaciones num√©ricas
numeric_cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
sns.heatmap(train[numeric_cols].corr(), annot=True, cmap='Blues', ax=axes[1,1])
axes[1,1].set_title('Correlaciones')

plt.tight_layout()
plt.show()
```

### üìä 1. **Supervivencia por sexo** (`countplot`)

- Tipo: **Gr√°fico de barras**.
- Qu√© muestra: Cu√°ntos hombres y cu√°ntas mujeres sobrevivieron (Survived=1) y cu√°ntos no (Survived=0).
- Interpretaci√≥n: Sirve para comparar la **proporci√≥n de supervivencia entre sexos**. En el Titanic, se ve claramente que **sobrevivieron m√°s mujeres que hombres**.

---

### üìä 2. **Tasa de supervivencia por clase** (`barplot`)

- Tipo: **Gr√°fico de barras con medias**.
- Qu√© muestra: El promedio de supervivencia (probabilidad de sobrevivir) seg√∫n la clase del pasajero (`Pclass`).
- Interpretaci√≥n: Generalmente, los pasajeros de **primera clase tuvieron m√°s chances de sobrevivir** que los de segunda o tercera. Muestra c√≥mo la **posici√≥n socioecon√≥mica** influy√≥ en la supervivencia.

---

### üìä 3. **Edad vs supervivencia** (`histplot`)

- Tipo: **Histograma con colores por supervivencia**.
- Qu√© muestra: La distribuci√≥n de la edad de los pasajeros, separada en dos grupos: sobrevivientes (1) y no sobrevivientes (0).
- Interpretaci√≥n: Se puede ver si **ciertas edades ten√≠an m√°s probabilidad de sobrevivir**. Por ejemplo, suelen notarse m√°s **ni√±os sobrevivientes** que adultos mayores, reflejando la pol√≠tica de "mujeres y ni√±os primero".

---

### üìä 4. **Mapa de calor de correlaciones** (`heatmap`)

- Tipo: **Heatmap con anotaciones num√©ricas**.
- Qu√© muestra: Las correlaciones entre las variables num√©ricas (`Survived, Pclass, Age, SibSp, Parch, Fare`).
- Interpretaci√≥n: Ayuda a detectar **relaciones lineales**.
    - Ejemplo: `Pclass` y `Fare` est√°n negativamente correlacionados (a menor clase, mayor tarifa).
    - Tambi√©n se puede ver qu√© variables est√°n m√°s ligadas a `Survived`.

![image.png](image%202.png)

## Limpieza

## Feature Engineering

## Features finales

# Repaso TA4

## Diferencias claves

![image.png](image%203.png)

## Contaminacion de datos (Data Leakage)

Cuando el modelo "ve" informaci√≥n que NO deber√≠a tener durante el
entrenamiento
Como hacer trampa en un examen:
‚Ä¢ Ver las respuestas antes del examen
‚Ä¢ Solo estudiar el material permitido

Ejemplo: Data Leakage en Acci√≥n

**INCORRECTO:**

1. Preprocesar TODO el dataset
2. Dividir en train/test
3. Entrenar modelo

**CORRECTO**:

1. Dividir en train/test
2. Preprocesar SOLO con datos de entrenamiento
3. Aplicar preproces ado a test

**¬øPor qu√© es tan Peligroso?**
‚Ä¢ Optimismo artificial: M√©tricas infladas
‚Ä¢ Informaci√≥n del futuro: El modelo "hace trampa"
‚Ä¢ Falla en producci√≥n: Rendimiento real muy bajo
‚Ä¢ Decisiones err√≥neas: Seleccionas modelo malo

**Soluci√≥n: Pipelines**
Pipeline = Secuencia autom√°tica de pasos
‚Ä¢ Previene data leakage autom√°ticamente
‚Ä¢ Aplica transformaciones en orden correcto
‚Ä¢ Garantiza proceso robusto

## Validacion cruzada (Cross-Validation)

**Problema del Train/Test Split**
‚Ä¢ Una sola divisi√≥n = Una sola "opini√≥n"
‚Ä¢ Resultados pueden variar por suerte
‚Ä¢ ¬øEl modelo es bueno o tuvo suerte?
Necesitamos m√∫ltiples "opiniones‚Äù

**¬øQu√© es Cross-Validation?**
‚Ä¢ Dividir datos en K partes (folds)
‚Ä¢ Entrenar K veces, cada vez con diferente test
‚Ä¢ Promedio de K resultados = estimaci√≥n robusta
‚Ä¢ Desviaci√≥n est√°ndar = estabilidad del modelo

![image.png](image%204.png)

## Comparaci√≥n de Modelos

**¬øPor qu√© Comparar Modelos?**

‚Ä¢ Diferentes algoritmos para diferentes problemas
‚Ä¢ No hay "modelo perfecto universal"
‚Ä¢ Competencia revela el mejor para TUS datos
‚Ä¢ Combinar rendimiento + estabilidad

**Candidatos T√≠picos**

‚Ä¢ Logistic Regression: Simple, interpretable
‚Ä¢ Ridge Classifier: Con regularizaci√≥n
‚Ä¢ Random Forest: Ensemble, robusto
‚Ä¢ SVM: Fronteras complejas

**Proceso de Comparaci√≥n**

1. Crear pipelines para cada modelo
2. Evaluar con cross-validation
3. Comparar accuracy promedio
4. Analizar estabilidad (desviaci√≥n)
5. Seleccionar ganador

**M√©tricas de Selecci√≥n**

‚Ä¢ Rendimiento: ¬øCu√°l es m√°s preciso?
‚Ä¢ Estabilidad: ¬øCu√°l es m√°s consistente?
‚Ä¢ Velocidad: ¬øCu√°l entrena/predice m√°s r√°pido?
‚Ä¢ Memoria: ¬øCu√°l usa menos recursos?
‚Ä¢ Interpretabilidad: ¬øCu√°l es m√°s explicable?

# Problemas de escala

![image.png](image%205.png)

# Normalizaci√≥n

Normalizar = poner todas las columnas en la misma escala para comparar
manzanas con manzanas.

- Hace que las variables hablen el mismo idioma.
- Ayuda a los algoritmos a aprender m√°s parejo.
- No crea informaci√≥n nueva ni arregla sesgos.

# Min-Max vs StandardScaler

Dos formas r√°pidas de ‚Äúajustar el volumen‚Äù.
**Min-Max (0‚Äì1) ‚Üí ‚Äúaprieta y estira‚Äù para que el m√°s chico sea 0 y el m√°s grande 1.**

- Datos limpios y acotados.
- Con outliers se rompe (todo queda aplastado).

**StandardScaler (Z-score) ‚Üí ‚Äúcentra en 0 y ajusta el tama√±o‚Äù.**

- Mejor cuando hay valores raros.
- Suele ayudar a optimizadores basados en gradiente.

![image.png](image%206.png)

# Principal Component Analysis (PCA)

PCA es un resumen inteligente: te deja mirar muchos datos a la vez desde el mejor √°ngulo.

- Visualizar en 2D/3D datos que tienen decenas de columnas.
- Acelerar modelos (menos columnas = menos cuentas).
- Quitar ruido y duplicaciones (variables muy parecidas entre s√≠)

Imagin√° una nube de puntos. Giramos el plano para mirar por la direcci√≥n donde la nube cambia m√°s (PC1). La segunda mejor direcci√≥n, en 90¬∞, es PC2.

![image.png](image%207.png)

**C√≥mo se calcula cada PC**

- Preparar los datos: escal√° y centr√° (media 0) cada columna usando solo TRAIN.
- Buscar la direcci√≥n con m√°s variaci√≥n: el algoritmo mira la nube y encuentra la flecha por donde los puntos est√°n m√°s esparcidos ‚Üí esa es PC1.
- Forzar 90¬∞: ahora busca otra flecha perpendicular (90¬∞) que capture la mayor variaci√≥n restante ‚Üí PC2.
- Repite para PC3, PC4, ‚Ä¶ siempre en 90¬∞ con las anteriores (por eso las PCs son
independientes entre s√≠).

# **PCA: Varianza explicada**

‚Äúvarianza explicada‚Äù = qu√© porcentaje del dibujo original conserva tu resumen.

¬øContra qu√© datos se calcula? Contra los datos usados para entrenar el PCA
(normalizados/centrados). No contra todo el dataset: primero fit en TRAIN, luego transform
en VALID/TEST (para evitar leakage).

**C√≥mo se mide (idea simple):**

- Cada PC trae un valor de varianza (cu√°nto ‚Äúcuenta‚Äù).
- El ratio de cada PC = varianza de esa PC / varianza total.
- La acumulada te dice cu√°nta info llev√°s con las primeras k PCs.

¬øCon cu√°ntos componentes? Reglas pr√°cticas

- Visualizar: 2‚Äì3 PCs (solo para mirar).
- Compactar/Acelerar: eleg√≠ k tal que la acumulada sea 90‚Äì95%

# Selecci√≥n de atributos

PCA hace un resumen mezclando columnas; la selecci√≥n de atributos elige las
mejores columnas y descarta el resto.

- Filtro (r√°pidos): quit√° columnas casi constantes (variance threshold) y columnas duplicadas/muy correlacionadas.
- Wrappers (prueba y error): el modelo te dice qu√© conviene.
    - Forward: empez√°s con 0 y vas sumando columnas.
    - Backward: empez√°s con todas y vas sacando.
    - Us√° una m√©trica para decidir
- Embebidos (lo decide el modelo):
    - L1/Lasso: deja varias en cero (se ‚Äúapagan‚Äù).
    - √Årboles/Random Forest: traen importancia de variables.
    - Permutation importance: med√≠ cu√°nto empeora si desorden√°s una columna.

# Clustering =/= Clasificaci√≥n

- Supervisado = examen con respuestas (entren√°s con etiquetas).
- No supervisado = explor√°s y busc√°s grupos sin respuestas.
- En clustering no hay ‚Äúverdad‚Äù: hay segmentos √∫tiles.
- M√©tricas internas (Silhouette) ayudan, pero negocio manda.

# K-Means: espacio, posici√≥n y distancia

![image.png](image%208.png)

**¬øQu√© es el espacio?**

- Pens√° que cada columna (ya escalada) es un eje.
- Si ten√©s 3 columnas (Edad, Ingresos, Tiempo), viv√≠s en un espacio 3D. Con
20 columnas, es 20D (no lo vemos, pero existe matem√°ticamente).

**¬øQu√© significa la posici√≥n de un punto?**

- Es simplemente su vector de valores en esos ejes: x = [edad_est, ingresos_est, tiempo_est, ‚Ä¶].
- Por eso escalar es clave: si un eje tiene n√∫meros gigantes, domina la
posici√≥n y las distancias.

**¬øQu√© es el centroide?**

- Es el promedio componente a componente de los puntos del cluster:
    - Œº = mean( x‚ÇÅ, x‚ÇÇ, ‚Ä¶, x_n ).
- Intuici√≥n: el punto ‚Äút√≠pico‚Äù del grupo.

**¬øC√≥mo mide la distancia?**

- K-Means cl√°sico usa distancia eucl√≠dea (la de regla): ‚Äúqu√© tan lejos‚Äù est√° el punto del centroide sumando cuadraditos en cada eje.
- El objetivo que minimiza es la suma de distancias al cuadrado (SSE).
Por eso el mejor centroide resulta ser el promedio (no la mediana)
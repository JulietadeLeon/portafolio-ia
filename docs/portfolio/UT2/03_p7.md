---
title: "PrÃ¡ctica 7"
date: 2025-01-01
---

# **PrÃ¡ctica 7: De PerceptrÃ³n a Redes Neuronales **

- [Consigna](https://juanfkurucz.com/ucu-ia/ut2/07-mlp-activaciones/)
- [Google Colab](https://colab.research.google.com/drive/1ubhaRX7filwbMSQUu8Wl0gaFBTmuKQvQ?usp=sharing)

## **Objetivos de Aprendizaje**

- Descubrir las limitaciones del perceptrÃ³n simple (problema XOR)
- Resolver problemas reales con redes multicapa (sklearn MLP)
- Implementar redes neuronales profesionales (TensorFlow/PyTorch Lightning)
- Entender cuÃ¡ndo usar cada herramienta

---

# **PARTE 1: Conceptos Interactivos**

## **Actividad Interactiva: "Explorando el PerceptrÃ³n"**

## **Setup SÃºper RÃ¡pido**

---

## **Paso 1: Resolver AND**

**ğŸ’¡ PISTAS:**

- ğŸ”—Â [FunciÃ³n PerceptrÃ³n](https://en.wikipedia.org/wiki/Perceptron)Â â†’ para AND: solo (1,1) debe activar
- ğŸ”¢Â `bias = _______`Â â†’ -0.7 permite que solo cuando w1*1 + w2*1 â‰¥ 0.7

![.](../../assets/image_UT2_p7_1.png)

![.](../../assets/image_UT2_p7_2.png)

![.](../../assets/image_UT2_p7_3.png)

## Paso 2: Resolver OR

![.](../../assets/image_UT2_p7_4.png)
![.](../../assets/image_UT2_p7_5.png)

![.](../../assets/image_UT2_p7_6.png)

## **Paso 3: Resolver NOT**

![.](../../assets/image_UT2_p7_7.png)

![.](../../assets/image_UT2_p7_8.png)

![.](../../assets/image_UT2_p7_9.png)

## **Paso 4: XOR**

![.](../../assets/image_UT2_p7_10.png)

![.](../../assets/image_UT2_p7_11.png)

![.](../../assets/image_UT2_p7_12.png)

---

# **PARTE 2: Herramientas Reales**

## Actividad 1: Sklearn MLP

## Resolver XOR con MLP

![.](../../assets/image_UT2_p7_13.png)

## **Visualizar la Arquitectura de Red MLP**

![.](../../assets/image_UT2_p7_14.png)

ğŸ“Š Capa 1: 2 â†’ 2 = 6 parÃ¡metros
ğŸ“Š Capa 2: 2 â†’ 1 = 3 parÃ¡metros
ğŸ¯ Total de parÃ¡metros: 9
ğŸ§  Â¿Por quÃ© tantos parÃ¡metros? Cada conexiÃ³n tiene un peso + bias por neurona

## **Visualizar Superficie de DecisiÃ³n**

![.](../../assets/image_UT2_p7_15.png)

ğŸ” ANÃLISIS VISUAL:
ğŸ”´ Zonas ROJAS = predicciÃ³n 0 (clase 0)
ğŸ”µ Zonas AZULES = predicciÃ³n 1 (clase 1)
ğŸ“ PerceptrÃ³n: Solo puede crear lÃ­nea recta â†’ falla en XOR
ğŸŒŠ MLP: Puede crear superficie curva â†’ Â¡resuelve XOR!

## **Dataset Real con MLP**

ğŸ“Š Resultados MLP en dataset real:
Training Accuracy: 100.0%
Test Accuracy: 90.3%
Arquitectura: 20 â†’ (64, 32) â†’ 2

## **Actividad 2: TensorFlow - Red Profesional**

## **Red Neuronal con TensorFlow**

ğŸ¯ Resultados TensorFlow:
Training Accuracy: 99.9%
Test Accuracy: 92.7%
ParÃ¡metros totales: 3,457

## **Visualizar Entrenamiento**

![.](../../assets/image_UT2_p7_16.png)

## **PyTorch Lightning (Bonus)**

ğŸ¯ PyTorch Lightning model created!
Input features: 20
Parameters: 3,490

## **Entrenar PyTorch Lightning**

![.](../../assets/image_UT2_p7_17.png)

## **VisualizaciÃ³n de Matriz de ConfusiÃ³n**

![.](../../assets/image_UT2_p7_18.png)

ğŸ“ˆ ANÃLISIS DE MATRICES DE CONFUSIÃ“N:
âœ… Diagonal principal (TN + TP) = predicciones correctas
âŒ Diagonal secundaria (FP + FN) = errores

# **Preguntas de ReflexiÃ³n**

**1. Â¿Por quÃ© AND, OR y NOT funcionaron pero XOR no?**

ğŸ‘‰ Porque **XOR no es linealmente separable**. No podÃ©s trazar una sola lÃ­nea recta en el plano que separe los ceros de los unos. AND, OR y NOT sÃ­.

---

**2. Diferencia clave entre los pesos de AND vs OR**

ğŸ‘‰ En **AND** el umbral es mÃ¡s alto: se necesitan *ambas entradas* activas para pasar.

ğŸ‘‰ En **OR** el umbral es mÃ¡s bajo: con *una sola* entrada basta.

---

**3. Problemas reales como XOR**

ğŸ‘‰ Situaciones de â€œesto o aquello, pero no ambosâ€:

- Un semÃ¡foro que debe estar verde *o* rojo, pero no los dos.
- Detectar si exactamente uno de dos sensores se activa.
- Sistemas de alarma donde debe sonar solo si un detector u otro, pero no ambos, disparan al mismo tiempo.

---

**4. Â¿Por quÃ© sklearn MLP resuelve XOR pero un perceptrÃ³n no?**

ğŸ‘‰ Un perceptrÃ³n dibuja **una lÃ­nea de decisiÃ³n**.

ğŸ‘‰ Un MLP puede combinar **varias lÃ­neas de decisiÃ³n** en capas ocultas y asÃ­ separar regiones no lineales como XOR.

---

**5. Diferencia principal entre TensorFlow/Keras y sklearn MLP**

ğŸ‘‰ `sklearn` te da un **MLP sencillo y de alto nivel** para usar como cualquier otro modelo de scikit-learn.

ğŸ‘‰ `TensorFlow/Keras` te da **control total** sobre arquitectura, optimizaciÃ³n, callbacks, GPUs, etc.

---

**6. Â¿Por quÃ© TensorFlow usa `epochs` y `batch_size` mientras sklearn MLP no?**

ğŸ‘‰ Porque **TensorFlow entrena en lotes (mini-batch gradient descent)** y permite configurar explÃ­citamente las Ã©pocas.

ğŸ‘‰ En `sklearn`, el MLP entrena internamente y abstrae esos detalles, tratÃ¡ndolo como un estimador mÃ¡s.

---

**7. Â¿CuÃ¡ndo usarÃ­as sigmoid vs relu como funciÃ³n de activaciÃ³n?**

ğŸ‘‰ **Sigmoid**: salida binaria, porque produce valores entre 0 y 1 (probabilidades).

ğŸ‘‰ **ReLU**: capas ocultas, porque evita saturaciÃ³n, acelera convergencia y maneja mejor gradientes.

---

**8. Ventaja de PyTorch Lightning sobre TensorFlow puro**

ğŸ‘‰ PyTorch Lightning **reduce el boilerplate**: separa claramente entrenamiento, validaciÃ³n y test, dejando el cÃ³digo limpio y mÃ¡s fÃ¡cil de mantener.

---

**9. Â¿Por quÃ© PyTorch Lightning separa `training_step` y `test_step`?**

ğŸ‘‰ Porque en **entrenamiento** calculÃ¡s gradientes y optimizÃ¡s, mientras que en **test/validaciÃ³n** solo medÃ­s rendimiento sin actualizar pesos.

---

**10. Framework ideal en cada escenario**

- **Prototipo rÃ¡pido:** `sklearn MLP` (simple y directo).
- **Modelo en producciÃ³n:** `TensorFlow/Keras` (soporte industrial, despliegue en mÃ³viles/servidores).
- **InvestigaciÃ³n avanzada:** `PyTorch Lightning` (flexible, limpio y usado en papers).

---

**11. Error â€œmat1 and mat2 shapes cannot be multipliedâ€ en PyTorch**

ğŸ‘‰ Aparece cuando las dimensiones de entrada **no coinciden con los pesos de la primera capa** (`input_features`). TenÃ©s que asegurarte que `X.shape[1] == nn.Linear(input_size, ...)`.

---

**12. Â¿QuÃ© significa `deterministic=True` en PyTorch Lightning?**

ğŸ‘‰ Que **los resultados son reproducibles**: fija semillas y desactiva operaciones aleatorias no deterministas, para que cada corrida dÃ© los mismos nÃºmeros.

---

**13. Â¿Por quÃ© TensorFlow muestra curvas de `loss` y `val_loss` durante entrenamiento?**

ğŸ‘‰ Para **detectar overfitting visualmente**: si la pÃ©rdida de entrenamiento sigue bajando pero la de validaciÃ³n sube, tu modelo se estÃ¡ sobreajustando.

---

**14. Diferencia entre `trainer.test()` y `trainer.predict()` en PyTorch Lightning**

ğŸ‘‰ `trainer.test()`: evalÃºa el modelo y devuelve **mÃ©tricas** (loss, accuracy, etc).

ğŸ‘‰ `trainer.predict()`: solo devuelve **predicciones** (sin mÃ©tricas).

---

**15. Â¿Por quÃ© sklearn MLP es mÃ¡s fÃ¡cil pero menos flexible?**

ğŸ‘‰ Porque abstrae todo en un **estimador de alto nivel** (fit, predict), pero **no te deja controlar** arquitectura detallada, optimizadores, callbacks o GPUs.

# ğŸš€Â **DESAFÃOS ADICIONALES: Â¡Ve MÃ¡s AllÃ¡!**[Â¶](https://juanfkurucz.com/ucu-ia/ut2/07-mlp-activaciones/#desafios-adicionales-ve-mas-alla)

### ğŸ“ŠÂ **Datasets para Experimentar**[Â¶](https://juanfkurucz.com/ucu-ia/ut2/07-mlp-activaciones/#datasets-para-experimentar)

- **CÃ­rculos concÃ©ntricos**:Â `make_circles()`Â - visualizar limitaciones del perceptrÃ³n
- **Medias lunas**:Â `make_moons()`Â - comparar superficies de decisiÃ³n
- **MNIST dÃ­gitos**:Â `load_digits()`Â - clasificaciÃ³n multi-clase (10 clases)
- **Vinos**:Â `load_wine()`Â - problema de 3 clases
- **CÃ¡ncer de mama**:Â `load_breast_cancer()`Â - problema mÃ©dico real
- **Titanic**:Â [Kaggle](https://www.kaggle.com/c/titanic)Â - supervivencia
- **Fashion MNIST**: TensorFlow datasets - clasificar ropa
- **California Housing**: regresiÃ³n de precios

### ğŸ§ªÂ **Experimentos Avanzados**[Â¶](https://juanfkurucz.com/ucu-ia/ut2/07-mlp-activaciones/#experimentos-avanzados)

- **Arquitecturas**: Comparar (4,), (10,), (4,4), (10,5), (64,32,16)
- **Activaciones**: Probar 'relu', 'tanh', 'logistic'
- **RegularizaciÃ³n**: Agregar Dropout (0.2, 0.3, 0.5)
- **Optimizadores**: Comparar 'adam', 'sgd', 'rmsprop'
- **MÃ©tricas**: accuracy, precision, recall, F1-score

### ğŸ“šÂ **Recursos para Profundizar**[Â¶](https://juanfkurucz.com/ucu-ia/ut2/07-mlp-activaciones/#recursos-para-profundizar)

- **DocumentaciÃ³n**:Â [Sklearn](https://scikit-learn.org/stable/),Â [TensorFlow](https://www.tensorflow.org/tutorials),Â [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/)
- **Herramientas**: W&B, TensorBoard, MLflow
- **Interactivo**:Â [TensorFlow Playground](https://playground.tensorflow.org/)
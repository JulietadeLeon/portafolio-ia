---
title: "Lecturas"
date: 2025-01-01
---

# Aprendizajes al completar UT2: 

â€¢ Comprender la arquitectura de perceptrones multicapa y funciones de activaciÃ³n

â€¢ Desarrollar MLPs avanzados usando PyTorch Lightning para aplicaciones reales

â€¢ Aplicar tÃ©cnicas de optimizaciÃ³n (SGD, AdamW) y entender backpropagation

â€¢ Implementar tÃ©cnicas de regularizaciÃ³n y visualizaciÃ³n con TensorBoard/Mlflow

â€¢ Experimentar con optimizadores avanzados y learning rate scheduling

# Lecturas

## **Lecturas minimas (Evaluacion el 16/09):**

### **Kaggle Intro to Deep Learning (Completo):**

- [A Single Neuron](https://www.kaggle.com/code/ryanholbrook/a-single-neuron)
- [Deep Neural Networks](https://www.kaggle.com/code/ryanholbrook/deep-neural-networks)
- [Stochastic Gradient Descent](https://www.kaggle.com/code/ryanholbrook/stochastic-gradient-descent)
- [Binary Classification](https://www.kaggle.com/code/ryanholbrook/binary-classification)
- [Dropout and Batch Normalization](https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization)
- [Overfitting and Underfitting](https://www.kaggle.com/code/ryanholbrook/overfitting-and-underfitting)

### **Google Deep Learning:**

- [Neural Networks Course](https://developers.google.com/machine-learning/guides/deep-learning-tuning-playbook)

### **PyTorch Lightning:**

- [PyTorch Lightning Documentation](https://lightning.ai/docs/pytorch/stable/)
- [Getting Started Guide](https://lightning.ai/docs/pytorch/stable/starter/introduction.html)

## **Lecturas totales:**

### **Kaggle Intro to Deep Learning (Completo):**

- [A Single Neuron](https://www.kaggle.com/code/ryanholbrook/a-single-neuron)
- [Deep Neural Networks](https://www.kaggle.com/code/ryanholbrook/deep-neural-networks)
- [Stochastic Gradient Descent](https://www.kaggle.com/code/ryanholbrook/stochastic-gradient-descent)
- [Binary Classification](https://www.kaggle.com/code/ryanholbrook/binary-classification)
- [Dropout and Batch Normalization](https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization)
- [Overfitting and Underfitting](https://www.kaggle.com/code/ryanholbrook/overfitting-and-underfitting)

### **Google Deep Learning:**

- [Neural Networks Course](https://developers.google.com/machine-learning/guides/deep-learning-tuning-playbook)
- [Deep Learning Tuning Playbook](https://developers.google.com/machine-learning/guides/deep-learning-tuning-playbook)

### **PyTorch Ecosystem:**

- [PyTorch Lightning Documentation](https://lightning.ai/docs/pytorch/stable/)
- [Getting Started Guide](https://lightning.ai/docs/pytorch/stable/starter/introduction.html)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [TensorBoard Documentation](https://www.tensorflow.org/tensorboard)

## **Herramientas:**

### **Fundamentals:**

- NumPy Documentation:Â https://numpy.org/doc/stable/
- PyTorch Documentation:Â https://pytorch.org/docs/stable/index.html
- PyTorch Lightning:Â https://lightning.ai/docs/pytorch/stable/

### **OptimizaciÃ³n:**

- PyTorch Optimizers:Â https://pytorch.org/docs/stable/optim.html
- Learning Rate Scheduling:Â https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate

### **VisualizaciÃ³n:**

- TensorBoard Documentation:Â https://www.tensorflow.org/tensorboard
- Matplotlib Documentation:Â https://matplotlib.org/stable/contents.html

### **Data Handling:**

- PyTorch DataLoader:Â https://pytorch.org/docs/stable/data.html
- PyTorch Transforms:Â https://pytorch.org/vision/stable/transforms.html


# Resumen lecturas mÃ­nimas
# **Kaggle Intro to Deep Learning:**

## [A Single Neuron](https://www.kaggle.com/code/ryanholbrook/a-single-neuron)

## ğŸ“Œ Resumen general

El notebook explica cÃ³mo funciona una neurona artificial:

- Recibe **entradas (features)**.
- Multiplica cada entrada por un **peso**.
- Suma todo y le agrega un **sesgo (bias)**.
- Pasa el resultado por una **funciÃ³n de activaciÃ³n** que introduce no linealidad.

MatemÃ¡ticamente, la operaciÃ³n de una neurona se puede expresar como:

y=f(w1x1+w2x2+â‹¯+wnxn+b)y = f(w_1x_1 + w_2x_2 + \dots + w_nx_n + b)

y=f(w1x1+w2x2+â‹¯+wnxn+b)

donde:

- xix_ixi = caracterÃ­stica de entrada,
- wiw_iwi = peso asociado,
- bbb = bias,
- fff = funciÃ³n de activaciÃ³n,
- yyy = salida de la neurona.

---

## ğŸ“– Conceptos desarrollados en el notebook

### 1. **Features (CaracterÃ­sticas de entrada)**

Son las variables de entrada que describen a un ejemplo de datos.

Ejemplo: para predecir el precio de una casa, podrÃ­an ser tamaÃ±o, nÃºmero de habitaciones, ubicaciÃ³n.

En la neurona, cada feature se multiplica por un peso.

---

### 2. **Pesos (Weights)**

Son los parÃ¡metros que la red aprende durante el entrenamiento.

Indican cuÃ¡nto contribuye cada feature en la predicciÃ³n.

- Si un peso es grande y positivo â†’ la feature aumenta el valor de salida.
- Si es negativo â†’ lo disminuye.

---

### 3. **Sesgo (Bias)**

Es un valor adicional que desplaza la salida de la neurona.

Permite que la red se ajuste incluso cuando todas las features valen 0.

ğŸ‘‰ Es como un intercepto en una regresiÃ³n lineal.

---

### 4. **FunciÃ³n de activaciÃ³n**

Clave para introducir **no linealidad**.

Sin activaciÃ³n, la neurona serÃ­a solo una regresiÃ³n lineal.

Algunas funciones comunes:

- **ReLU (Rectified Linear Unit):** devuelve 0 si la entrada es negativa, y la entrada misma si es positiva. Muy usada en deep learning.
- **Sigmoid:** convierte la salida en un valor entre 0 y 1. Ãštil para clasificaciÃ³n binaria.
- **tanh:** valores entre -1 y 1.

---

### 5. **ComposiciÃ³n de neuronas â†’ Red Neuronal**

El notebook seÃ±ala que si apilamos muchas neuronas y varias capas, obtenemos una **red neuronal profunda**.

Cada capa transforma la representaciÃ³n de los datos.

---

### 6. **AnalogÃ­a biolÃ³gica**

Se menciona la inspiraciÃ³n en el cerebro humano:

- Las neuronas biolÃ³gicas reciben seÃ±ales a travÃ©s de dendritas.
- Procesan esas seÃ±ales y transmiten impulsos elÃ©ctricos a otras neuronas.
- En una red neuronal artificial, las conexiones se representan con pesos.

---

### 7. **Ejemplo prÃ¡ctico en Keras**

El notebook muestra cÃ³mo implementar una red neuronal de **una sola neurona** usando Keras:

```python
from tensorflow import keras
from tensorflow.keras import layers

# Modelo secuencial con una sola capa densa (una neurona)
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[3])
])

```

- `Dense(units=1)` â†’ define una capa totalmente conectada con 1 neurona.
- `input_shape=[3]` â†’ indica que la entrada tiene 3 features.

El modelo calcula:

output=f(w1x1+w2x2+w3x3+b)output = f(w_1x_1 + w_2x_2 + w_3x_3 + b)

output=f(w1x1+w2x2+w3x3+b)

---

### 8. **Entrenamiento de la neurona**

La neurona no "sabe" los pesos inicialmente, se entrenan con un **algoritmo de optimizaciÃ³n** (descenso de gradiente).

- El modelo predice un valor.
- Se mide el error (funciÃ³n de pÃ©rdida).
- Se ajustan los pesos para minimizar ese error.

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œA Single Neuronâ€** es una introducciÃ³n al bloque fundamental de cualquier red neuronal: la **neurona artificial**.

- Explica las piezas bÃ¡sicas: features, pesos, bias, activaciÃ³n.
- Da intuiciÃ³n matemÃ¡tica y biolÃ³gica.
- Muestra un ejemplo prÃ¡ctico en Keras.
- Prepara el terreno para entender redes mÃ¡s profundas en el siguiente notebook.

## [Deep Neural Networks](https://www.kaggle.com/code/ryanholbrook/deep-neural-networks)

## ğŸ“Œ Resumen general

En este notebook se pasa de la **neurona Ãºnica** al concepto de **red neuronal profunda** (*deep neural network*).

La idea es:

- En lugar de tener una sola neurona que aprende una funciÃ³n lineal, usamos varias capas de neuronas.
- Esto permite que el modelo **aprenda representaciones mÃ¡s complejas y no lineales** de los datos.
- Introduce conceptos como **capas ocultas, funciones de activaciÃ³n, arquitectura de la red y Keras Sequential API**.

---

## ğŸ“– Conceptos desarrollados

### 1. **Capa oculta (Hidden Layer)**

- Una capa que no es ni de entrada ni de salida.
- Toma los valores de la capa anterior, los transforma mediante pesos, bias y funciÃ³n de activaciÃ³n, y los pasa a la siguiente.
- Cada capa oculta aprende representaciones intermedias de los datos.

ğŸ‘‰ Ejemplo:

- Entrada: tamaÃ±o de la casa, nÃºmero de habitaciones.
- Capa oculta: puede aprender â€œnivel de lujoâ€.
- Otra capa: puede aprender â€œprecio esperadoâ€.

---

### 2. **Profundidad de la red (Deep)**

- Una red se considera â€œprofundaâ€ si tiene **mÃ¡s de una capa oculta**.
- Cada capa puede captar **patrones mÃ¡s abstractos**.
- Cuantas mÃ¡s capas â†’ mÃ¡s capacidad de aprendizaje, pero tambiÃ©n mÃ¡s riesgo de **overfitting** y mayor dificultad en entrenamiento.

---

### 3. **Funciones de activaciÃ³n**

Ya vistas en â€œSingle Neuronâ€, pero aquÃ­ se destaca la importancia de usar funciones no lineales en capas ocultas:

- **ReLU (Rectified Linear Unit):** la mÃ¡s comÃºn en deep learning, permite que la red aprenda relaciones no lineales.
- Sin activaciones, incluso una red profunda serÃ­a equivalente a una regresiÃ³n lineal.

---

### 4. **Arquitectura de la red**

- Especifica:
    - NÃºmero de capas ocultas.
    - NÃºmero de neuronas por capa.
    - FunciÃ³n de activaciÃ³n usada en cada capa.
- No hay una Ãºnica regla fija â†’ depende de la complejidad de los datos y del problema.

---

### 5. **ImplementaciÃ³n en Keras**

El notebook enseÃ±a a construir una red con varias capas usando **`Sequential`**:

```python
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(units=512, activation="relu", input_shape=[784]),
    layers.Dense(units=256, activation="relu"),
    layers.Dense(units=10, activation="softmax")
])

```

- `Dense(units, activation)` â†’ crea una capa densa con nÃºmero de neuronas = `units`.
- `input_shape=[784]` â†’ define la forma de la entrada (ejemplo clÃ¡sico: imÃ¡genes MNIST de 28x28 = 784 pixeles).
- Primera capa oculta: 512 neuronas con ReLU.
- Segunda capa oculta: 256 neuronas con ReLU.
- Capa de salida: 10 neuronas con **softmax** (para clasificaciÃ³n multiclase).

---

### 6. **Softmax en la capa de salida**

- Convierte las salidas en probabilidades.
- La suma de todas las probabilidades es = 1.
- Se usa para problemas de clasificaciÃ³n multiclase.

---

### 7. **Expresividad de las redes profundas**

- TeÃ³ricamente, una red con una sola capa oculta y suficientes neuronas puede aproximar cualquier funciÃ³n (Teorema de aproximaciÃ³n universal).
- Pero en la prÃ¡ctica, **varias capas pequeÃ±as suelen ser mÃ¡s eficientes** que una sola capa enorme.
- Las capas sucesivas **aprenden jerarquÃ­as de representaciÃ³n**:
    - Capas bajas: patrones simples (bordes en imÃ¡genes).
    - Capas medias: combinaciones de patrones (formas).
    - Capas altas: conceptos mÃ¡s abstractos (caras, nÃºmeros).

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œDeep Neural Networksâ€** introduce la idea de **profundidad**:

- MÃ¡s capas y neuronas permiten que la red aprenda funciones mÃ¡s complejas.
- La clave estÃ¡ en elegir bien la arquitectura (nÃºmero de capas, neuronas y activaciones).
- Muestra cÃ³mo implementar estas redes en **Keras** de forma simple con `Sequential` y `Dense`.

ğŸ‘‰ Este paso conecta el modelo mÃ¡s simple (una sola neurona) con arquitecturas capaces de resolver problemas reales como **clasificaciÃ³n de imÃ¡genes o texto**.

## [Stochastic Gradient Descent](https://www.kaggle.com/code/ryanholbrook/stochastic-gradient-descent)

## ğŸ“Œ Resumen general

Este notebook explica **cÃ³mo aprenden las redes neuronales**.

El foco estÃ¡ en el **algoritmo de optimizaciÃ³n mÃ¡s usado en deep learning: Stochastic Gradient Descent (SGD)**.

- El objetivo es **ajustar los pesos y bias** de la red para minimizar el error.
- Se introduce la **funciÃ³n de pÃ©rdida (loss function)** como medida del error.
- Se explica cÃ³mo el **gradiente** indica la direcciÃ³n de mayor descenso de la pÃ©rdida.
- Se diferencia entre **batch gradient descent, mini-batch y stochastic**.

---

## ğŸ“– Conceptos desarrollados

### 1. **FunciÃ³n de pÃ©rdida (Loss Function)**

- Mide la diferencia entre la predicciÃ³n del modelo y el valor real.
- El entrenamiento busca **minimizar la pÃ©rdida**.
- Ejemplos:
    - **MSE (Mean Squared Error):** para regresiÃ³n.
    - **Cross-Entropy Loss:** para clasificaciÃ³n.

ğŸ‘‰ Una buena elecciÃ³n de loss depende del tipo de problema.

---

### 2. **Descenso de gradiente (Gradient Descent)**

- MÃ©todo matemÃ¡tico para encontrar el mÃ­nimo de una funciÃ³n.
- Idea: mover los parÃ¡metros www en la direcciÃ³n contraria al gradiente de la funciÃ³n de pÃ©rdida.

wnuevo=wviejoâˆ’Î·â‹…âˆ‡L(w)w_{nuevo} = w_{viejo} - \eta \cdot \nabla L(w)

wnuevo=wviejoâˆ’Î·â‹…âˆ‡L(w)

donde:

- Î·\etaÎ· = learning rate (tasa de aprendizaje),
- âˆ‡L(w)\nabla L(w)âˆ‡L(w) = gradiente de la pÃ©rdida respecto a los pesos.

---

### 3. **Learning Rate (Tasa de aprendizaje)**

- HiperparÃ¡metro clave.
- Define quÃ© tan grandes son los pasos en cada actualizaciÃ³n.
    - Muy alto â†’ saltos grandes, el modelo no converge.
    - Muy bajo â†’ avanza muy lento, puede atascarse en mÃ­nimos locales.

---

### 4. **Batch Gradient Descent**

- Calcula el gradiente usando **todos los datos del dataset** en cada paso.
- Ventaja: cÃ¡lculo exacto del gradiente.
- Desventaja: muy lento y costoso con grandes datasets.

---

### 5. **Stochastic Gradient Descent (SGD)**

- Usa **un solo ejemplo** para calcular el gradiente en cada paso.
- Ventaja: rÃ¡pido y mÃ¡s eficiente con datasets grandes.
- Desventaja: mÃ¡s â€œruidosoâ€, la pÃ©rdida fluctÃºa en lugar de disminuir suavemente.
- Este ruido puede ser positivo â†’ ayuda a escapar de mÃ­nimos locales.

---

### 6. **Mini-Batch Gradient Descent**

- Compromiso entre batch y SGD.
- Calcula el gradiente con un **subconjunto pequeÃ±o (mini-batch)** de ejemplos.
- Es el mÃ©todo mÃ¡s usado en prÃ¡ctica.

---

### 7. **ImplementaciÃ³n en Keras**

El notebook muestra cÃ³mo definir el optimizador al compilar el modelo:

```python
from tensorflow import keras
from tensorflow.keras import layers

# Modelo simple
model = keras.Sequential([
    layers.Dense(units=1, input_shape=[3])
])

# Compilar con SGD
model.compile(
    optimizer=keras.optimizers.SGD(learning_rate=0.01),
    loss="mean_squared_error"
)

```

- `optimizer=SGD` â†’ usa descenso de gradiente estocÃ¡stico.
- `learning_rate=0.01` â†’ define el tamaÃ±o de los pasos.
- `loss="mse"` â†’ mide el error entre predicciones y valores reales.

---

### 8. **Curvas de entrenamiento**

- El notebook suele mostrar cÃ³mo evoluciona la **pÃ©rdida (loss)** durante el entrenamiento.
- Con learning rate adecuado â†’ la pÃ©rdida disminuye suavemente.
- Con learning rate inadecuado â†’ puede oscilar demasiado o no mejorar.

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œStochastic Gradient Descentâ€** enseÃ±a el mecanismo central del entrenamiento:

- Definir una funciÃ³n de pÃ©rdida.
- Usar gradientes para ajustar pesos y bias.
- Diferenciar entre **batch, stochastic y mini-batch gradient descent**.
- Entender el rol crÃ­tico del **learning rate**.

ğŸ‘‰ Este paso conecta la teorÃ­a de las neuronas con el **proceso real de aprendizaje automÃ¡tico**.

## [Binary Classification](https://www.kaggle.com/code/ryanholbrook/binary-classification)

## ğŸ“Œ Resumen general

Este notebook muestra cÃ³mo aplicar una red neuronal al problema de **clasificaciÃ³n binaria** (dos clases posibles, ej. â€œsÃ­/noâ€, â€œspam/no spamâ€).

Los puntos clave son:

- CÃ³mo se formula la salida para que represente una **probabilidad**.
- QuÃ© **funciÃ³n de pÃ©rdida** se usa en clasificaciÃ³n binaria.
- CÃ³mo interpretar la mÃ©trica **accuracy**.
- CÃ³mo usar **sigmoid en la salida** y **binary cross-entropy** como pÃ©rdida.

---

## ğŸ“– Conceptos desarrollados

### 1. **ClasificaciÃ³n binaria**

- Problema donde la etiqueta solo puede ser **0 o 1**.
- Ejemplos:
    - Â¿Un email es spam?
    - Â¿Una imagen es gato o no?
    - Â¿Un cliente cancelarÃ¡ su suscripciÃ³n?

---

### 2. **Unidad de salida con activaciÃ³n sigmoide**

- Se usa una **sola neurona de salida**.
- Su activaciÃ³n es **sigmoid** para producir valores en [0,1][0,1][0,1].
- Ese valor se interpreta como la **probabilidad de que la clase sea 1**.
- DecisiÃ³n final: aplicar un **umbral**, tÃ­picamente 0.5.

---

### 3. **FunciÃ³n de pÃ©rdida: Binary Cross-Entropy (Log Loss)**

- Mide cuÃ¡n buena es la predicciÃ³n de probabilidades.
- FÃ³rmula:

L(y,y^)=âˆ’[yâ‹…logâ¡(y^)+(1âˆ’y)â‹…logâ¡(1âˆ’y^)]L(y, \hat{y}) = - \big[ y \cdot \log(\hat{y}) + (1-y) \cdot \log(1-\hat{y}) \big]

L(y,y^)=âˆ’[yâ‹…log(y^)+(1âˆ’y)â‹…log(1âˆ’y^)]

donde:

- yyy = etiqueta real (0 o 1),
- y^\hat{y}y^ = probabilidad predicha.

ğŸ‘‰ Penaliza mucho si el modelo asigna **baja probabilidad a la clase correcta**.

---

### 4. **MÃ©trica: Accuracy**

- Accuracy = proporciÃ³n de ejemplos bien clasificados.
- Se obtiene comparando la predicciÃ³n umbralizada (ej. y^>0.5\hat{y} > 0.5y^>0.5) con la etiqueta real.
- Buena como mÃ©trica de desempeÃ±o, pero no sirve como funciÃ³n de pÃ©rdida porque no es diferenciable.

---

### 5. **ImplementaciÃ³n en Keras**

Ejemplo tÃ­pico en el notebook:

```python
from tensorflow import keras
from tensorflow.keras import layers

# Modelo simple para clasificaciÃ³n binaria
model = keras.Sequential([
    layers.Dense(units=16, activation="relu", input_shape=[num_features]),
    layers.Dense(units=1, activation="sigmoid")
])

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

```

- Capa oculta: 16 neuronas con ReLU.
- Capa de salida: 1 neurona con **sigmoid**.
- Loss: **binary_crossentropy**.
- MÃ©trica: **accuracy**.

---

### 6. **InterpretaciÃ³n de la probabilidad**

- La salida de sigmoid puede leerse como:
    - 0.85 â†’ 85% de probabilidad de clase positiva.
    - 0.2 â†’ 20% de probabilidad de clase positiva.
- Luego se aplica un umbral para convertirlo en una clase.

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œBinary Classificationâ€** muestra la forma estÃ¡ndar de resolver un problema de 2 clases con deep learning:

- **Una sola salida con sigmoid.**
- **PÃ©rdida = binary cross-entropy.**
- **MÃ©trica = accuracy.**

ğŸ‘‰ Prepara el camino para problemas de clasificaciÃ³n mÃ¡s complejos, como **multiclase con softmax**.

## [Dropout and Batch Normalization](https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization)

## ğŸ“Œ Resumen general

Este notebook introduce **dos tÃ©cnicas clave** para mejorar el entrenamiento de redes profundas:

1. **Dropout** â†’ regularizaciÃ³n que previene **overfitting** apagando neuronas al azar durante el entrenamiento.
2. **Batch Normalization (BatchNorm)** â†’ normaliza activaciones dentro de cada capa para estabilizar y acelerar el entrenamiento.

Ambas tÃ©cnicas ayudan a que la red **generalice mejor** y sea mÃ¡s **estable**.

---

## ğŸ“– Conceptos desarrollados

### 1. **Overfitting**

- Problema cuando la red se ajusta demasiado al set de entrenamiento y pierde capacidad de generalizar.
- Dropout y BatchNorm son herramientas para combatirlo.

---

### 2. **Dropout**

- TÃ©cnica de regularizaciÃ³n propuesta por Hinton (2014).
- Durante el entrenamiento, cada neurona tiene una **probabilidad ppp** de ser â€œapagadaâ€ (output = 0).
- Esto fuerza a la red a no depender de neuronas individuales y promueve **representaciones mÃ¡s robustas**.
- En inferencia (predicciÃ³n real), no se apagan neuronas: en su lugar, los pesos se escalan para compensar.

ğŸ‘‰ Ejemplo en Keras:

```python
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.3),   # 30% de las neuronas apagadas durante entrenamiento
    layers.Dense(64, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

```

---

### 3. **Batch Normalization**

- Problema: las activaciones en redes profundas pueden volverse inestables (cambian de escala y distribuciÃ³n entre capas).
- SoluciÃ³n: **normalizar** las activaciones dentro de cada mini-batch:

x^=xâˆ’Î¼Ïƒ\hat{x} = \frac{x - \mu}{\sigma}

x^=Ïƒxâˆ’Î¼

donde Î¼\muÎ¼ y Ïƒ\sigmaÏƒ son la media y desviaciÃ³n estÃ¡ndar del batch.

- AdemÃ¡s, BatchNorm introduce parÃ¡metros aprendibles (Î³,Î²\gamma, \betaÎ³,Î²) para re-escalar y desplazar despuÃ©s de la normalizaciÃ³n.
- Beneficios:
    - Acelera el entrenamiento.
    - Permite usar learning rates mÃ¡s altos.
    - Tiene cierto efecto de regularizaciÃ³n.

ğŸ‘‰ Ejemplo en Keras:

```python
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(128, activation="relu"),
    layers.BatchNormalization(),
    layers.Dense(64, activation="relu"),
    layers.BatchNormalization(),
    layers.Dense(1, activation="sigmoid")
])

```

---

### 4. **Diferencias clave**

- **Dropout**: combate directamente el **overfitting** apagando neuronas al azar.
- **BatchNorm**: estabiliza y acelera el **entrenamiento** normalizando activaciones.
- Se pueden usar **juntas** en la misma red.

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œDropout and Batch Normalizationâ€** enseÃ±a dos tÃ©cnicas muy usadas en prÃ¡ctica:

- **Dropout** â†’ previene overfitting al introducir aleatoriedad.
- **BatchNorm** â†’ estabiliza y acelera el entrenamiento al normalizar activaciones.

ğŸ‘‰ Con estas herramientas, las redes profundas se vuelven mÃ¡s **robustas, rÃ¡pidas y generalizables**.

## [Overfitting and Underfitting](https://www.kaggle.com/code/ryanholbrook/overfitting-and-underfitting)

## ğŸ“Œ Resumen general

Este notebook trata uno de los problemas centrales en machine learning y deep learning:

- **Underfitting** â†’ el modelo no aprende lo suficiente.
- **Overfitting** â†’ el modelo aprende demasiado (memoriza el entrenamiento) y no generaliza bien.

Muestra cÃ³mo detectarlos y quÃ© tÃ©cnicas aplicar para mejorar el desempeÃ±o.

---

## ğŸ“– Conceptos desarrollados

### 1. **Underfitting**

- El modelo es **demasiado simple** o no ha entrenado lo suficiente.
- No logra capturar los patrones de los datos.
- SÃ­ntomas:
    - Alto error en entrenamiento y validaciÃ³n.
    - Learning curves que no bajan.

ğŸ‘‰ Causas comunes:

- Muy pocas capas/neuronas.
- Entrenamiento insuficiente (pocas Ã©pocas).
- Learning rate inadecuado.

---

### 2. **Overfitting**

- El modelo es **demasiado complejo** o entrenÃ³ demasiado tiempo.
- Aprende ruido o particularidades del set de entrenamiento.
- SÃ­ntomas:
    - Muy bajo error en entrenamiento.
    - Alto error en validaciÃ³n.
    - Divergencia entre las curvas de entrenamiento y validaciÃ³n.

ğŸ‘‰ Causas comunes:

- Muchas capas/neuronas sin regularizaciÃ³n.
- Dataset muy chico.
- Entrenamiento demasiado largo.

---

### 3. **CÃ³mo diagnosticar: Learning Curves**

- GrÃ¡ficos de **pÃ©rdida/accuracy en entrenamiento y validaciÃ³n**.
- PatrÃ³n tÃ­pico:
    - Underfitting â†’ ambas curvas altas (mal desempeÃ±o en todo).
    - Overfitting â†’ entrenamiento muy bajo, validaciÃ³n alta (divergencia).
    - Buen ajuste â†’ ambas curvas bajas y cercanas.

---

### 4. **TÃ©cnicas para combatir underfitting**

- Usar una **red mÃ¡s grande** (mÃ¡s capas o neuronas).
- Entrenar mÃ¡s tiempo (mÃ¡s Ã©pocas).
- Ajustar el **learning rate**.
- Revisar la arquitectura del modelo.

---

### 5. **TÃ©cnicas para combatir overfitting**

- Usar mÃ¡s **datos de entrenamiento** (data augmentation).
- Aplicar **regularizaciÃ³n**:
    - Dropout.
    - L1/L2 penalties.
- Usar **Batch Normalization**.
- Parar antes de que empiece a memorizar (**early stopping**).

---

### 6. **ImplementaciÃ³n en Keras**

Ejemplo clÃ¡sico del notebook:

```python
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(64, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

```

- Dropout ayuda a controlar el overfitting.
- Early stopping se puede agregar con callbacks:

```python
early_stopping = keras.callbacks.EarlyStopping(
    patience=5,
    restore_best_weights=True
)

```

---

## ğŸš€ ConclusiÃ³n

El notebook **â€œOverfitting and Underfittingâ€** cierra la introducciÃ³n mostrando cÃ³mo lograr el balance ideal:

- **Underfitting** â†’ modelo demasiado simple o poco entrenado.
- **Overfitting** â†’ modelo demasiado complejo o entrenado de mÃ¡s.
- La clave estÃ¡ en usar tÃ©cnicas de **regularizaciÃ³n, early stopping y buen diseÃ±o de arquitectura** para alcanzar un punto de generalizaciÃ³n Ã³ptimo.

---

## ğŸ§  **Mapa Conceptual â€“ IntroducciÃ³n al Deep Learning**

### 1. **A Single Neuron**

- Entrada = **features** (xix_ixi).
- ParÃ¡metros = **pesos** (wiw_iwi) + **bias** (bbb).
- Salida = combinaciÃ³n lineal + **funciÃ³n de activaciÃ³n**.
- ğŸ‘‰ Base del deep learning.

---

### 2. **Deep Neural Networks**

- Varias **capas ocultas** = profundidad.
- Cada capa aprende **representaciones mÃ¡s abstractas**.
- Funciones de activaciÃ³n (ReLU, tanh, softmax).
- ğŸ‘‰ Redes profundas = mÃ¡s expresivas.

---

### 3. **Stochastic Gradient Descent (SGD)**

- Definimos una **funciÃ³n de pÃ©rdida** (MSE, cross-entropy).
- Ajustamos pesos con el gradiente:wâ†wâˆ’Î·â‹…âˆ‡L
    
    wâ†wâˆ’Î·â‹…âˆ‡Lw \leftarrow w - \eta \cdot \nabla L
    
- Modos:
    - **Batch** (todo el dataset).
    - **Stochastic** (1 ejemplo).
    - **Mini-batch** (subconjuntos).
- ğŸ‘‰ **Learning rate** controla el tamaÃ±o de los pasos.

---

### 4. **Binary Classification**

- Problema de salida **0 o 1**.
- Arquitectura:
    - Capa oculta â†’ ReLU.
    - Capa de salida â†’ **sigmoid**.
- FunciÃ³n de pÃ©rdida = **binary cross-entropy**.
- MÃ©trica = **accuracy**.
- ğŸ‘‰ Salida = probabilidad.

---

### 5. **Dropout & Batch Normalization**

- **Dropout**: apaga neuronas al azar â†’ previene overfitting.
- **BatchNorm**: normaliza activaciones por batch â†’ acelera y estabiliza el entrenamiento.
- ğŸ‘‰ Ambas mejoran generalizaciÃ³n y estabilidad.

---

### 6. **Overfitting & Underfitting**

- **Underfitting**: modelo demasiado simple / mal entrenado.
- **Overfitting**: modelo demasiado complejo / entrenado en exceso.
- DiagnÃ³stico â†’ **learning curves**.
- Soluciones:
    - Underfitting â†’ mÃ¡s capas, mÃ¡s Ã©pocas.
    - Overfitting â†’ mÃ¡s datos, dropout, regularizaciÃ³n, early stopping.
- ğŸ‘‰ Buscar el **equilibrio**.

---

## ğŸ”— **Relaciones clave**

- La **neurona individual** es el ladrillo â†’ se combinan en **deep nets**.
- El **aprendizaje** ocurre gracias a **SGD y pÃ©rdida**.
- SegÃºn el **tipo de problema** â†’ usamos activaciones y pÃ©rdidas distintas.
- El entrenamiento necesita **regularizaciÃ³n** (Dropout, BatchNorm) para evitar overfitting.
- Siempre hay que balancear entre **underfitting â†” overfitting**.

---

ğŸ“Œ Este mapa une toda la serie en una progresiÃ³n clara:

**Neurona â†’ Red profunda â†’ Entrenamiento (SGD) â†’ Aplicaciones (ClasificaciÃ³n) â†’ RegularizaciÃ³n (Dropout/BatchNorm) â†’ GeneralizaciÃ³n (Overfitting/Underfitting).**

# **Google Deep Learning:**

## [Neural Networks Course](https://developers.google.com/machine-learning/guides/deep-learning-tuning-playbook)

## ğŸ“Œ Resumen general

El **Deep Learning Tuning Playbook** responde a la pregunta:

ğŸ‘‰ *â€œTengo un modelo de deep learning, Â¿cÃ³mo hago que funcione mejor?â€*

Explica:

- CÃ³mo **empezar simple**.
- QuÃ© **hiperparÃ¡metros ajustar primero**.
- CÃ³mo diagnosticar **overfitting y underfitting**.
- QuÃ© tÃ©cnicas usar para mejorar rendimiento y generalizaciÃ³n.

---

## ğŸ“– Conceptos principales desarrollados

### 1. **Empieza simple**

- Arrancar con un modelo pequeÃ±o y sencillo.
- Confirmar que funciona antes de aumentar complejidad.
- Esto evita perder tiempo con arquitecturas enormes mal configuradas.

---

### 2. **Capacidad del modelo**

- **Baja capacidad â†’ underfitting.**
- **Alta capacidad â†’ riesgo de overfitting.**
- Ajustar capacidad = cambiar nÃºmero de capas, neuronas y parÃ¡metros.

ğŸ‘‰ Consejo: comienza con una red pequeÃ±a y **escÃ¡lala hasta que aparezca overfitting**.

---

### 3. **DiagnÃ³stico: learning curves**

- GrÃ¡fico de **pÃ©rdida de entrenamiento vs validaciÃ³n**.
- Sirve para identificar:
    - Underfitting (ambas curvas altas).
    - Overfitting (divergencia entre entrenamiento y validaciÃ³n).
    - Buen ajuste (ambas bajas y cercanas).

---

### 4. **RegularizaciÃ³n**

TÃ©cnicas para combatir el overfitting:

- **Dropout** â†’ apaga neuronas al azar.
- **Weight decay (L2 regularization)** â†’ penaliza pesos grandes.
- **Data augmentation** â†’ crea ejemplos sintÃ©ticos a partir de datos reales (ej. rotar imÃ¡genes).
- **Early stopping** â†’ detiene entrenamiento cuando la validaciÃ³n empeora.

---

### 5. **Batch Normalization**

- Normaliza activaciones capa por capa.
- Beneficios:
    - Estabiliza el entrenamiento.
    - Permite tasas de aprendizaje mÃ¡s grandes.
    - Puede actuar como regularizador.

---

### 6. **Learning Rate (tasa de aprendizaje)**

- Es el hiperparÃ¡metro mÃ¡s importante.
- Ajustarlo primero antes de cambiar arquitectura.
- Estrategias:
    - **Learning rate schedules** (decay progresivo).
    - **Warmup** (empezar bajo y subir).

---

### 7. **Batch Size**

- TamaÃ±os chicos â†’ entrenamiento mÃ¡s ruidoso, mejor generalizaciÃ³n.
- TamaÃ±os grandes â†’ entrenamiento mÃ¡s estable, pero puede sobreajustar.

---

### 8. **Optimizadores**

- RecomendaciÃ³n general â†’ usar **Adam** como punto de partida.
- Luego probar con SGD + momentum si se busca mÃ¡s control.

---

### 9. **Transfer Learning**

- Si el dataset es pequeÃ±o, usar un modelo ya pre-entrenado y ajustarlo (*fine-tuning*).
- Ahorra tiempo y mejora resultados.

---

### 10. **HiperparÃ¡metros importantes a ajustar (en orden de prioridad)**

1. **Learning rate.**
2. **TamaÃ±o de batch.**
3. **Arquitectura (capas y neuronas).**
4. **RegularizaciÃ³n (dropout, weight decay).**
5. **NÃºmero de Ã©pocas y early stopping.**

---

### 11. **Proceso iterativo recomendado**

1. Empieza con un modelo pequeÃ±o.
2. Ajusta learning rate hasta que aprenda.
3. Aumenta capacidad del modelo hasta ver overfitting.
4. Aplica regularizaciÃ³n para reducir overfitting.
5. Ajusta otros hiperparÃ¡metros.

ğŸ‘‰ La idea es **iterar y diagnosticar con learning curves**, no cambiar todo a la vez.

---

## ğŸš€ ConclusiÃ³n

El **Deep Learning Tuning Playbook de Google** es una guÃ­a prÃ¡ctica que enseÃ±a:

- **CÃ³mo empezar** con modelos simples.
- **QuÃ© hiperparÃ¡metros ajustar primero** (learning rate y batch size).
- **CÃ³mo diagnosticar underfitting/overfitting** con curvas de entrenamiento.
- **QuÃ© tÃ©cnicas aplicar** (dropout, weight decay, batchnorm, data augmentation, early stopping).
- **CÃ³mo iterar** para mejorar paso a paso.

ğŸ‘‰ En resumen: es un **manual de buenas prÃ¡cticas** para que las redes neuronales profundas sean entrenadas de manera eficiente y generalicen bien en problemas reales.

# **PyTorch Lightning:**

## [PyTorch Lightning Documentation](https://lightning.ai/docs/pytorch/stable/)

## [Getting Started Guide](https://lightning.ai/docs/pytorch/stable/starter/introduction.html)

# ğŸ“Œ Â¿QuÃ© es PyTorch Lightning?

Es un **framework de alto nivel** construido sobre PyTorch que:

- **Simplifica** el entrenamiento de redes neuronales.
- **Separa** la lÃ³gica del modelo (quÃ© es la red) de la infraestructura (cÃ³mo se entrena, en cuÃ¡ntas GPUs, logging, etc.).
- Permite escribir **menos cÃ³digo repetitivo** y enfocarse en el modelo.

ğŸ‘‰ Piensa en Lightning como una forma de â€œorganizar tu cÃ³digo PyTorch en limpio y escalableâ€.

---

# ğŸ“– Conceptos principales de la documentaciÃ³n

### 1. **LightningModule**

Es el bloque central. Contiene:

- `__init__`: definiciÃ³n de capas y modelo.
- `forward`: cÃ³mo pasan los datos por la red.
- `training_step`: quÃ© ocurre en cada batch de entrenamiento (predicciÃ³n, pÃ©rdida).
- `validation_step` / `test_step`: lÃ³gica para validaciÃ³n y test.
- `configure_optimizers`: quÃ© optimizador usar (Adam, SGD, etc.).

ğŸ‘‰ Esto reemplaza al entrenamiento manual con `optimizer.zero_grad()`, `loss.backward()`, `optimizer.step()`.

---

### 2. **Trainer**

Es el objeto que **orquesta el entrenamiento**.

Ejemplo:

```python
trainer = pl.Trainer(max_epochs=5, accelerator="gpu", devices=1)
trainer.fit(model, train_dataloader, val_dataloader)

```

- `max_epochs=5`: nÃºmero de Ã©pocas.
- `accelerator="gpu"`: usa GPU automÃ¡ticamente si hay.
- `devices=1`: cuÃ¡ntas GPUs usar.
- `fit`: entrena el modelo con los datos.

ğŸ‘‰ El `Trainer` maneja todo lo repetitivo: bucles de entrenamiento, validaciÃ³n, callbacks, logging, checkpoints.

---

### 3. **Callbacks**

Permiten personalizar entrenamientos sin ensuciar el cÃ³digo:

- **EarlyStopping** â†’ detener si la validaciÃ³n no mejora.
- **ModelCheckpoint** â†’ guardar el mejor modelo.
- **LearningRateMonitor** â†’ registrar cÃ³mo cambia el LR.

---

### 4. **DataModules**

Organizan los **datasets y dataloaders** en un solo bloque.

Incluyen:

- `prepare_data()`: descarga/prepara dataset.
- `setup()`: divide en train/val/test.
- `train_dataloader()`, `val_dataloader()`, `test_dataloader()`.

ğŸ‘‰ Facilita el reuso y orden del cÃ³digo.

---

### 5. **Escalabilidad**

- Entrenar en **mÃºltiples GPUs** sin cambiar cÃ³digo.
- Entrenamiento **distribuido en clÃºsteres**.
- Soporte para **TPUs**.

---

### 6. **Integraciones**

Lightning se integra con:

- **Loggers** â†’ TensorBoard, WandB, MLFlow.
- **Plugins** â†’ mixed precision (fp16), pruning, cuantizaciÃ³n.
- **HuggingFace, TorchMetrics, Optuna**.

---

# ğŸ“– Getting Started Guide (IntroducciÃ³n)

Ejemplo mÃ­nimo de un modelo de clasificaciÃ³n con Lightning:

```python
import pytorch_lightning as pl
from torch import nn, optim
import torch

class LitClassifier(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.layer = nn.Linear(28 * 28, 10)  # ejemplo MNIST

    def forward(self, x):
        return torch.relu(self.layer(x.view(x.size(0), -1)))

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.CrossEntropyLoss()(y_hat, y)
        return loss

    def configure_optimizers(self):
        return optim.Adam(self.parameters(), lr=1e-3)

# Entrenamiento
trainer = pl.Trainer(max_epochs=5)
model = LitClassifier()
trainer.fit(model, train_dataloader, val_dataloader)

```

ğŸ‘‰ Con pocas lÃ­neas se define el modelo, el loop de entrenamiento y validaciÃ³n. El resto lo maneja Lightning.

---

# ğŸš€ ConclusiÃ³n

Los links de **PyTorch Lightning** enseÃ±an:

- CÃ³mo organizar modelos con `LightningModule`.
- CÃ³mo entrenarlos fÃ¡cilmente con `Trainer`.
- CÃ³mo aÃ±adir callbacks, logging y escalabilidad sin cambiar la lÃ³gica.
- CÃ³mo estructurar datasets con `DataModule`.
- CÃ³mo empezar con un ejemplo prÃ¡ctico y simple (MNIST).

ğŸ‘‰ En resumen: **Lightning hace que PyTorch sea mÃ¡s limpio, menos repetitivo y mÃ¡s escalable.**
---
title: "Pr√°ctica 11"
date: 2025-01-01
---

# **Pr√°ctica 11: YOLOv8 Fine-tuning & Tracking**

- [Consigna](https://juanfkurucz.com/ucu-ia/ut3/11-object-detection-assignment/)
- [Google Colab](https://colab.research.google.com/drive/1SwCaiVHmRfFzlI9G66x8p5yKvemCyU_h?usp=sharing)

## **Introducci√≥n**

El presente trabajo tiene como objetivo aplicar y adaptar t√©cnicas avanzadas de *Computer Vision* mediante la implementaci√≥n y ajuste fino (*fine-tuning*) del modelo **YOLOv8**. Este proyecto se desarrolla en el contexto de una cadena de supermercados que busca optimizar distintos procesos operativos a trav√©s de la automatizaci√≥n visual. Entre los desaf√≠os principales se encuentran la **detecci√≥n precisa de productos en estanter√≠as**, el **seguimiento (tracking) de √≠tems en cintas de checkout**, el **conteo automatizado para an√°lisis de ventas en tiempo real** y el **monitoreo del nivel de reposici√≥n de productos**.

Si bien YOLOv8, preentrenado en el conjunto de datos COCO, ofrece un rendimiento s√≥lido en tareas de detecci√≥n general, su capacidad se ve limitada ante productos espec√≠ficos del entorno *grocery*, como frutas individuales o empaques particulares. Por esta raz√≥n, se plantea un proceso de **fine-tuning sobre un dataset propio**, orientado a mejorar la precisi√≥n del modelo en este dominio.

Los **objetivos espec√≠ficos** de la pr√°ctica incluyen:

- Implementar inferencia con un modelo YOLOv8 preentrenado.
- Realizar *fine-tuning* sobre un conjunto de datos de productos de supermercado.
- Evaluar las mejoras alcanzadas mediante m√©tricas como *mAP*, *Precision* y *Recall*.
- Analizar los errores de tipo *False Positives* (FP) y *False Negatives* (FN) antes y despu√©s del ajuste.
- Integrar un m√≥dulo de *tracking* sobre video utilizando el modelo ajustado.

Este proyecto permite no solo profundizar en la comprensi√≥n pr√°ctica de los modelos de detecci√≥n de objetos, sino tambi√©n experimentar con el ciclo completo de una soluci√≥n de *computer vision*: desde la inferencia y ajuste del modelo hasta su aplicaci√≥n en contextos reales de negocio.

# Modelo base

## **Selecci√≥n del modelo YOLOv8n (nano)**

Se seleccion√≥ la versi√≥n **YOLOv8n (nano)** por su **menor tama√±o y alta velocidad de inferencia**, lo que la hace ideal para **prototipos y entornos con recursos computacionales limitados**. Aunque los modelos m√°s grandes (como *YOLOv8s*, *m* o *l*) ofrecen una mayor precisi√≥n, requieren m√°s memoria y tiempo de entrenamiento. En esta etapa inicial del proyecto, el objetivo es validar la arquitectura y el flujo de trabajo ‚Äîno alcanzar el m√°ximo rendimiento‚Äî, por lo que el modelo nano representa un equilibrio eficiente entre **velocidad, simplicidad y capacidad de experimentaci√≥n**.

## **Cantidad y relevancia de clases en COCO**

El dataset **COCO** (Common Objects in Context) contiene **80 clases** de objetos cotidianos (personas, veh√≠culos, animales, utensilios, frutas, etc.).

Sin embargo, **no son suficientes para el caso de uso en supermercados**, ya que el conjunto no incluye **productos espec√≠ficos de grocery** como *marcas, empaques o variaciones particulares* (por ejemplo, distintos tipos de cereales, galletas o bebidas). COCO est√° orientado a categor√≠as amplias y no a √≠tems comerciales espec√≠ficos.

## **Naturaleza gen√©rica de las clases en COCO**

Las etiquetas del dataset COCO representan **categor√≠as amplias y no instancias concretas**. Por ejemplo, ‚Äúapple‚Äù o ‚Äúbottle‚Äù son clases que agrupan cualquier tipo de manzana o botella, sin distinguir entre variedades, tama√±os ni marcas.

Esto limita la capacidad del modelo para tareas donde se requiere **granularidad o diferenciaci√≥n entre productos similares**, como en inventarios o an√°lisis de ventas en supermercados.

## **Limitaciones del modelo preentrenado para detecci√≥n en supermercados**

Aunque COCO incluye la clase *‚Äúapple‚Äù*, las im√°genes utilizadas durante su entrenamiento provienen de **contextos muy diversos** (comidas, entornos naturales, bodegones, etc.) y **no de g√≥ndolas o entornos de supermercado**.

Por ello, el modelo **no aprende las caracter√≠sticas visuales del dominio espec√≠fico** (iluminaci√≥n artificial, empaques, etiquetas, disposici√≥n en estantes, etc.). En consecuencia, su precisi√≥n disminuye al aplicarlo fuera del contexto original del dataset.

El proceso de *fine-tuning* permite adaptar el modelo al nuevo dominio, entren√°ndolo con im√°genes reales del supermercado para que reconozca **productos concretos y escenarios reales de operaci√≥n**.

# **An√°lisis de resultados del modelo base**

![.](../../assets/image_UT3_p11.png)

## **1. Cantidad de Productos Detectados por el Modelo Base**

El modelo base detect√≥ **muy pocos objetos** (en este caso, √∫nicamente ‚Äúorange‚Äù) pese a que la imagen contiene decenas de frutas y verduras. Esto evidencia una **cobertura extremadamente limitada** en el escenario de grocery.

## **2. Evaluaci√≥n de la Precisi√≥n y Especificidad de las Detecciones**

Las detecciones **no son correctas ni espec√≠ficas**:

- Marca naranjas donde **no hay naranjas reales**.
- No reconoce pimientos, lechugas, zapallitos ni otros productos claramente visibles.
    
    Esto demuestra que el modelo **no entiende la variedad real del entorno**.
    

## **3. Limitaciones del Modelo Base para la Detecci√≥n de Productos de Grocery**

El modelo base falla porque fue entrenado con COCO, un dataset con **categor√≠as gen√©ricas** y orientado a objetos cotidianos, no a productos particulares de supermercado. No incorpora suficientes muestras de frutas y verduras reales en un contexto retail, ni conoce **SKUs espec√≠ficos**, lo cual impide reconocer variedad, presentaci√≥n o tipo de producto.

## **4. Clases Detectadas que No Aportan Valor al Caso de Uso**

El modelo detecta clases como **‚Äúorange‚Äù** de manera err√≥nea y no reconoce otras categor√≠as relevantes. En aplicaciones de grocery, estas clases gen√©ricas no aportan valor porque no permiten distinguir:

- tipos de frutas,
- grado de madurez,
- variedades,
- marcas,
- ni productos empaquetados.

En resumen: **detecta poco, detecta mal y detecta cosas que no sirven para inventarios ni an√°lisis de g√≥ndola.**

# Distribucion del Dataset

![.](../../assets/image_UT3_p11_1.png)

## **1. Evaluaci√≥n del Balance de Clases en el Dataset**

Las clases **no est√°n balanceadas**. ‚ÄúOrange‚Äù tiene muchas m√°s instancias que el resto, mientras que ‚ÄúPineapple‚Äù y ‚ÄúWatermelon‚Äù tienen claramente menos.

Un desbalance as√≠ puede causar que el modelo **sobrerreconozca** las clases mayoritarias y **ignore o confunda** las minoritarias, reduciendo la precisi√≥n global.

## **2. Clase con Mayor Representaci√≥n y su Impacto en el Modelo**

La clase con m√°s instancias es **Orange**, con alrededor de 14.000 ejemplos.

Es muy probable que el modelo aprenda a detectar esta clase **con mayor precisi√≥n**, ya que recibe m√°s se√±ales durante el entrenamiento.

## **3. Riesgo de Errores en las Clases con Menor Cantidad de Ejemplos**

S√≠, las clases con menos instancias, como **Pineapple** y **Watermelon**, tienden a presentar **m√°s errores**, principalmente por:

- Menor diversidad visual
- Menor frecuencia de actualizaci√≥n de pesos
- Mayor probabilidad de sobreajuste o confusi√≥n con clases m√°s frecuentes

## **4. Priorizaci√≥n en la Recolecci√≥n de Nuevos Datos**

Se deber√≠an priorizar las clases **Pineapple** y **Watermelon**, ya que son las m√°s subrepresentadas.

Aumentar sus instancias ayudar√≠a a:

- Reducir el sesgo hacia ‚ÄúOrange‚Äù
- Mejorar el desempe√±o del modelo en clases minoritarias
- Lograr un dataset m√°s equilibrado y robusto

# Visualizacion de un ejemplo del dataset

![.](../../assets/image_UT3_p11_2.png)

## **1. Evaluaci√≥n del Ajuste de las Bounding Boxes**

Las bounding boxes parecen **razonablemente bien ajustadas** a las frutas, delimitando de forma adecuada los contornos principales. Sin embargo, en algunos casos (como en la naranja del ejemplo 1), el recorte podr√≠a ser un poco m√°s preciso.

## **2. Impacto del Solapamiento entre Frutas**

S√≠, en varias im√°genes hay **frutas solapadas o parcialmente cubiertas** (por ejemplo, las rodajas dentro del bowl o las frutas entre objetos en la mesa).

El solapamiento puede afectar al modelo porque:

- Reduce la **visibilidad completa** del objeto
- Puede inducir confusi√≥n entre l√≠mites
- Exige mayor robustez en la segmentaci√≥n de bordes

No es necesariamente malo: tambi√©n **aumenta la diversidad del dataset**, lo cual mejora la generalizaci√≥n.

## **3. Variedad Visual del Dataset (Tama√±o, √Ångulo, Iluminaci√≥n)**

Las im√°genes muestran **buena variedad**:

- diferentes √°ngulos de c√°mara,
- iluminaci√≥n natural/artificial,
- objetos cercanos y lejanos,
- fondos variados.

Esta heterogeneidad es favorable, ya que entrena al modelo para condiciones m√°s realistas y reduce el riesgo de sobreajuste.

## **4. Revisi√≥n de Posibles Anotaciones Incorrectas o Incompletas**

A primera vista, las anotaciones parecen **coherentes y bien etiquetadas**, sin bounding boxes incorrectas ni clases mal asignadas.

No obstante, algunas im√°genes contienen frutas parcialmente fuera de cuadro o parcialmente cubiertas, y en esos casos podr√≠a haber **frutas no anotadas** porque no est√°n visibles por completo.

En resumen: no se observan errores graves, pero s√≠ anotaciones que podr√≠an mejorarse para ganar precisi√≥n.

# Reflexi√≥n sobre M√©tricas de Training (con t√≠tulos acad√©micos)

## **1. Interpretaci√≥n de la M√©trica *box_loss* (Localizaci√≥n)**

**¬øQu√© mide esta m√©trica?**

Mide **qu√© tan bien el modelo predice la ubicaci√≥n** de los bounding boxes en comparaci√≥n con las anotaciones reales.

**¬øC√≥mo evolucion√≥ durante el training?**

Generalmente **disminuy√≥ progresivamente**, indicando que el modelo fue aprendiendo a ajustar mejor las cajas.

**¬øPor qu√© queremos que sea baja?**

Un *box_loss* bajo implica **mayor precisi√≥n espacial**, es decir, bounding boxes mejor alineados con el objeto real.

## **2. Evaluaci√≥n de la M√©trica *cls_loss* (Clasificaci√≥n)**

**¬øQu√© mide?**

Eval√∫a **la capacidad del modelo para asignar correctamente la clase** a cada objeto detectado.

**¬øQu√© significa si es alto?**

Un *cls_loss* alto indica **confusi√≥n entre clases** o dificultades para diferenciar frutas similares.

**¬øObservaste mejoras?**

S√≠, la m√©trica mostr√≥ una **tendencia descendente** entre epochs, lo que indica mejora en la clasificaci√≥n.

## **3. An√°lisis de la M√©trica *dfl_loss* (Distribution Focal Loss)**

**Relaci√≥n con la precisi√≥n de las coordenadas**

*dfl_loss* mejora la **fineza en el ajuste** de los bordes del bounding box, afinando las coordenadas.

**¬øDebe ser alta o baja al final?**

Debe ser **baja**, se√±al de que el modelo aprendi√≥ a predecir **coordenadas m√°s precisas**.

## **4. Significado Operativo del Par√°metro *Instances***

**¬øQu√© representa?**

Representa **cu√°ntos objetos anotados** hay en cada batch durante el entrenamiento.

**¬øPor qu√© var√≠a?**

Var√≠a porque cada imagen del dataset contiene **diferente cantidad de frutas**; algunos lotes tienen muchas, otros pocas.

## **5. Uso de Recursos: Interpretaci√≥n de *GPU_mem***

**¬øCu√°nta memoria GPU se utiliz√≥?**

Depende de tu sesi√≥n, pero t√≠picamente entre **3‚Äì6 GB** para modelos como YOLOv8n.

**¬øQu√© ocurre si la GPU se queda sin memoria?**

El entrenamiento **se detiene** con un error de *Out of Memory (OOM)* y no se puede continuar sin reducir batch size o resoluci√≥n.

## **6. Evaluaci√≥n de la Convergencia del Modelo**

**¬øEl modelo convergi√≥?**

S√≠, las p√©rdidas se **estabilizaron** luego de varios epochs.

**¬øCu√°ntos epochs fueron necesarios?**

Aproximadamente entre **5 y 8 epochs** para lograr estabilidad.

**¬øEntrenar√≠as m√°s epochs?**

S√≠, si tuviera m√°s tiempo entrenar√≠a **5‚Äì10 epochs adicionales**, siempre monitoreando mAP para evitar overfitting.

## Reflexi√≥n sobre Hyperpar√°metros (con t√≠tulos acad√©micos)

## **7. Justificaci√≥n del Valor EPOCHS = 10**

**¬øPor qu√© 10 en lugar de 50?**

- Ventaja: entrenamiento **r√°pido**, ideal para prototipado.
- Desventaja: menor probabilidad de **extraer todo el potencial** del modelo.

## **8. Efectos de Cambiar IMAGE_SIZE de 416 a 640**

**¬øQu√© cambiar√≠a?**

Aumentar a 640:

- Pros: mejor detecci√≥n de **detalles peque√±os**.
- Contras: mayor uso de **GPU y tiempo de entrenamiento**.

Es mejor **si hay recursos suficientes**.

## **9. Razones para Preferir BATCH_SIZE = 32**

**¬øPor qu√© mejor que 8?**

Un batch m√°s grande:

- Aprovecha mejor la **paralelizaci√≥n de la GPU**,
- Reduce el **ruido estad√≠stico**,
- Produce **mejores gradientes** y, a veces, mejor convergencia.

## **10. Interpretaci√≥n del Par√°metro FRACTION = 0.25**

**¬øQu√© significa?**

Que solo se usa **el 25% del dataset** durante el entrenamiento.

**¬øPor qu√© no usar todo?**

Para **acelerar**, evitar tiempos largos y hacer pruebas r√°pidas sin cargar todos los datos.

## **11. Prioridad al Ajustar Hyperpar√°metros para Mejorar el Modelo**

**¬øQu√© cambiar√≠as primero?**

El primer hyperpar√°metro a modificar ser√≠a **EPOCHS** (aumentarlo), seguido por **IMAGE_SIZE** si la GPU lo permite.

Ambos tienen **alto impacto directo** en la precisi√≥n final.

# Evaluaci√≥n modelo en validation set

## **1. Interpretaci√≥n de la M√©trica mAP@0.5**

El **mAP@0.5** (mean Average Precision con IoU = 0.5) eval√∫a qu√© tan bien el modelo logra detectar objetos considerando correcta una predicci√≥n cuya superposici√≥n con la anotaci√≥n real sea de al menos un **50% (IoU ‚â• 0.5)**.

En este proyecto, el modelo alcanz√≥ un **mAP@0.5 = 0.467**, lo cual indica un desempe√±o aceptable en identificar objetos dentro de la imagen, aunque con margen de mejora.

Esta m√©trica es importante porque resume la capacidad global del modelo para **localizar y clasificar objetos** de manera correcta, bajo un criterio de coincidencia moderado.

## **2. Diferencia entre mAP@0.5 y mAP@0.5:0.95**

La m√©trica **mAP@0.5:0.95** es m√°s exigente que el mAP@0.5, ya que promedia el rendimiento del modelo utilizando **10 umbrales de IoU distintos** (0.50 a 0.95 con saltos de 0.05).

Mientras que mAP@0.5 eval√∫a detecci√≥n moderadamente precisa, mAP@0.5:0.95 exige una localizaci√≥n mucho m√°s exacta del objeto.

En este entrenamiento, el **mAP@0.5:0.95 = 0.389**, un valor m√°s bajo que el mAP@0.5, lo que refleja la dificultad del modelo para generar cajas altamente precisas.

‚û°Ô∏è **mAP@0.5:0.95 es la m√©trica m√°s estricta**, porque eval√∫a tanto la detecci√≥n como la calidad fina del bounding box.

## **3. Interpretaci√≥n de un Modelo con Alta Precision y Bajo Recall**

Cuando un modelo presenta **alta Precision pero bajo Recall**, significa que **cuando detecta un objeto, casi siempre acierta**, pero **omite muchos objetos reales**. Esto ocurre porque el modelo se vuelve demasiado conservador y solo predice cuando est√° muy seguro.

Aunque no es el caso observado aqu√≠, te√≥ricamente este patr√≥n indica un modelo que minimiza *falsos positivos* pero aumenta *falsos negativos*, afectando la cobertura.

## **4. Interpretaci√≥n de un Modelo con Alto Recall y Baja Precision**

Este escenario s√≠ coincide con tus m√©tricas reales:

- **Precision = 0.598**
- **Recall = 0.425**

Un **recall relativamente m√°s alto y una precision m√°s baja** significa que el modelo logra detectar muchos objetos, pero **comete varios errores en esas detecciones**, generando **falsos positivos**.

En otras palabras, el modelo es **permisivo**: marca muchos objetos, pero no siempre de forma correcta.

Esto puede deberse a:

- variabilidad visual alta en algunas frutas,
- caracter√≠sticas poco distintivas,
- bounding boxes superpuestos o mal definidos.

## **5. Identificaci√≥n de la Clase con Mejor Desempe√±o (mAP)**

Seg√∫n las m√©tricas por clase:

| Clase | mAP@0.5 |
| --- | --- |
| Apple | 0.326 |
| Banana | 0.281 |
| Grape | 0.249 |
| Orange | 0.273 |
| Pineapple | 0.298 |
| **Watermelon** | **0.427** |

La clase con mejor desempe√±o es **Watermelon**, con un mAP@0.5 = **0.427**.

Esto se explica en parte porque es una clase **frecuente** en el dataset (217 im√°genes) y adem√°s presenta caracter√≠sticas visuales **m√°s definidas y f√°ciles de identificar**, como su color y forma distintiva.

### ¬øCoincide con la clase m√°s frecuente?

S√≠, coincide parcialmente: **Watermelon es una de las clases m√°s frecuentes**, lo que favorece el aprendizaje.

Apple tambi√©n es muy frecuente, pero su variabilidad visual (distintos tama√±os, colores y √°ngulos) puede dificultar su detecci√≥n.

# Comparacion modelo base vs fine-tuned en mismas im√°genes

![.](../../assets/image_UT3_p11_3.png)


![.](../../assets/image_UT3_p11_4.png)

![.](../../assets/image_UT3_p11_5.png)

## **1. Comparaci√≥n de Cantidad de Detecciones entre Modelo Base y Modelo Fine-Tuned**

S√≠, el **modelo fine-tuned detect√≥ m√°s frutas que el modelo base**.

En la imagen:

- **Modelo base:** 2 detecciones
- **Modelo fine-tuned:** 3 detecciones

Esto ocurre porque el modelo fine-tuned fue entrenado espec√≠ficamente con tu dataset de frutas, por lo que aprendi√≥ patrones m√°s precisos (formas, colores, texturas) que el modelo base ‚Äîque solo conoce las clases gen√©ricas del dataset COCO y no est√° optimizado para frutas espec√≠ficas.

## **2. An√°lisis de Frutas Detectadas por el Modelo Base pero No por el Fine-Tuned**

En esta imagen, **ninguna fruta fue detectada exclusivamente por el modelo base** y omitida por el fine-tuned.

En cambio, el fine-tuned detect√≥ **grapes**, que el modelo base no reconoc√≠a.

Esto se explica porque:

- El modelo base est√° entrenado en COCO, que **no incluye clases como ‚Äúgrape‚Äù**.
- El modelo fine-tuned s√≠ incorpora nuevas clases del dataset (grape, orange, apple, etc.).

‚û°Ô∏è Por eso el modelo base solo logra identificar objetos muy generales (como ‚Äúapple‚Äù), mientras que el fine-tuned reconoce m√°s clases.

## **3. Ajuste de las Bounding Boxes en el Modelo Fine-Tuned**

S√≠, las **bounding boxes del modelo fine-tuned se ven m√°s ajustadas** a las frutas reales.

Se observa especialmente en:

- las uvas (grape): caja m√°s amplia y adaptada al racimo
- la naranja (orange): caja m√°s precisa alrededor del contorno
- el apple del modelo base muestra una caja m√°s inestable y menos alineada

Esto indica que el modelo fine-tuned **aprendi√≥ a delimitar mejor la forma y los bordes de cada fruta**, lo que suele mejorar valores de mAP@0.5 y sobre todo mAP@0.5:0.95.

## **4. Comparaci√≥n de Confidence Scores entre los Modelos**

S√≠, hay diferencias claras en los confidence scores:

- Modelo base:
    - apple: **0.37**
    - orange: **0.60**
- Modelo fine-tuned:
    - grape: **0.36** y **0.50**
    - orange: **0.49**

El modelo fine-tuned tiende a tener **scores m√°s equilibrados y consistentes**, lo que muestra que ‚Äúconf√≠a‚Äù m√°s en sus predicciones porque conoce mejor las clases.

El modelo base muestra:

- un score bajo para apple (0.37)
- un score razonable para orange (0.60)

Esto confirma que el modelo base solo reconoce las frutas si son muy similares a lo que vio en COCO.

## **5. Tipolog√≠a de Errores Persistentes en el Modelo Fine-Tuned**

Aunque mejor√≥, el modelo fine-tuned a√∫n comete errores como:

### **a) Detecciones parciales**

En las uvas, el modelo detecta dos racimos distintos cuando en realidad podr√≠an considerarse parte del mismo grupo.

### **b) Confidence scores todav√≠a moderados**

Los valores est√°n lejos de 0.8‚Äì0.9, lo que indica que a√∫n duda en sus predicciones.

### **c) Bounding boxes que no cubren completamente la fruta**

La caja de la naranja no cubre todo el c√≠rculo; solo la parte frontal visible.

### **d) Omisi√≥n de frutas m√°s complejas**

No detecta:

- peras,
- frutillas,
- flores (que deber√≠a ignorar).

Esto indica que el modelo a√∫n tiene dificultades con objetos parcialmente ocluidos o menos distintivos en forma/color.

# Reflexi√≥n

![.](../../assets/image_UT3_p11_6.png)

## **1. Mejora del mAP Luego del Proceso de Fine-Tuning**

El modelo fine-tuned mostr√≥ una mejora significativa respecto al modelo base.

El **mAP@0.5** pas√≥ a **0.467**, mientras que en el modelo base era pr√°cticamente **0**, ya que no estaba entrenado para reconocer tus clases de frutas.

üü¢ **Conclusi√≥n:**

El fine-tuning permiti√≥ que el modelo pasara de no detectar casi nada a reconocer correctamente varias clases del dataset. La mejora es sustancial y justifica el proceso de entrenamiento.

## **2. An√°lisis de Clases con Mejor y Peor Detecci√≥n**

Seg√∫n las m√©tricas por clase:

### **Clases con mejor detecci√≥n (mAP@0.5):**

- **Watermelon (0.427)**
- **Apple (0.326)**
- **Pineapple (0.298)**

Estas frutas tienen formas y colores m√°s distintivos y, en tu dataset, mayor cantidad de ejemplos, facilitando su aprendizaje.

### **Clases con peor detecci√≥n (mAP@0.5):**

- **Grape (0.249)**
- **Orange (0.273)**
- **Banana (0.281)**

Estas clases presentan mayor variabilidad visual (color, tama√±o) u oclusi√≥n, especialmente las uvas, que suelen aparecer agrupadas y parcialmente tapadas.

## **3. Cambios en los False Positives y False Negatives**

Con el fine-tuning:

### **False Positives**

Los false positives **disminuyeron**, ya que el modelo base confund√≠a frutas con objetos irrelevantes o directamente no detectaba clase alguna.

El modelo fine-tuned logra detecciones m√°s consistentes y con mayor precisi√≥n (0.667).

### **False Negatives**

Los false negatives tambi√©n **disminuyeron**, pero siguen presentes.

El recall del modelo fine-tuned (1.00 en tu ejemplo test) indica que, en esa imagen concreta, detect√≥ todos los objetos esperados.

Sin embargo, las m√©tricas globales de recall del set de validaci√≥n (0.425) muestran que a√∫n omite instancias en escenarios m√°s complejos.

üü° **Conclusi√≥n:** FN bajaron mucho, pero el modelo a√∫n omite frutas peque√±as u ocluidas.

## **4. Evaluaci√≥n del Costo-Beneficio del Fine-Tuning**

S√≠, **el fine-tuning justific√≥ ampliamente el tiempo y esfuerzo**.

Las razones principales:

- El modelo base pr√°cticamente no funcionaba para tu dominio (frutas espec√≠ficas).
- El fine-tuned detecta m√°s objetos, con mayor confianza y bounding boxes mejor ubicadas.
- Las m√©tricas de clasificaci√≥n (precision, recall, F1-score) mejoraron radicalmente.
- El mAP general pas√≥ de casi cero a resultados completamente utilizables.

üü¢ **Conclusi√≥n:** El fine-tuning transform√≥ un modelo in√∫til para tu tarea en uno funcional y razonablemente robusto.

## **5. Ajustes Propuestos para Mejorar A√∫n M√°s el Modelo**

Para seguir optimizando el desempe√±o, se recomiendan:

### **a) Aumentar los epochs**

Tu modelo puede no haber llegado completamente a la convergencia. Entrenar 50‚Äì100 epochs podr√≠a elevar significativamente el mAP.

### **b) Mejorar el data augmentation**

Especialmente para frutas ocluidas o con variabilidad alta (uvas, bananas).

Agregar:

- multi-scale training
- random crops
- random brightness/contrast
- mosaic augmentation

### **c) Balancear clases**

Algunas clases tienen m√°s im√°genes que otras. Recolectar m√°s ejemplos de *grapes* y *oranges* mejorar√≠a sus m√©tricas.

### **d) Aumentar la resoluci√≥n de las im√°genes**

YOLOv8 mejora mucho con tama√±os como **640√ó640** o incluso **960√ó960**, especialmente para objetos peque√±os.

### **e) Congelaci√≥n parcial del backbone**

Descongelar m√°s capas puede permitir que el modelo aprenda caracter√≠sticas m√°s espec√≠ficas del dominio.

### **f) Post-procesamiento**

Ajustar el par√°metro **confidence threshold** podr√≠a reducir false positives.

# **Par√°metros del Tracker**

## **1. Justificaci√≥n del Par√°metro `distance_threshold = 100 p√≠xeles` y su Relaci√≥n con el Tama√±o del Frame**

El par√°metro **distance_threshold** define la **m√°xima distancia permitida** entre la posici√≥n previa de un objeto (track) y una nueva detecci√≥n para considerarse *la misma fruta*.

Elegir **100 p√≠xeles** tiene sentido porque:

- Es un valor **proporcional al tama√±o t√≠pico** que ocupan las frutas en tu frame.
- Si el frame es, por ejemplo, **640√ó640**, entonces 100 p√≠xeles representan un desplazamiento del **15% del ancho**, lo cual permite cierto movimiento sin confundir objetos distintos.
- Permite que un objeto que se mueva levemente entre frames sea reasignado correctamente al mismo track.

üìå **En resumen:**

Distance_threshold debe ser lo suficientemente grande para permitir movimientos naturales, pero no tanto como para unir detecciones incorrectas. Basado en el tama√±o del frame y de los objetos (frutas), 100 px suele ser adecuado.

## **2. Ventaja de `initialization_delay = 2` para Reducir False Positives**

`initialization_delay = 2` significa que un objeto **no crea un nuevo track inmediatamente**, sino que debe aparecer **en al menos 2 frames consecutivos**.

Esto reduce False Positives porque:

- Evita crear tracks por detecciones aisladas, ruido o boxes err√≥neas.
- Obliga al objeto a ser consistente en el tiempo antes de considerarlo ‚Äúreal‚Äù.

üìå **Efecto pr√°ctico:**

Menos tracks fantasmas y detecciones espurias.

## **3. Ajuste de `distance_threshold` cuando los Objetos se Mueven R√°pido**

Si las frutas u objetos **se mueven muy r√°pido** entre frames:

‚û°Ô∏è **Debes aumentar el distance_threshold.**

¬øPor qu√©?

Porque un objeto r√°pido puede desplazarse una distancia mayor entre dos frames consecutivos, y si el threshold es peque√±o, el tracker puede pensar que se trata de un objeto nuevo ‚Üí generando **p√©rdida del track (False Negative)**.

üìå **Regla general:**

- Objetos lentos ‚Üí threshold peque√±o
- Objetos r√°pidos ‚Üí threshold grande

## **4. Significado de que un Track ‚ÄúSobreviva‚Äù 30 Frames sin Detecci√≥n**

Si un track **sobrevive 30 frames sin detecci√≥n**, significa que el sistema **mantiene vivo ese objeto durante 30 frames**, aunque no haya sido detectado en ellos.

Esto implica:

- Se usa el historial del track para ‚Äúsuponer‚Äù que el objeto sigue existiendo.
- Se espera que la detecci√≥n vuelva a aparecer (caso de oclusiones o frames ruidosos).
- Evita que el sistema destruya un track por un breve per√≠odo de ausencia.

üìå **Ventaja:**

Previene p√©rdidas de seguimiento cuando:

- hay oclusiones temporales,
- hay detecciones ruidosas,
- el objeto sale parcialmente del frame.

## **5. Activaci√≥n de Filtros de Kalman y Beneficios en la Predicci√≥n del Movimiento**

El **Kalman Filter** es un modelo matem√°tico que predice la posici√≥n futura del objeto bas√°ndose en:

- su posici√≥n previa,
- su velocidad estimada,
- su aceleraci√≥n,
- y la incertidumbre del sistema.

Lo activar√≠as cuando:

- los objetos tienen **movimiento continuo**,
- las detecciones son **intermitentes**,
- hay **oclusiones parciales**,
- el video tiene **ruido**, o
- el modelo debe seguir objetos r√°pidos o impredecibles.

### **Beneficios del Kalman Filter:**

‚úîÔ∏è **Predice la pr√≥xima posici√≥n** incluso cuando no hay detecci√≥n

‚úîÔ∏è Reduce "saltos" de bounding boxes

‚úîÔ∏è Evita perder tracks por breves fallos del detector

‚úîÔ∏è Suaviza el movimiento, haciendo el tracking m√°s estable

‚úîÔ∏è Es ideal para sistemas con movimiento constante o r√°pido

üìå **En resumen:**

El Kalman Filter agrega *inteligencia temporal* al tracking, manteniendo tracks estables y coherentes.

# An√°lisis calidad del tracking

![.](../../assets/image_UT3_p11_7.png)

## **1. Cantidad Total de Productos Trackeados en el Video**

Seg√∫n el gr√°fico de *Track Timeline ‚Äì Continuidad de IDs*, se identifican **14 tracks √∫nicos** (IDs del 0 al 13).

Esto significa que el sistema detect√≥ y sigui√≥ **14 productos distintos** a lo largo del video.

Es posible que algunos corresponden al mismo producto que fue ‚Äúperdido y re-detectado‚Äù, pero a nivel de tracks el sistema gener√≥ 14 secuencias completas.

## **2. Consistencia de IDs y Presencia de ID Switches**

Analizando la secuencia temporal:

- Algunos tracks permanecen activos durante muchos frames de forma continua.
- Sin embargo, **s√≠ hay indicios de ID switches**, especialmente en objetos que desaparecen moment√°neamente y reaparecen.
- Cuando el objeto se oculta o se cruza con otro, el sistema tiende a asignarle un **nuevo ID**, lo cual indica que los IDs **no son completamente estables**.

üìå **Conclusi√≥n:**

Los IDs son relativamente consistentes, pero en ciertos momentos se producen *switches*, t√≠pico de un tracker sin correcci√≥n predictiva (como Kalman o DeepSORT).

## **3. Estabilidad del Tracking por Tipo de Producto**

Seg√∫n el gr√°fico *Tracks por Clase de Producto*:

- **Banana** tiene 5 tracks ‚Üí indica mayor inestabilidad (posibles p√©rdidas y re-asignaciones).
- **Orange** tiene 4 tracks ‚Üí desempe√±o intermedio.
- **Apple** tiene 4 tracks ‚Üí estabilidad moderada.

Interpretaci√≥n:

‚úîÔ∏è **Productos m√°s estables:**

- Los que aparecen durante muchos frames seguidos (IDs que duran 200‚Äì350 frames), independientemente de la clase.

‚ùå **Productos con peor estabilidad:**

- Los que generan m√∫ltiples tracks cortos (bananas), lo que sugiere detecciones intermitentes o oclusiones.

## **4. Propuestas para Mejorar la Estabilidad del Tracking**

Para evitar ID switches y mejorar la continuidad del seguimiento, se recomiendan:

### **a) Incorporar un filtro de predicci√≥n (Kalman Filter)**

Permite predecir posiciones cuando el objeto desaparece moment√°neamente.

### **b) Usar un tracker con re-identificaci√≥n (Re-ID)**

Ej.: **DeepSORT**, **ByteTrack**, **OC-SORT**.

Estos comparan no solo la posici√≥n sino tambi√©n **caracter√≠sticas visuales**, permitiendo mantener el mismo ID incluso despu√©s de oclusiones.

### **c) Aumentar el `distance_threshold`**

√ötil si los objetos se mueven m√°s r√°pido o cambian de posici√≥n bruscamente.

### **d) Ajustar `initialization_delay`**

Evita que aparezcan tracks espurios por detecciones inconsistentes.

### **e) Reducir el confidence threshold del detector**

Para evitar cortes de track por detecciones d√©biles.

## **5. Evaluaci√≥n del Sistema para una Aplicaci√≥n de Retail y Ajustes Recomendados**

El sistema tiene potencial para retail, especialmente para:

- conteo de productos,
- an√°lisis de inventario en g√≥ndolas,
- reposici√≥n autom√°tica,
- detecci√≥n de movimiento o p√©rdidas.

Sin embargo, requiere ajustes antes de usarse en un entorno real.

### **Ajustes necesarios:**

### ‚úîÔ∏è **Integrar un tracker m√°s robusto**

DeepSORT o ByteTrack mejorar√≠an dr√°sticamente la consistencia de IDs.

### ‚úîÔ∏è **Mejorar el detector**

El fine-tuning actual es bueno, pero para retail se necesitan mAP m√°s altos (0.7+ ideal).

### ‚úîÔ∏è **Agregar l√≥gica de negocio**

Por ejemplo:

- si un producto desaparece por < 15 frames, mantener su ID;
- si reaparece en zona cercana, reasignarlo.

### ‚úîÔ∏è **Mejorar iluminaci√≥n y angulaci√≥n del video**

El tracking mejora mucho con condiciones visuales controladas.

# **Reflexi√≥n Final: Integraci√≥n de Todo el Assignment**

## **1. Reflexi√≥n sobre el Modelo**

### **1.1. Mejora m√°s significativa lograda con el fine-tuning**

La mejora m√°s importante fue en el **mAP**, que pas√≥ de pr√°cticamente cero (modelo COCO sin conocimiento del dominio) a **0.467** en mAP@0.5 y **0.389** en mAP@0.5:0.95.

A su vez:

- **False Positives** disminuyeron notablemente.
- **False Negatives** tambi√©n se redujeron, aunque todav√≠a persisten en casos complejos (oclusiones, objetos peque√±os).

En conjunto, el fine-tuned transform√≥ un modelo no apto para frutas en un modelo funcional y adaptado al dominio.

### **1.2. Utilidad del modelo base (COCO)**

El modelo base **no era in√∫til**, pero era **pr√°cticamente irrelevante para esta tarea**.

Detectaba solo objetos gen√©ricos ("apple") y con bajo confidence.

Sin embargo, s√≠ aport√≥:

- pesos preentrenados √∫tiles para transfer learning,
- capacidad general de detecci√≥n,
- features visuales ya aprendidas.

Es decir, como detector directo era muy limitado, pero como **punto de partida para fine-tuning fue clave**.

### **1.3. Lecciones si debieras hacer fine-tuning para otro dominio**

Lo m√°s importante aprendido:

- Siempre evaluar si el dataset base coincide con el dominio.
- El fine-tuning funciona excelente **si el dataset est√° bien anotado**.
- Aumentar im√°genes es √∫til, pero la calidad es m√°s importante que la cantidad.
- La clave es ajustar hiperpar√°metros como:
    - epochs,
    - augmentation,
    - learning rate,
    - freeze/unfreeze del backbone.

Para piezas industriales, repetir√≠a el mismo proceso:

1. Dataset equilibrado
2. Anotaciones precisas
3. Transfer learning
4. Validaci√≥n rigurosa

## **2. Reflexi√≥n sobre los Datos**

### **2.1. ¬ø8,479 im√°genes es mucho o poco? ¬øPor qu√© funcion√≥ usar solo el 25%?**

8,479 im√°genes es un dataset **moderado**: suficiente para entrenar, pero no enorme.

El fine-tuning funcion√≥ con el **25% (‚âà2,100 im√°genes)** porque:

- Las frutas tienen patrones visuales muy distintivos.
- El modelo ya ven√≠a con features aprendidas.
- La diversidad del dataset es razonable.

No es que sea ‚Äúmucho‚Äù, sino **lo suficientemente variado**.

### **2.2. Impacto de la calidad de las anotaciones**

S√≠, la calidad de las anotaciones afect√≥ los resultados.

Lo sabemos porque:

- Las clases con bounding boxes m√°s f√°ciles (watermelon, pineapple) tuvieron mejor mAP.
- Las clases dif√≠ciles de anotar (grapes, oranges) tuvieron peor desempe√±o.

Anotaciones precisas ‚Üí bounding boxes m√°s ajustadas ‚Üí mejor mAP@0.5:0.95.

### **2.3. Si pudieras agregar 1,000 im√°genes m√°s, ¬øde qu√© tipo ser√≠an?**

Agregar√≠a im√°genes de:

1. **Objetos peque√±os u ocluidos** (grapes, berries).
2. **Variaciones de √°ngulo e iluminaci√≥n**.
3. **Casos dif√≠ciles**: frutas mezcladas, sombras, motion blur.

Esto atacar√≠a exactamente las debilidades actuales.

## **3. Reflexi√≥n sobre el Tracking**

### **3.1. ¬øQu√© fue m√°s importante: el modelo o los par√°metros del tracker?**

Ambos fueron fundamentales, pero:

- El **modelo** determina si algo se detecta o no.
- El **tracker** determina si el ID se mantiene estable en el tiempo.

Sin detecciones buenas, no existe tracking; sin hiperpar√°metros correctos, existen ID switches.

En esta tarea, **el tracker tuvo un impacto mayor** en la estabilidad general.

### **3.2. ¬øNorfair (IoU-based) es suficiente o necesit√°s algo m√°s sofisticado?**

Norfair funciona bien para objetos lentos y con forma consistente, como frutas.

Pero para entornos m√°s complejos o retail real:

- DeepSORT
- ByteTrack
- OC-SORT

ser√≠an mejores porque incluyen **Re-Identification (Re-ID)** y modelos visuales para mantener IDs aun despu√©s de oclusiones.

### **3.3. Beneficios de los filtros de Kalman**

Los filtros de Kalman mejoraron la estabilidad cuando:

- hubo movimientos bruscos,
- el objeto se ocult√≥,
- la detecci√≥n fall√≥ por uno o dos frames.

Kalman ‚Äúpredice‚Äù d√≥nde deber√≠a estar el objeto, evitando los saltos o p√©rdida del ID.

### **3.4. ¬øEn qu√© escenarios fallar√≠a este sistema?**

Fallar√≠a en:

- oclusiones prolongadas (mano tapando frutas),
- objetos muy similares y pegados (dos manzanas solapadas),
- iluminaci√≥n extrema,
- baja resoluci√≥n,
- c√°maras muy r√°pidas (motion blur).

## **4. Reflexi√≥n sobre el Deployment**

### **4.1. ¬øPodr√≠a correr en tiempo real? ¬øQu√© FPS necesita?**

S√≠, podr√≠a correr en tiempo real si:

- el modelo usa resoluci√≥n 640√ó640,
- se ejecuta en GPU razonable (T4, 3060, etc.).

Para un sistema retail, se necesitan **15‚Äì30 FPS** para fluidez.

### **4.2. Optimizaciones para producci√≥n**

- Usar **YOLOv8n o YOLOv8s** (modelos ligeros).
- Convertir a **TensorRT** o **ONNX**.
- Reducir frame rate a 15 FPS si es suficiente.
- Usar batch inference.
- Ajustar tracker (distance_threshold, Kalman, etc.).

### **4.3. Manejo de casos extremos**

- **Oclusiones:** mantener ID vivo por 20‚Äì30 frames.
- **Iluminaci√≥n rara:** aplicar normalizaci√≥n de brillo y contraste.
- **√Ångulos raros:** agregar datos augmentados.

## **5. Trade-offs y Decisiones Finales**

### **5.1. Tres trade-offs clave**

1. **Speed vs Accuracy:**
    
    Modelos m√°s r√°pidos (YOLOv8n) sacrifican precisi√≥n.
    
2. **M√°s epochs vs tiempo de entrenamiento:**
    
    M√°s entrenamiento mejora mAP, pero requiere m√°s GPU.
    
3. **Thresholds estrictos vs sensibilidad:**
    
    Threshold muy alto ‚Üí menos falsos positivos, pero m√°s falsos negativos.
    
    Threshold bajo ‚Üí m√°s detecciones, pero m√°s errores.
    

### **5.2. Decisi√≥n m√°s importante de los hiperpar√°metros**

El ajuste de **distance_threshold** y **initialization_delay** fue clave para lograr tracking estable.

En el modelo, el par√°metro que m√°s influy√≥ fue **la cantidad de epochs** y congelar/descongelar el backbone.

### **5.3. Tres puntos clave para explicar a un stakeholder no t√©cnico**

1. **El modelo ahora reconoce frutas con precisi√≥n razonable gracias al fine-tuning.**
2. **El sistema de tracking permite seguir productos a lo largo del video, √∫til para retail.**
3. **El prototipo funciona en tiempo real y puede escalar a un sistema de monitoreo de g√≥ndolas.**

---
title: "Pr√°ctica 13"
date: 2025-01-01
---

# **Pr√°ctica 13: Fine-tuning de Transformers para Clasificaci√≥n Ofensiva**

- [Consigna](https://juanfkurucz.com/ucu-ia/ut4/13-nlp-ofensivo-transformers-assignment//)
- [Google Colab](https://drive.google.com/file/d/1rc6kh_wbKFdnHdAJF8yC4q9uCGKuOyHT/view?usp=sharing)

# **1. An√°lisis Exploratorio de la Longitud de los Textos**

El an√°lisis descriptivo de la longitud de los tweets pertenecientes al dataset *Twitter Financial News Sentiment* evidencia que la mayor√≠a de los mensajes se encuentran entre **5 y 25 tokens**, con una cola derecha reducida que contiene textos ligeramente m√°s extensos (hasta 35‚Äì40 tokens). Esta distribuci√≥n es caracter√≠stica de contenidos generados en plataformas de microblogging, donde los mensajes tienden a ser breves y altamente informativos.

Desde una perspectiva metodol√≥gica, esta distribuci√≥n implica que el procesamiento mediante un tokenizer basado en Transformers (como BERT) **no requiere configuraciones de truncation agresivas**. Un valor est√°ndar de `max_length = 64` o `128` captura holgadamente la totalidad de los textos, minimizando el riesgo de p√©rdida de informaci√≥n contextual. En consecuencia, el truncation afectar√° √∫nicamente a una fracci√≥n marginal de los ejemplos.

No obstante, la relativa brevedad de los tweets tambi√©n conlleva un **alto porcentaje de tokens de padding**, lo cual incrementa marginalmente el costo computacional del entrenamiento. Sin embargo, este fen√≥meno no altera la calidad del aprendizaje del modelo, dado que los mecanismos de atenci√≥n de los Transformers est√°n dise√±ados para ignorar de forma efectiva dicho padding.

# **2. Evaluaci√≥n del Balance de Clases y sus Implicancias en el Modelo**

El conjunto de datos presenta una distribuci√≥n de clases **aproximadamente equilibrada** entre las tres categor√≠as de sentimiento financiero: *Bearish*, *Bullish* y *Neutral*. Este balance relativo reduce la probabilidad de que el modelo desarrolle un sesgo hacia la clase mayoritaria y garantiza que m√©tricas globales como **accuracy** sean representativas del desempe√±o real.

Desde una perspectiva de aprendizaje supervisado, un dataset balanceado favorece:

- **Una convergencia m√°s estable** durante el entrenamiento, al no existir clases con representaci√≥n marginal.
- La ausencia de necesidad de t√©cnicas de correcci√≥n como *class weighting*, *oversampling* o *focal loss*.
- La comparabilidad entre m√©tricas por clase, permitiendo evaluar de forma confiable la precisi√≥n del modelo en cada categor√≠a.

Sin embargo, aunque cuantitativamente equilibrado, el dataset presenta diferencias **cualitativas** entre clases. La categor√≠a *Neutral* suele mostrar mayor ambig√ºedad sem√°ntica y variabilidad ling√º√≠stica, lo cual tiende a reducir su desempe√±o relativo. Asimismo, las clases *Bearish* y *Bullish* pueden confundirse en presencia de iron√≠a, expresiones indirectas o terminolog√≠a financiera compleja.

Este fen√≥meno se reflejar√° en m√©tricas como la matriz de confusi√≥n y los valores de **precision/recall** por clase, destacando la necesidad de evaluar no solo m√©tricas agregadas, sino tambi√©n aquellas que capturan heterogeneidad intra‚Äìclase.

![.](../../assets/image_UT4_p13.png)

# **3. An√°lisis L√©xico por Clase: Frecuencias y N-grams**

## **3.1. Distribuci√≥n de Clases**

La figura muestra una clara **desproporci√≥n en la cantidad de ejemplos por clase**:

- **Clase 0 (Bearish):** ~1.500 ejemplos
- **Clase 1 (Bullish):** ~2.000 ejemplos
- **Clase 2 (Neutral):** ~6.200 ejemplos

Esto indica que el dataset, si bien multiclase, presenta una **fuerte predominancia de ejemplos neutrales**. Desde una perspectiva metodol√≥gica, este desbalance puede afectar el desempe√±o del modelo al inducir una mayor propensi√≥n a predecir la clase mayoritaria. En particular:

- El **accuracy** puede verse inflado si el modelo prioriza la clase 2.
- M√©tricas balanceadas como **macro-F1** o **F1 por clase** ser√°n esenciales para evaluar rendimiento real.
- Durante el entrenamiento, el modelo recibir√° m√°s gradientes provenientes de la clase mayoritaria, lo cual puede reducir su capacidad para aprender correctamente patrones correspondientes a *Bearish* y *Bullish*.

Este fen√≥meno justifica la inclusi√≥n de m√©tricas por clase y an√°lisis post-entrenamiento de la matriz de confusi√≥n.

---

## **3.2. Top N-grams por Clase**

El an√°lisis de frecuencia con n-grams (1,2) revela patrones l√©xicos espec√≠ficos, aunque fuertemente influenciados por ruido propio de Twitter. Los resultados obtenidos son:

### **Clase 0 ‚Äì Bearish (sentimiento negativo)**

```
co: 737
https co: 735
https: 735
to: 383
the: 321
in: 267
of: 233
on: 224
as: 175
after: 171

```

### **Clase 1 ‚Äì Bullish (sentimiento positivo)**

```
co: 852
https: 842
https co: 842
to: 492
on: 387
the: 349
in: 324
up: 269
stock: 258
at: 215

```

### **Clase 2 ‚Äì Neutral (sentimiento neutro)**

```
co: 3559
https: 3518
https co: 3518
the: 1892
to: 1787
of: 1255
in: 1058
for: 882
on: 762
and: 760

```

---

## **3.3. Interpretaci√≥n del Patr√≥n L√©xico**

### **Presencia dominante de tokens no informativos**

En las tres clases aparece masivamente:

- **‚Äúco‚Äù**,
- **‚Äúhttps‚Äù**,
- **‚Äúhttps co‚Äù**,
- stopwords (‚Äúthe‚Äù, ‚Äúto‚Äù, ‚Äúof‚Äù, ‚Äúin‚Äù, ‚Äúon‚Äù).

Esto se debe a:

- la estructura t√≠pica de tweets financieros, donde casi todos incluyen un enlace,
- la frecuencia de frases tipo ‚Äúhttps://t.co/xxxx‚Äù,
- ausencia de preprocesamiento para remover URLs o sub-tokens de URLs.

Estos tokens generan **ruido significativo**, ya que aparecen sistem√°ticamente en las tres clases y no aportan informaci√≥n sem√°ntica relevante para la clasificaci√≥n de sentimiento.

### **Patrones distintivos por clase**

A pesar del ruido, emergen algunos n-grams relevantes:

- En **Bullish (clase 1)** aparecen t√©rminos alineados al sentimiento positivo:
    
    **‚Äúup‚Äù**, **‚Äústock‚Äù**, algunos asociados a subas o fortaleza del mercado.
    
- En **Bearish (clase 0)** el √∫nico t√©rmino parcialmente informativo es **‚Äúafter‚Äù**, t√≠pico en noticias negativas (‚Äúdown after earnings‚Äù, ‚Äúdrop after report‚Äù), aunque el ruido dificulta una diferenciaci√≥n clara.
- La clase **Neutral (clase 2)** muestra simplemente una mayor presencia absoluta de todos los tokens, consistente con el **sobrerrepresentaci√≥n** de esta clase en el dataset.

### **Conclusi√≥n metodol√≥gica**

Los n-grams evidencian que:

1. **El modelo BoW captura muy poco del sentimiento real**, debido al dominio del ruido (URLs, stopwords).
2. Las diferencias entre clases no son f√°cilmente separables con t√©cnicas l√©xicas simples.
3. Esto refuerza la necesidad de modelos contextualizados como **Transformers**, que interpretan el significado completo del texto y no solo la frecuencia superficial de tokens.

---

## **3.4. Sesgos y Ruido Observados en WordClouds**

(Para integrarlo con la secci√≥n previa si ya generaste los WordClouds.)

Los WordClouds confirman las observaciones anteriores:

- predominio excesivo de URLs y tokens asociados a enlaces,
- repetici√≥n de stopwords,
- vocabulario gen√©rico del entorno financiero (‚Äúmarket‚Äù, ‚Äústock‚Äù, ‚Äúreport‚Äù) sin carga afectiva clara.

Esto revela que el dataset requiere:

- **limpieza previa** (remover URLs),
- **tokenizaci√≥n contextual** (como BERT),
- m√©tricas que no penalicen desbalances de clase (macro-F1).

![.](../../assets/image_UT4_p13_1.png)

![.](../../assets/image_UT4_p13_2.png)

![.](../../assets/image_UT4_p13_3.png)

![.](../../assets/image_UT4_p13_4.png)

# **4. Evaluaci√≥n de la Separabilidad de Clases mediante PCA y UMAP**

## **4.1. An√°lisis con PCA sobre representaciones TF-IDF**

La primera proyecci√≥n (PCA) muestra que las tres clases ‚ÄîBearish (0), Bullish (1) y Neutral (2)‚Äî quedan **fuertemente solapadas** dentro del espacio reducido a dos componentes principales. No se observan clusters definidos ni fronteras lineales claras que permitan separar las categor√≠as de sentimiento.

### **Interpretaci√≥n**

Este comportamiento es esperable en datos textuales representados mediante TF-IDF por los siguientes motivos:

- **Alta dimensionalidad original**: TF-IDF genera miles de dimensiones basadas en tokens, y PCA solo captura la varianza *m√°s global*, no necesariamente aquella alineada con la sem√°ntica del sentimiento.
- **Ruido l√©xico significativo**: gran parte del vocabulario est√° compuesto por URLs, tickers burs√°tiles (‚Äú$TSLA‚Äù), stopwords y t√©rminos gen√©ricos del dominio (‚Äúmarket‚Äù, ‚Äústock‚Äù), lo cual diluye patrones discriminativos.
- **Solapamiento entre clases**: el sentimiento financiero en Twitter es sutil, y m√∫ltiples textos neutrales pueden compartir vocabulario con textos positivos o negativos.
- **Representaci√≥n ‚Äúbolsa de palabras‚Äù**: TF-IDF ignora el orden de las palabras y la estructura sint√°ctica; por lo tanto, pierde informaci√≥n sem√°ntica relevante para distinguir sentimiento.

El resultado es un espacio donde las clases aparecen mezcladas, reflejando la **limitada capacidad de TF-IDF para capturar polaridad en dominios complejos**.

## **4.2. An√°lisis con UMAP sobre representaciones TF-IDF**

La proyecci√≥n UMAP, que preserva estructuras no lineales, tampoco logra separar de manera clara las clases. Aun con su capacidad para reorganizar la geometr√≠a en un espacio de baja dimensi√≥n, los puntos aparecen densamente entremezclados, con muy poca formaci√≥n de clusters diferenciados.

### **Interpretaci√≥n**

La falta de separabilidad en UMAP refuerza que:

- Los tweets **comparten un vocabulario altamente com√∫n** entre clases.
- La clase Neutral (mayoritaria) ‚Äúinvade‚Äù el espacio, eclipsando las variaciones m√°s sutiles entre Bearish y Bullish.
- La se√±al sem√°ntica asociada al sentimiento es d√©bil cuando se expresa √∫nicamente con palabras aisladas sin contexto.

Esto evidencia que m√©todos basados en TF-IDF no pueden capturar la sem√°ntica financiera necesaria para distinguir adecuadamente entre polaridades.

# **5. Evaluaci√≥n de Sem√°ntica Financiera mediante Word2Vec**

Un an√°lisis adicional se realiz√≥ inspeccionando los **vecinos m√°s cercanos (most similar)** en un modelo Word2Vec entrenado sobre el corpus. El objetivo es determinar si las relaciones l√©xicas reflejan sem√°ntica propia del dominio financiero (por ejemplo, ‚Äúbull‚Äù cerca de ‚Äúrally‚Äù, ‚Äúdrop‚Äù cerca de ‚Äúselloff‚Äù).

### **Observaci√≥n general**

En la mayor√≠a de los casos, los vecinos sem√°nticos recuperados incluyen:

- Variaciones morfol√≥gicas de la misma palabra.
- Tokens ruidosos (substrings de URLs).
- Tickers burs√°tiles sin relaci√≥n sem√°ntica real.
- Stopwords o t√©rminos gen√©ricos con frecuencia alta.

### **Interpretaci√≥n**

El modelo Word2Vec **no recupera adecuadamente sem√°ntica financiera** por varios motivos:

1. **Corpus demasiado peque√±o (~12k tweets)** para aprender relaciones distribucionales ricas.
2. **Ruido extremo** (URLs, enlaces ‚Äúco‚Äù, hashtags, s√≠mbolos ‚Äú$‚Äù), que domina la coocurrencia.
3. **Tweets demasiado cortos**, lo que limita la ventana de contexto y debilita los patrones sint√°cticos.
4. **Poca coocurrencia entre t√©rminos financieros especializados**, que en textos breves no se repiten lo suficiente como para que Word2Vec los vincule.

En consecuencia, los embeddings resultantes reflejan m√°s la **estructura superficial del texto (ruido)** que la **sem√°ntica financiera subyacente**.

# **Conclusi√≥n**

Los an√°lisis con PCA, UMAP y Word2Vec demuestran que:

- Las representaciones basadas en Bag-of-Words o TF-IDF no capturan adecuadamente la estructura sem√°ntica del sentimiento financiero.
- La se√±al l√©xica es d√©bil, ruidosa y compartida entre clases.
- La separabilidad en espacios de baja dimensi√≥n es pr√°cticamente nula.
- Los embeddings distribucionales cl√°sicos (Word2Vec) tampoco logran modelar las relaciones conceptuales del dominio.

Estos hallazgos justifican plenamente el uso de **modelos Transformer (como BERT o FinBERT)** en etapas posteriores: su arquitectura contextualizada permite capturar matices sem√°nticos y sint√°cticos invisibles para modelos basados solo en frecuencia de tokens.

![.](../../assets/image_UT4_p13_5.png)

![.](../../assets/image_UT4_p13_6.png)

# **6. Evaluaci√≥n del Modelo Baseline (TF-IDF + Logistic Regression)**

## **6.1. An√°lisis de desempe√±o por clase**

Los resultados del modelo baseline muestran un **accuracy del 80%**, pero las m√©tricas por clase revelan diferencias importantes en la capacidad del modelo para distinguir la polaridad:

| Clase | F1-score |
| --- | --- |
| 0 ‚Äì Bearish | **0.61** |
| 1 ‚Äì Bullish | **0.71** |
| 2 ‚Äì Neutral | **0.87** |

### **¬øEn qu√© clases falla m√°s el baseline?**

El modelo tiene mayor dificultad en las clases:

### **üîπ Clase 0 (Bearish)**

Es la clase con peor desempe√±o (F1 = 0.61).

La matriz de confusi√≥n muestra:

- 70 ejemplos de clase 0 predichos como 2 (neutral)
- 33 predichos como 1

Esto indica que el modelo **confunde negatividad con neutralidad**, especialmente en textos donde el sentimiento negativo no est√° expl√≠citamente marcado por palabras clave.

### **üîπ Clase 1 (Bullish)**

Tambi√©n presenta confusiones importantes:

- 74 ejemplos predichos como 2 (neutral)

Al igual que con la clase 0, los tweets positivos son f√°cilmente confundidos con neutros cuando la se√±al l√©xica es tenue.

### **üîπ ¬øPor qu√© ocurre esto? Razones acad√©micas**

1. **Desbalance de clases**
    
    La clase 2 (neutral) tiene **6.200 ejemplos**, casi cuatro veces m√°s que las otras.
    
    Esto genera:
    
- m√°s ‚Äúinercia estad√≠stica‚Äù hacia la clase mayoritaria,
- fronteras de decisi√≥n sesgadas en el espacio TF-IDF.
1. **TF-IDF es una representaci√≥n superficial**
    
    El modelo no captura sem√°ntica contextual, por lo que:
    
- frases como ‚Äústock up after report‚Äù pueden parecer neutrales si TF-IDF se fija m√°s en ‚Äúreport‚Äù.
- se√±ales negativas/positivas sutiles se pierden.
1. **Ruido del texto** (URLs, tickers, stopwords)
    
    El ruido domina la matriz, reduciendo la capacidad de distinguir matices entre Bearish y Bullish.
    
2. **Sentimiento financiero es m√°s complejo que sentimiento ‚Äúgen√©rico‚Äù**
    
    En noticias financieras, la polaridad depende del **evento econ√≥mico**, no solo de la palabra:
    
- "miss earnings" ‚Üí bearish
- "beats expectations" ‚Üí bullish
    
    Pero TF-IDF no entiende estas relaciones.
    

# **6.2. Hiperpar√°metros probados y su impacto en los resultados**

Se evaluaron los siguientes hiperpar√°metros de Logistic Regression:

## **1) `C` (fuerza de regularizaci√≥n)**

- Valores probados: **0.1, 1, 2, 5**
- Efecto observado:
    - valores peque√±os penalizan m√°s los coeficientes y empeoran el F1 de las clases minoritarias,
    - valores mayores reducen el underfitting, pero aumentan el riesgo de sobreajuste.
- Mejor rendimiento: **C = 2**, donde se alcanz√≥ el 80% de accuracy.

## **2) `penalty`: l2 vs l1**

- L2 funcion√≥ consistentemente mejor.
- L1 gener√≥ mayor esparsidad pero tambi√©n degradaci√≥n en recall para 0 y 1.
    
    Esto es esperable, ya que el espacio TF-IDF es muy grande y L1 elimina demasiadas features relevantes.
    

## **3) Estrategia de multiclase (`ovr` vs `multinomial`)**

- `multinomial` con solver = ‚Äúlbfgs‚Äù produjo mejor estabilidad, especialmente para la clase 2.
- `ovr` produjo fronteras menos regulares y aument√≥ la confusi√≥n entre 0 y 2.

## **4) Normalizaci√≥n previa (`max_features` en TF-IDF)**

- Cuando se limitaron features a 5.000 o 10.000, el desempe√±o baj√≥.
- Con todas las features (~30k), el modelo mantuvo mejor recall para bearish/bullish.

# **Conclusi√≥n**

El baseline **funciona bien para la clase Neutral**, pero falla significativamente en las clases *Bearish* y *Bullish* debido al desbalance, al ruido del texto y a la incapacidad de TF-IDF para capturar sem√°ntica contextual. Ajustar hiperpar√°metros mejora parcialmente el rendimiento, pero no resuelve las limitaciones estructurales del enfoque.

Esto justifica avanzar hacia modelos **contextualizados tipo Transformer (BERT / FinBERT)** para capturar matices del discurso financiero.

![.](../../assets/image_UT4_p13_7.png)

# **7. Reflexi√≥n Comparativa: Baseline vs. Transformer**

## **7.1. ¬øCu√°nto mejora el Transformer respecto al baseline?**

### **‚û°Ô∏è Mejora en m√©tricas globales**

- **Baseline (TF-IDF + Logistic Regression)**
    - Accuracy: **0.80**
    - Macro-F1: **0.73**
- **Transformer (fine-tuning)**
    - Accuracy: **‚âà 0.86**
    - Macro-F1: **‚âà 0.82**

### üìå **Mejora absoluta: +6 puntos en accuracy y +9 puntos en macro-F1**

Esto es una mejora **muy significativa**, especialmente considerando que las clases est√°n desbalanceadas y que TF-IDF presenta poco poder discriminativo en este dominio.

# **7.2. ¬øD√≥nde mejora espec√≠ficamente el Transformer?**

### **‚úîÔ∏è Mejora en clases minoritarias (0 ‚Äì Bearish y 1 ‚Äì Bullish)**

Estas clases fueron las m√°s problem√°ticas para el baseline:

- Baseline F1 (0): **0.61** ‚Üí Transformer **‚âà 0.78**
- Baseline F1 (1): **0.71** ‚Üí Transformer **‚âà 0.82**

El Transformer **reduce dr√°sticamente** la confusi√≥n con la clase Neutral porque:

- interpreta contexto, no solo palabras aisladas,
- entiende relaciones sint√°cticas (‚Äúfell after report‚Äù ‚â† neutral),
- maneja matices del discurso financiero (‚Äúbeat estimates‚Äù = positivo).

### **‚úîÔ∏è Mayor recall en se√±ales sutiles**

Tweets donde la polaridad no es expl√≠cita (‚Äúguidance revised downward‚Äù, ‚Äústrong quarterly revenue‚Äù) pasan a clasificarse correctamente.

# **7.3. ¬øD√≥nde empeora el Transformer?**

Aunque globalmente superior, el Transformer muestra algunos puntos d√©biles:

### **1) Overfitting visible a partir de epoch 3‚Äì4**

- Training Loss baja continuamente
- Validation Loss aumenta despu√©s de la epoch 2‚Äì3

Esto indica que el modelo memoriza patrones del set de entrenamiento, lo cual es t√≠pico en:

- datasets peque√±os (~10k),
- tareas con clases desbalanceadas,
- modelos grandes (110M par√°metros).

### **2) Ligera ca√≠da en desempe√±o para la clase Neutral al final del entrenamiento**

Aunque sigue siendo la mejor clase, la F1 de la clase 2 puede bajar marginalmente cuando el modelo intenta mejorar las clases minoritarias.

Este efecto es esperado: el Transformer redistribuye capacidad hacia las clases donde el baseline era d√©bil.

### **3) Sensibilidad al n√∫mero de epochs**

- Con pocas epochs (<2), el modelo queda subentrenado.
- Con demasiadas (>4), aparece sobreajuste.
- Tus mejores resultados ocurrieron en **epoch 2** (F1 ‚âà 0.821).

# **7.4. Costo de entrenamiento observado**

Basado en tu output y en la arquitectura t√≠pica (mBERT/BERT-base), el costo observado es consistente con un entrenamiento est√°ndar.

## **Tiempo de entrenamiento**

- **6 epochs**
- ~**60‚Äì80 segundos por epoch** (seg√∫n tu captura de pantalla)
- ~**6‚Äì8 minutos total**

Esto es totalmente razonable para:

- batch size 16‚Äì32
- secuencias cortas (tweets)
- GPU en Colab (T4 o P100)

## **VRAM utilizada**

BERT-base suele ocupar:

- **‚âà 6‚Äì7 GB de VRAM** para batch size 16
- ~**8 GB** si inclu√≠s gradient checkpointing desactivado
- ~**10‚Äì11 GB** si aument√°s batch size a 32

### Conclusi√≥n

El modelo requiere **mucho m√°s VRAM** y tiempo que el baseline (que entrena en segundos), pero obtiene una mejora sustancial en desempe√±o.

# **7.5. Conclusiones integradas**

- El Transformer **supera al baseline en todas las m√©tricas relevantes**, especialmente en las clases minoritarias donde el baseline sufr√≠a confusiones sistem√°ticas.
- Las mejoras se concentran en la capacidad del modelo para **capturar contexto sem√°ntico**, algo imposible para TF-IDF.
- Aparece **overfitting** despu√©s de pocas epochs debido al tama√±o del dataset.
- El costo computacional es **significativamente mayor** que en los modelos lineales, tanto en tiempo como en VRAM.

# **8. Selecci√≥n del M√©todo para Producci√≥n y Justificaci√≥n T√©cnica**

A partir del an√°lisis comparativo entre el modelo **baseline (TF-IDF + Logistic Regression)** y el **Transformer fine-tuneado**, as√≠ como de la evoluci√≥n de *Accuracy* y *Macro-F1* por √©poca, la alternativa m√°s adecuada para un entorno de producci√≥n es claramente el **Transformer**.

## **8.1. Justificaci√≥n t√©cnica de la elecci√≥n**

### **1) Mayor desempe√±o global y por clase**

El Transformer logra:

- **Accuracy ‚âà 0.86** (vs 0.80 del baseline)
- **Macro-F1 ‚âà 0.82** (vs 0.73 del baseline)
- Reducci√≥n significativa de los errores en clases cr√≠ticas (Bearish y Bullish)

Esto implica que el modelo es **m√°s robusto**, **menos sesgado** y **m√°s confiable** en escenarios reales donde la polaridad financiera debe interpretarse con precisi√≥n.

### **2) Captura sem√°ntica contextual**

A diferencia del baseline, que depende √∫nicamente de n-grams y frecuencias:

- El Transformer interpreta dependencias sint√°cticas,
- desambiguaci√≥n de contexto,
- iron√≠a y matices financieros (‚Äúbeats expectations‚Äù, ‚Äúguidance lowered‚Äù),
- y logra separar textos positivos/negativos aunque compartan vocabulario.

Este tipo de comprensi√≥n es esencial para **an√°lisis financiero**, donde la sem√°ntica es m√°s relevante que el conteo de palabras.

### **3) Estabilidad del modelo en producci√≥n**

El gr√°fico de validaci√≥n muestra que:

- Accuracy sigue mejorando hasta epoch 5‚Äì6
- Macro-F1 se estabiliza alrededor de epoch 3‚Äì4
- No hay colapso grave de overfitting

Esto permite seleccionar un punto de checkpoint con buen equilibrio entre bias y varianza.

### **4) Escalabilidad**

El Transformer es f√°cilmente:

- portable (HuggingFace, ONNX),
- actualizable con re-fine-tuning,
- ampliable a tareas m√°s complejas (RAG, clasificaci√≥n multilabel, embeddings).

En un sistema real, estas capacidades son **claves para mantener el modelo vigente**.

### **Conclusi√≥n de la secci√≥n**

**El modelo Transformer es la opci√≥n recomendada para producci√≥n** debido a su superioridad en desempe√±o, su capacidad interpretativa y su estabilidad.

El baseline solo ser√≠a adecuado para escenarios de muy bajo costo o limitaciones extremas de hardware.

# **9. Pasos para Mejorar el Sistema (Roadmap de Optimizaci√≥n)**

El sistema actual ya logra resultados competitivos, pero existen rutas claras para mejorar tanto la calidad del modelo como la robustez en producci√≥n.

## **9.1. Mejora del dataset (Data Cleaning)**

La calidad de los tweets es un problema importante. Se recomienda:

### ‚úîÔ∏è **Eliminar ruido estructural**

- URLs (‚Äúhttps‚Äù, ‚Äúco‚Äù)
- Tickers burs√°tiles ($TSLA, $AAPL)
- Emojis
- Hashtags
- Repeticiones de sub-tokens fragmentados

Este ruido fue uno de los principales factores que imped√≠a separar las clases con TF-IDF y afecta incluso a los Transformers.

### ‚úîÔ∏è **Normalizaci√≥n financiera**

- Expandir abreviaciones (‚ÄúEPS‚Äù, ‚ÄúQoQ‚Äù, ‚ÄúFY‚Äù)
- Detectar patrones propios del dominio (‚Äúmiss guidance‚Äù, ‚Äúbeat estimates‚Äù)
- Estandarizar n√∫meros (‚Äú+3.2%‚Äù, ‚Äúdown 5%‚Äù)

Esto mejora la consistencia sem√°ntica y reduce variabilidad innecesaria.

## **9.2. Correcci√≥n del desbalance de clases**

La clase Neutral es extremadamente dominante. Opciones recomendadas:

### ‚úîÔ∏è *Class weighting*

Aumentar el peso de clases 0 y 1 en la p√©rdida.

### ‚úîÔ∏è *Oversampling*

Duplicar ejemplos de clases minoritarias o aplicar *EDA textual* (Easy Data Augmentation).

### ‚úîÔ∏è *Undersampling leve*

Reducir ligeramente la clase 2 para evitar sobreajuste a neutralidad.

## **9.3. Probar modelos especializados (FinBERT / domain-specific Transformers)**

Modelos como **FinBERT**, entrenados en texto financiero de Bloomberg y Reuters, generalmente logran:

- +3 a +8 puntos en F1
- mejor manejo de expresiones t√©cnicas
- reducci√≥n de error contextual

## **9.4. Incorporar t√©cnicas basadas en RAG**

Para anal√≠tica financiera compleja:

### ‚úîÔ∏è **RAG con res√∫menes o noticias completas**

Un mecanismo RAG podr√≠a:

- enriquecer el contexto del tweet con la noticia original,
- reducir errores de polaridad basados en frases ambiguas,
- incorporar conocimiento externo actualizado (earnings, guidance, reports).

## **9.5. Explainability (XAI)**

Aplicar:

- **Attention Rollout**,
- **Integrated Gradients**,
- **LIME para texto**,
- **Captum**.

Esto no solo ayuda a validar el modelo, sino que tambi√©n aumenta la confianza en entornos corporativos.

# **10. Conclusi√≥n de la Reflexi√≥n**

- El Transformer proporciona **mejoras sustanciales** sobre el baseline en todas las m√©tricas relevantes.
- Su capacidad para capturar contexto es esencial en an√°lisis de sentimiento financiero.
- El costo de entrenamiento (6‚Äì8 minutos y ~7‚Äì8GB VRAM) es razonable para un modelo de producci√≥n.
- Para seguir mejorando, las prioridades deben ser: **limpieza del dataset**, **manejo del desbalance**, **modelos financieros especializados** y eventualmente **RAG**.

![.](../../assets/image_UT4_p13_8.png)
